{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d158954-8312-4679-99a8-38420351c8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from collections import defaultdict\n",
    "import platform\n",
    "import glob\n",
    "import os\n",
    "import ast\n",
    "\n",
    "# 根据操作系统设置合适的中文字体\n",
    "system = platform.system()\n",
    "if system == 'Darwin':  # macOS\n",
    "    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'Heiti TC', 'PingFang HK', 'Apple Color Emoji']\n",
    "elif system == 'Windows':\n",
    "    plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'SimSun']\n",
    "else:  # Linux或其他\n",
    "    plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'WenQuanYi Micro Hei', 'WenQuanYi Zen Hei']\n",
    "\n",
    "# 正常显示负号\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(f\"当前操作系统: {system}\")\n",
    "print(f\"当前字体设置: {plt.rcParams['font.sans-serif']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a81fda-041e-4bcd-926a-85ce119a9234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已保存结果到 生成结果/matches_analysis/merged_matches_双竹2025-01-10之后VOC数据.xlsx\n",
      "已保存结果到 生成结果/defect_analysis/merged_defect_双竹2025-01-10之后VOC数据.xlsx\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Needs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/Lynx/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Needs'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 111\u001b[0m\n\u001b[1;32m    102\u001b[0m     merge_analysis_with_original(\n\u001b[1;32m    103\u001b[0m         needs_result_pattern, \n\u001b[1;32m    104\u001b[0m         original_data_pattern, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmerged_needs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m     )\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 111\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 102\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m merge_analysis_with_original(\n\u001b[1;32m     94\u001b[0m     defect_result_pattern, \n\u001b[1;32m     95\u001b[0m     original_data_pattern, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmerged_defect\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m )\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# (3) 处理needs分析结果\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m \u001b[43mmerge_analysis_with_original\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mneeds_result_pattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43moriginal_data_pattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNeeds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 注意大小写\u001b[39;49;00m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mneeds_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmerged_needs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    108\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 53\u001b[0m, in \u001b[0;36mmerge_analysis_with_original\u001b[0;34m(analysis_pattern, original_pattern, analysis_column, output_dir, output_prefix)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices:\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(result_df):\n\u001b[0;32m---> 53\u001b[0m             result_df\u001b[38;5;241m.\u001b[39mat[idx, analysis_column] \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43manalysis_column\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# 构建输出文件路径\u001b[39;00m\n\u001b[1;32m     56\u001b[0m file_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(original_file)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Lynx/lib/python3.10/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Lynx/lib/python3.10/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Lynx/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Needs'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def find_file(pattern):\n",
    "    \"\"\"查找匹配模式的文件，返回第一个匹配的文件路径\"\"\"\n",
    "    files = glob.glob(pattern)\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"未找到匹配 {pattern} 的文件\")\n",
    "    return files[0]\n",
    "\n",
    "def merge_analysis_with_original(analysis_pattern, original_pattern, analysis_column, output_dir, output_prefix):\n",
    "    \"\"\"\n",
    "    合并分析结果与原始数据\n",
    "    \n",
    "    参数:\n",
    "    - analysis_pattern: 分析结果文件的模式\n",
    "    - original_pattern: 原始数据文件的模式\n",
    "    - analysis_column: 需要合并到原始数据的分析结果列名\n",
    "    - output_dir: 输出目录\n",
    "    - output_prefix: 输出文件名前缀\n",
    "    \"\"\"\n",
    "    # 查找文件\n",
    "    analysis_file = find_file(analysis_pattern)\n",
    "    original_file = find_file(original_pattern)\n",
    "    \n",
    "    # 读取文件\n",
    "    analysis_df = pd.read_excel(analysis_file)\n",
    "    original_df = pd.read_excel(original_file)\n",
    "    \n",
    "    # 创建新的DataFrame，复制原始数据\n",
    "    result_df = original_df.copy()\n",
    "    \n",
    "    # 初始化新列\n",
    "    result_df[analysis_column] = None\n",
    "    \n",
    "    # 遍历分析结果\n",
    "    for _, row in analysis_df.iterrows():\n",
    "        # 确保Review_Indices是列表形式\n",
    "        if isinstance(row['Review_Indices'], str):\n",
    "            indices = ast.literal_eval(row['Review_Indices'])\n",
    "        else:\n",
    "            indices = row['Review_Indices']\n",
    "        \n",
    "        # 确保indices是列表\n",
    "        if not isinstance(indices, list):\n",
    "            indices = [indices]\n",
    "        \n",
    "        # 为匹配的索引赋值\n",
    "        for idx in indices:\n",
    "            if 0 <= idx < len(result_df):\n",
    "                result_df.at[idx, analysis_column] = row[analysis_column]\n",
    "    \n",
    "    # 构建输出文件路径\n",
    "    file_name = os.path.basename(original_file)\n",
    "    base_name = os.path.splitext(file_name)[0]\n",
    "    output_file = os.path.join(output_dir, f\"{output_prefix}_{base_name}.xlsx\")\n",
    "    \n",
    "    # 确保输出目录存在\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 保存结果\n",
    "    result_df.to_excel(output_file, index=False)\n",
    "    print(f\"已保存结果到 {output_file}\")\n",
    "    \n",
    "    return output_file\n",
    "\n",
    "def main():\n",
    "    # 1. 文件路径和模式\n",
    "    matches_dir = '生成结果/matches_analysis/'\n",
    "    defect_dir = '生成结果/defect_analysis/'\n",
    "    needs_dir = '生成结果/needs_analysis/'\n",
    "    original_data_dir = './Data/'\n",
    "    \n",
    "    # 2. 具体文件名或模式\n",
    "    matches_result_pattern = os.path.join(matches_dir, 'refined_*_matches_analysis.xlsx')\n",
    "    defect_result_pattern = os.path.join(defect_dir, 'refined_*_defects_analysis.xlsx')\n",
    "    needs_result_pattern = os.path.join(needs_dir, 'refined_*_needs_analysis.xlsx')  # 注意：这里修正了路径，原来是defect_dir\n",
    "    original_data_pattern = os.path.join(original_data_dir, '*_校对.xlsx')\n",
    "    \n",
    "    # 3. 执行合并操作\n",
    "    # (1) 处理matches分析结果\n",
    "    merge_analysis_with_original(\n",
    "        matches_result_pattern, \n",
    "        original_data_pattern, \n",
    "        \"Match\",  # 注意大小写\n",
    "        matches_dir, \n",
    "        \"merged_matches\"\n",
    "    )\n",
    "    \n",
    "    # (2) 处理defect分析结果\n",
    "    merge_analysis_with_original(\n",
    "        defect_result_pattern, \n",
    "        original_data_pattern, \n",
    "        \"Defect\",  # 注意大小写\n",
    "        defect_dir, \n",
    "        \"merged_defect\"\n",
    "    )\n",
    "    \n",
    "    # (3) 处理needs分析结果\n",
    "    merge_analysis_with_original(\n",
    "        needs_result_pattern, \n",
    "        original_data_pattern, \n",
    "        \"Need\",  # 注意大小写\n",
    "        needs_dir, \n",
    "        \"merged_needs\"\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db43524b-ee4e-4b2b-bdb3-04a7ddf15b79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lynx",
   "language": "python",
   "name": "lynx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
