{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71d629c9-3752-4cd8-92fb-8c32a3fc8de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "matches_dir = '生成结果/matches_analysis/'\n",
    "needs_dir = '生成结果/needs_analysis/'\n",
    "defect_dir = '生成结果/defect_analysis/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "535be625-60a8-4b53-8ada-9f9b1830dad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "将从 生成结果/matches_analysis/致欧-2025-01-10之后VOC数据_功能场景匹配象限分析_完整列表.txt 读取数据\n",
      "将结果保存到 生成结果/matches_analysis/致欧-2025-01-10之后VOC数据_功能场景匹配象限分析_完整列表.xlsx\n",
      "数据已成功保存到 生成结果/matches_analysis/致欧-2025-01-10之后VOC数据_功能场景匹配象限分析_完整列表.xlsx\n"
     ]
    }
   ],
   "source": [
    "# 从文件中读取文本内容\n",
    "# 在matches_dir文件夹中查找txt文件\n",
    "txt_files = [f for f in os.listdir(matches_dir) if f.endswith('.txt')]\n",
    "\n",
    "if not txt_files:\n",
    "    print(f\"在 {matches_dir} 文件夹中未找到任何txt文件\")\n",
    "    sys.exit(1)\n",
    "    \n",
    "# 如果找到多个txt文件，打印列表并使用第一个\n",
    "if len(txt_files) > 1:\n",
    "    print(f\"在 {matches_dir} 文件夹中找到多个txt文件:\")\n",
    "    for i, txt_file in enumerate(txt_files):\n",
    "        print(f\"{i+1}. {txt_file}\")\n",
    "    print(f\"将使用第一个文件: {txt_files[0]}\")\n",
    "\n",
    "# 获取第一个txt文件的完整路径\n",
    "txt_file_name = txt_files[0]\n",
    "matches_file_path = os.path.join(matches_dir, txt_file_name)\n",
    "try:\n",
    "    with open(matches_file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "except UnicodeDecodeError:\n",
    "    # 如果UTF-8解码失败，尝试其他编码\n",
    "    with open(matches_file_path, 'r', encoding='gbk') as file:\n",
    "        text = file.read()\n",
    "\n",
    "# 初始化列表存储提取的数据\n",
    "data = []\n",
    "\n",
    "# 定义当前象限\n",
    "current_quadrant = \"\"\n",
    "\n",
    "# 逐行解析文本\n",
    "lines = text.strip().split('\\n')\n",
    "i = 0\n",
    "while i < len(lines):\n",
    "    line = lines[i].strip()\n",
    "    \n",
    "    # 匹配象限标题\n",
    "    if line.startswith('## '):\n",
    "        quadrant_match = re.match(r'## 第(.+)象限：(.+)', line)\n",
    "        if quadrant_match:\n",
    "            current_quadrant = f\"第{quadrant_match.group(1)}象限：{quadrant_match.group(2)}\"\n",
    "    \n",
    "    # 匹配功能项\n",
    "    elif re.match(r'^\\d+\\.\\s', line):\n",
    "        feature = line[line.find('.')+1:].strip()\n",
    "        \n",
    "        # 检查下一行是否包含分数信息\n",
    "        if i+1 < len(lines):\n",
    "            scores_line = lines[i+1].strip()\n",
    "            importance_match = re.search(r'重要性分数:\\s*([\\d\\.]+)', scores_line)\n",
    "            frequency_match = re.search(r'提及频率:\\s*([\\d\\.e\\-]+)', scores_line)\n",
    "            quality_match = re.search(r'文本质量:\\s*([\\d\\.]+)', scores_line)\n",
    "            \n",
    "            # 检查下一行是否包含最终得分\n",
    "            if i+2 < len(lines):\n",
    "                final_score_line = lines[i+2].strip()\n",
    "                final_score_match = re.search(r'最终得分:\\s*([\\d\\.]+)', final_score_line)\n",
    "                \n",
    "                if importance_match and frequency_match and quality_match and final_score_match:\n",
    "                    importance = float(importance_match.group(1))\n",
    "                    frequency = float(frequency_match.group(1))\n",
    "                    quality = float(quality_match.group(1))\n",
    "                    final_score = float(final_score_match.group(1))\n",
    "                    \n",
    "                    # 添加到数据列表\n",
    "                    data.append({\n",
    "                        '象限': current_quadrant,\n",
    "                        '场景匹配内容': feature,\n",
    "                        '重要性分数': importance,\n",
    "                        '提及频率': frequency,\n",
    "                        '文本质量': quality,\n",
    "                        '最终得分': final_score\n",
    "                    })\n",
    "    i += 1\n",
    "\n",
    "# 创建DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 保存为Excel文件\n",
    "excel_file_name = os.path.splitext(txt_file_name)[0] + '.xlsx'\n",
    "matches_excel_file = os.path.join(matches_dir, excel_file_name)\n",
    "df.to_excel(matches_excel_file, index=False)\n",
    "print(f\"将从 {matches_file_path} 读取数据\")\n",
    "print(f\"将结果保存到 {matches_excel_file}\")\n",
    "print(f\"数据已成功保存到 {matches_excel_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e8ab26a-7c6a-4003-bcdc-5da19038e351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "将从 生成结果/needs_analysis/致欧-2025-01-10之后VOC数据_用户需求象限分析_完整列表.txt 读取数据\n",
      "将结果保存到 生成结果/needs_analysis/致欧-2025-01-10之后VOC数据_用户需求象限分析_完整列表.xlsx\n",
      "数据已成功保存到 生成结果/needs_analysis/致欧-2025-01-10之后VOC数据_用户需求象限分析_完整列表.xlsx\n"
     ]
    }
   ],
   "source": [
    "# 从文件中读取文本内容\n",
    "#needs_file_path =  os.path.join(needs_dir , '美国站旅行袋销售数据及VOC数据_用户需求象限分析_完整列表.txt')  # 请替换为您的实际文件路径\n",
    "txt_files = [f for f in os.listdir(needs_dir) if f.endswith('.txt')]\n",
    "\n",
    "if not txt_files:\n",
    "    print(f\"在 {needs_dir} 文件夹中未找到任何txt文件\")\n",
    "    sys.exit(1)\n",
    "    \n",
    "# 如果找到多个txt文件，打印列表并使用第一个\n",
    "if len(txt_files) > 1:\n",
    "    print(f\"在 {needs_dir} 文件夹中找到多个txt文件:\")\n",
    "    for i, txt_file in enumerate(txt_files):\n",
    "        print(f\"{i+1}. {txt_file}\")\n",
    "    print(f\"将使用第一个文件: {txt_files[0]}\")\n",
    "\n",
    "# 获取第一个txt文件的完整路径\n",
    "txt_file_name = txt_files[0]\n",
    "needs_file_path = os.path.join(needs_dir, txt_file_name)\n",
    "\n",
    "\n",
    "try:\n",
    "    with open(needs_file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "except UnicodeDecodeError:\n",
    "    # 如果UTF-8解码失败，尝试其他编码\n",
    "    with open(needs_file_path, 'r', encoding='gbk') as file:\n",
    "        text = file.read()\n",
    "\n",
    "# 初始化列表存储提取的数据\n",
    "data = []\n",
    "\n",
    "# 定义当前象限\n",
    "current_quadrant = \"\"\n",
    "\n",
    "# 逐行解析文本\n",
    "lines = text.strip().split('\\n')\n",
    "i = 0\n",
    "while i < len(lines):\n",
    "    line = lines[i].strip()\n",
    "    \n",
    "    # 匹配象限标题\n",
    "    if line.startswith('## '):\n",
    "        quadrant_match = re.match(r'## 第(.+)象限：(.+)', line)\n",
    "        if quadrant_match:\n",
    "            current_quadrant = f\"第{quadrant_match.group(1)}象限：{quadrant_match.group(2)}\"\n",
    "    \n",
    "    # 匹配功能项\n",
    "    elif re.match(r'^\\d+\\.\\s', line):\n",
    "        feature = line[line.find('.')+1:].strip()\n",
    "        \n",
    "        # 检查下一行是否包含分数信息\n",
    "        if i+1 < len(lines):\n",
    "            scores_line = lines[i+1].strip()\n",
    "            importance_match = re.search(r'重要性分数:\\s*([\\d\\.]+)', scores_line)\n",
    "            frequency_match = re.search(r'提及频率:\\s*([\\d\\.e\\-]+)', scores_line)\n",
    "            quality_match = re.search(r'文本质量:\\s*([\\d\\.]+)', scores_line)\n",
    "            \n",
    "            # 检查下一行是否包含最终得分\n",
    "            if i+2 < len(lines):\n",
    "                final_score_line = lines[i+2].strip()\n",
    "                final_score_match = re.search(r'最终得分:\\s*([\\d\\.]+)', final_score_line)\n",
    "                \n",
    "                if importance_match and frequency_match and quality_match and final_score_match:\n",
    "                    importance = float(importance_match.group(1))\n",
    "                    frequency = float(frequency_match.group(1))\n",
    "                    quality = float(quality_match.group(1))\n",
    "                    final_score = float(final_score_match.group(1))\n",
    "                    \n",
    "                    # 添加到数据列表\n",
    "                    data.append({\n",
    "                        '象限': current_quadrant,\n",
    "                        '未满足需求': feature,\n",
    "                        '重要性分数': importance,\n",
    "                        '提及频率': frequency,\n",
    "                        '文本质量': quality,\n",
    "                        '最终得分': final_score\n",
    "                    })\n",
    "    i += 1\n",
    "\n",
    "# 创建DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 保存为Excel文件\n",
    "#needs_excel_file =  os.path.join(needs_dir, '美国站旅行袋销售数据及VOC数据_用户需求象限分析_完整列表.xlsx')\n",
    "# 生成对应的Excel文件名（保持基本文件名相同，只改变扩展名）\n",
    "excel_file_name = os.path.splitext(txt_file_name)[0] + '.xlsx'\n",
    "needs_excel_file = os.path.join(needs_dir, excel_file_name)\n",
    "\n",
    "print(f\"将从 {needs_file_path} 读取数据\")\n",
    "print(f\"将结果保存到 {needs_excel_file}\")\n",
    "\n",
    "\n",
    "df.to_excel(needs_excel_file, index=False)\n",
    "\n",
    "print(f\"数据已成功保存到 {needs_excel_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2dab7b0b-6ca6-4fc2-8ba3-2cd9b0faa0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "将从 生成结果/defect_analysis/致欧-2025-01-10之后VOC数据_缺陷象限分析_完整列表.txt 读取数据\n",
      "将结果保存到 生成结果/defect_analysis/致欧-2025-01-10之后VOC数据_缺陷象限分析_完整列表.xlsx\n",
      "数据已成功保存到 生成结果/defect_analysis/致欧-2025-01-10之后VOC数据_缺陷象限分析_完整列表.xlsx\n"
     ]
    }
   ],
   "source": [
    "# 从文件中读取文本内容\n",
    "#defect_file_path =  os.path.join(defect_dir , '美国站旅行袋销售数据及VOC数据_缺陷象限分析_完整列表.txt')  # 请替换为您的实际文件路径\n",
    "\n",
    "txt_files = [f for f in os.listdir(defect_dir) if f.endswith('.txt')]\n",
    "\n",
    "if not txt_files:\n",
    "    print(f\"在 {defect_dir} 文件夹中未找到任何txt文件\")\n",
    "    sys.exit(1)\n",
    "    \n",
    "# 如果找到多个txt文件，打印列表并使用第一个\n",
    "if len(txt_files) > 1:\n",
    "    print(f\"在 {defect_dir} 文件夹中找到多个txt文件:\")\n",
    "    for i, txt_file in enumerate(txt_files):\n",
    "        print(f\"{i+1}. {txt_file}\")\n",
    "    print(f\"将使用第一个文件: {txt_files[0]}\")\n",
    "\n",
    "# 获取第一个txt文件的完整路径\n",
    "txt_file_name = txt_files[0]\n",
    "defect_file_path = os.path.join(defect_dir, txt_file_name)\n",
    "\n",
    "\n",
    "try:\n",
    "    with open(defect_file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "except UnicodeDecodeError:\n",
    "    # 如果UTF-8解码失败，尝试其他编码\n",
    "    with open(defect_file_path, 'r', encoding='gbk') as file:\n",
    "        text = file.read()\n",
    "\n",
    "# 初始化列表存储提取的数据\n",
    "data = []\n",
    "\n",
    "# 定义当前象限\n",
    "current_quadrant = \"\"\n",
    "\n",
    "# 逐行解析文本\n",
    "lines = text.strip().split('\\n')\n",
    "i = 0\n",
    "while i < len(lines):\n",
    "    line = lines[i].strip()\n",
    "    \n",
    "    # 匹配象限标题\n",
    "    if line.startswith('## '):\n",
    "        quadrant_match = re.match(r'## 第(.+)象限：(.+)', line)\n",
    "        if quadrant_match:\n",
    "            current_quadrant = f\"第{quadrant_match.group(1)}象限：{quadrant_match.group(2)}\"\n",
    "    \n",
    "    # 匹配功能项\n",
    "    elif re.match(r'^\\d+\\.\\s', line):\n",
    "        feature = line[line.find('.')+1:].strip()\n",
    "        \n",
    "        # 检查下一行是否包含分数信息\n",
    "        if i+1 < len(lines):\n",
    "            scores_line = lines[i+1].strip()\n",
    "            importance_match = re.search(r'重要性分数:\\s*([\\d\\.]+)', scores_line)\n",
    "            frequency_match = re.search(r'提及频率:\\s*([\\d\\.e\\-]+)', scores_line)\n",
    "            quality_match = re.search(r'文本质量:\\s*([\\d\\.]+)', scores_line)\n",
    "            \n",
    "            # 检查下一行是否包含最终得分\n",
    "            if i+2 < len(lines):\n",
    "                final_score_line = lines[i+2].strip()\n",
    "                final_score_match = re.search(r'最终得分:\\s*([\\d\\.]+)', final_score_line)\n",
    "                \n",
    "                if importance_match and frequency_match and quality_match and final_score_match:\n",
    "                    importance = float(importance_match.group(1))\n",
    "                    frequency = float(frequency_match.group(1))\n",
    "                    quality = float(quality_match.group(1))\n",
    "                    final_score = float(final_score_match.group(1))\n",
    "                    \n",
    "                    # 添加到数据列表\n",
    "                    data.append({\n",
    "                        '象限': current_quadrant,\n",
    "                        '产品缺陷': feature,\n",
    "                        '重要性分数': importance,\n",
    "                        '提及频率': frequency,\n",
    "                        '文本质量': quality,\n",
    "                        '最终得分': final_score\n",
    "                    })\n",
    "    i += 1\n",
    "\n",
    "# 创建DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 保存为Excel文件\n",
    "#defect_excel_file =  os.path.join(defect_dir, '美国站旅行袋销售数据及VOC数据_缺陷象限分析_完整列表.xlsx')\n",
    "\n",
    "\n",
    "excel_file_name = os.path.splitext(txt_file_name)[0] + '.xlsx'\n",
    "defect_excel_file = os.path.join(defect_dir, excel_file_name)\n",
    "\n",
    "print(f\"将从 {defect_file_path} 读取数据\")\n",
    "print(f\"将结果保存到 {defect_excel_file}\")\n",
    "\n",
    "df.to_excel(defect_excel_file, index=False)\n",
    "\n",
    "print(f\"数据已成功保存到 {defect_excel_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a157fcf-d8bd-4b95-b28c-5191280d2757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lynx",
   "language": "python",
   "name": "lynx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
