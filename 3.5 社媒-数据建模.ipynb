{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9339031c-f7fb-4c8c-b83b-3c024bb699f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T10:46:08.293624Z",
     "iopub.status.busy": "2025-04-15T10:46:08.293624Z",
     "iopub.status.idle": "2025-04-15T10:46:09.618023Z",
     "shell.execute_reply": "2025-04-15T10:46:09.618023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前操作系统: Windows\n",
      "当前字体设置: ['SimHei', 'Microsoft YaHei', 'SimSun']\n"
     ]
    }
   ],
   "source": [
    "# 导入所需的所有包\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from scipy.stats import normaltest, skew, kurtosis\n",
    "from scipy.stats import skew, kurtosis, norm\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import os\n",
    "import platform\n",
    "\n",
    "# 根据操作系统设置合适的中文字体\n",
    "system = platform.system()\n",
    "if system == 'Darwin':  # macOS\n",
    "    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'Heiti TC', 'PingFang HK', 'Apple Color Emoji']\n",
    "elif system == 'Windows':\n",
    "    plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'SimSun']\n",
    "else:  # Linux或其他\n",
    "    plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'WenQuanYi Micro Hei', 'WenQuanYi Zen Hei']\n",
    "\n",
    "# 正常显示负号\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 检查字体是否设置成功\n",
    "print(f\"当前操作系统: {system}\")\n",
    "print(f\"当前字体设置: {plt.rcParams['font.sans-serif']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7f8cdf-4600-4c15-816e-82bb0f3cc6f3",
   "metadata": {},
   "source": [
    "## 数据加载和初步检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "283ce721-c943-406b-b46d-74826e23bef2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T10:46:09.618023Z",
     "iopub.status.busy": "2025-04-15T10:46:09.618023Z",
     "iopub.status.idle": "2025-04-15T10:46:09.633427Z",
     "shell.execute_reply": "2025-04-15T10:46:09.633427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提取的文件夹名: 生成结果/social_media/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Asin_List_file = \"旅行包-机会款式.xlsx\" \n",
    "\n",
    "# # 文件和目录的设置\n",
    "# input_file = Asin_List_file  # 这实际上是Excel文件\n",
    "\n",
    "# 从Excel文件名中提取基础文件夹名称\n",
    "folder_name = '生成结果/social_media/'\n",
    "#folder_name = os.path.splitext(input_file)[0]\n",
    "print(f\"提取的文件夹名: {folder_name}\")\n",
    "\n",
    "# 确保文件夹存在\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "    print(f\"已创建文件夹: {folder_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dc923b0-6cf7-4c43-b7fb-f706cd07e92c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T10:46:09.633427Z",
     "iopub.status.busy": "2025-04-15T10:46:09.633427Z",
     "iopub.status.idle": "2025-04-15T10:46:09.998588Z",
     "shell.execute_reply": "2025-04-15T10:46:09.998588Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据加载完成，共 605 行和 67 列\n",
      "从IV.txt加载了 18 个自变量\n",
      "将使用的控制变量: author_followers_cnt, author_friends_cnt\n",
      "已确认因变量'interaction_view_cnt'存在于数据中\n",
      "已确认所有控制变量存在于数据中\n",
      "已创建结果文件: 生成结果/social_media/View-模型结果.txt\n",
      "数据预览:\n",
      "                    id  title  \\\n",
      "0  1909480340126580992    NaN   \n",
      "1  1909020699747886080    NaN   \n",
      "2  1908203431765881088    NaN   \n",
      "3  1908194727209385984    NaN   \n",
      "4  1908053656731087104    NaN   \n",
      "\n",
      "                                             content  url lang  \\\n",
      "0  Metal Shoe Rack\\nUpto 24% off\\nLink for you: h...  NaN   en   \n",
      "1  @emob_ @DamnNearWhite @Tr3sMilagros @MyFirstKi...  NaN   en   \n",
      "2  J.T. Foote Adjustable Shoe Trees - Plastic \\n🛠...  NaN   en   \n",
      "3  EXVITO Metal Shoe Rack for Home – Adjustable &...  NaN   en   \n",
      "4  Closet Shoe Organizer for 24 Pairs with Adjust...  NaN   en   \n",
      "\n",
      "                     publish_time publish_time_date publish_time_time  \\\n",
      "0  Tue Apr 08 05:36:04 +0000 2025        2025-04-08          05:36:04   \n",
      "1  Sun Apr 06 23:09:37 +0000 2025        2025-04-06          23:09:37   \n",
      "2  Fri Apr 04 17:02:05 +0000 2025        2025-04-04          17:02:05   \n",
      "3  Fri Apr 04 16:27:30 +0000 2025        2025-04-04          16:27:30   \n",
      "4  Fri Apr 04 07:06:56 +0000 2025        2025-04-04          07:06:56   \n",
      "\n",
      "   is_truncated  interaction_like_cnt  ...  承重能力表达  耐用性表达  长期满意度表达  颜色选择表达  \\\n",
      "0         False                     0  ...       1      1        1       0   \n",
      "1         False                     1  ...       1      0        1       0   \n",
      "2         False                     0  ...       1      0        0       0   \n",
      "3         False                     0  ...       0      1        1       0   \n",
      "4         False                     0  ...       0      0        0       0   \n",
      "\n",
      "   季节适应性表达  品牌声誉表达  消费者信任度表达  创新功能表达  儿童友好设计表达  组合灵活性表达  \n",
      "0        1       0         1       1         0        1  \n",
      "1        1       0         1       0         1        0  \n",
      "2        0       1         1       1         0        0  \n",
      "3        1       1         0       0         0        0  \n",
      "4        0       0         0       0         0        0  \n",
      "\n",
      "[5 rows x 67 columns]\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "data_file = os.path.join(folder_name, \"数据变量语义匹配二元赋值结果.xlsx\")\n",
    "data = pd.read_excel(data_file)\n",
    "print(f\"数据加载完成，共 {len(data)} 行和 {len(data.columns)} 列\")\n",
    "\n",
    "# 修改IV文件路径\n",
    "iv_file = os.path.join(folder_name, 'IV.txt')\n",
    "with open(iv_file, 'r', encoding='utf-8') as f:\n",
    "    iv_list = f.read().splitlines()\n",
    "    iv_list = [iv.strip() for iv in iv_list if iv.strip()]  # 移除空行\n",
    "print(f\"从IV.txt加载了 {len(iv_list)} 个自变量\")\n",
    "\n",
    "# 定义因变量和控制变量\n",
    "dv_col = 'interaction_view_cnt'\n",
    "control_vars = ['author_followers_cnt', 'author_friends_cnt']\n",
    "print(f\"将使用的控制变量: {', '.join(control_vars)}\")\n",
    "\n",
    "# 检查DV列是否存在\n",
    "if dv_col not in data.columns:\n",
    "    print(f\"错误: 数据中不存在列 '{dv_col}'\")\n",
    "    print(\"数据包含的列:\", data.columns.tolist()[:10], \"...\")\n",
    "    raise ValueError(f\"找不到DV列: {dv_col}\")\n",
    "else:\n",
    "    print(f\"已确认因变量'{dv_col}'存在于数据中\")\n",
    "\n",
    "# 检查控制变量是否存在\n",
    "missing_controls = [var for var in control_vars if var not in data.columns]\n",
    "if missing_controls:\n",
    "    print(f\"错误: 以下控制变量在数据中不存在: {missing_controls}\")\n",
    "    raise ValueError(\"缺少必要的控制变量\")\n",
    "else:\n",
    "    print(\"已确认所有控制变量存在于数据中\")\n",
    "\n",
    "# 检查IV列是否都存在\n",
    "missing_ivs = [iv for iv in iv_list if iv not in data.columns]\n",
    "if missing_ivs:\n",
    "    print(f\"警告: 以下IV在数据中不存在: {missing_ivs}\")\n",
    "    iv_list = [iv for iv in iv_list if iv in data.columns]\n",
    "    print(f\"将使用剩余的 {len(iv_list)} 个IV进行建模\")\n",
    "\n",
    "if not iv_list:\n",
    "    raise ValueError(\"没有可用的IV变量进行建模\")\n",
    "\n",
    "# 修改结果文件路径\n",
    "result_file = os.path.join(folder_name, \"View-模型结果.txt\")\n",
    "with open(result_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"# 模型分析结果\\n\\n\")\n",
    "print(f\"已创建结果文件: {result_file}\")\n",
    "\n",
    "# 显示数据前几行\n",
    "print(\"数据预览:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b8dd4e-0539-4fbf-94a5-90a0b78c6cf4",
   "metadata": {},
   "source": [
    "## DV分布分析（简化模型标准）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efa87413-57da-45c6-a1bc-9781b840915a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T10:46:09.998588Z",
     "iopub.status.busy": "2025-04-15T10:46:09.998588Z",
     "iopub.status.idle": "2025-04-15T10:46:10.013677Z",
     "shell.execute_reply": "2025-04-15T10:46:10.013677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## interaction_view_cnt 分布分析结果:\n",
      "- 样本量: 605\n",
      "- 零值数量: 21\n",
      "- 零值比例: 3.4711\n",
      "- 均值: 576.2678\n",
      "- 中位数: 15.0000\n",
      "- 标准差: 1830.7616\n",
      "- 最小值: 0\n",
      "- 最大值: 16742\n",
      "- 偏度: 4.1096\n",
      "- 峰度: 19.4342\n",
      "\n",
      "## 推荐的模型: OLS\n",
      "- 变量转换: 对数转换\n",
      "- 原因: 数据中零值比例为3.47%，不超过20%，使用OLS模型。数据偏度为4.11，表现为偏态分布，对因变量进行对数转换。\n"
     ]
    }
   ],
   "source": [
    "# 分析DV的分布\n",
    "def analyze_distribution(data, col):\n",
    "    \"\"\"\n",
    "    分析变量分布并返回基本统计量和模型推荐\n",
    "    \"\"\"\n",
    "    # 提取非空数据\n",
    "    valid_data = data[col].dropna()\n",
    "    \n",
    "    # 基本统计量\n",
    "    stats_dict = {\n",
    "        \"样本量\": len(valid_data),\n",
    "        \"零值数量\": (valid_data == 0).sum(),\n",
    "        \"零值比例\": (valid_data == 0).mean() * 100,\n",
    "        \"均值\": valid_data.mean(),\n",
    "        \"中位数\": valid_data.median(),\n",
    "        \"标准差\": valid_data.std(),\n",
    "        \"最小值\": valid_data.min(),\n",
    "        \"最大值\": valid_data.max(),\n",
    "        \"偏度\": skew(valid_data),\n",
    "        \"峰度\": kurtosis(valid_data)\n",
    "    }\n",
    "\n",
    "    # 模型选择逻辑 - 根据零值比例和分布偏度\n",
    "    zero_inflated = stats_dict[\"零值比例\"] > 20  # 如果零值超过20%，使用Tobit\n",
    "    high_skew = abs(stats_dict[\"偏度\"]) > 1.0   # 如果偏度较大，使用对数转换\n",
    "    \n",
    "    model_type = \"ols\"  # 默认模型类型\n",
    "    transform_type = \"none\"  # 默认不转换\n",
    "    reason = \"\"\n",
    "    \n",
    "    if zero_inflated:\n",
    "        model_type = \"tobit\"\n",
    "        reason += f\"数据中零值比例为{stats_dict['零值比例']:.2f}%，超过20%，使用Tobit模型。\"\n",
    "        \n",
    "        if high_skew:\n",
    "            transform_type = \"log\"\n",
    "            reason += f\"数据偏度为{stats_dict['偏度']:.2f}，表现为偏态分布，对因变量进行对数转换。\"\n",
    "    else:\n",
    "        model_type = \"ols\"\n",
    "        reason += f\"数据中零值比例为{stats_dict['零值比例']:.2f}%，不超过20%，使用OLS模型。\"\n",
    "        \n",
    "        if high_skew:\n",
    "            transform_type = \"log\"\n",
    "            reason += f\"数据偏度为{stats_dict['偏度']:.2f}，表现为偏态分布，对因变量进行对数转换。\"\n",
    "    \n",
    "    return model_type, transform_type, reason, stats_dict\n",
    "\n",
    "# 对DV进行分布分析\n",
    "model_type, transform_type, reason, dv_stats = analyze_distribution(data, dv_col)\n",
    "\n",
    "# 显示分析结果\n",
    "print(f\"\\n## {dv_col} 分布分析结果:\")\n",
    "for key, value in dv_stats.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"- {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"- {key}: {value}\")\n",
    "\n",
    "print(f\"\\n## 推荐的模型: {model_type.upper()}\")\n",
    "print(f\"- 变量转换: {'对数转换' if transform_type == 'log' else '不转换'}\")\n",
    "print(f\"- 原因: {reason}\")\n",
    "\n",
    "# 将结果保存到文件\n",
    "with open(result_file, 'a', encoding='utf-8') as f:\n",
    "    f.write(f\"## {dv_col} 分布分析\\n\\n\")\n",
    "    for key, value in dv_stats.items():\n",
    "        if isinstance(value, float):\n",
    "            f.write(f\"- {key}: {value:.4f}\\n\")\n",
    "        else:\n",
    "            f.write(f\"- {key}: {value}\\n\")\n",
    "    \n",
    "    f.write(f\"\\n## 模型选择\\n\\n\")\n",
    "    f.write(f\"- 推荐的模型类型: {model_type.upper()}\\n\")\n",
    "    f.write(f\"- 变量转换: {'对数转换' if transform_type == 'log' else '不转换'}\\n\")\n",
    "    f.write(f\"- 选择原因: {reason}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82877530-0c32-459c-a16f-d2616318cb34",
   "metadata": {},
   "source": [
    "## 数据预处理和模型准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f91e72a-700a-40d1-8c0e-d470a6df1fe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T10:46:10.013677Z",
     "iopub.status.busy": "2025-04-15T10:46:10.013677Z",
     "iopub.status.idle": "2025-04-15T10:46:10.043864Z",
     "shell.execute_reply": "2025-04-15T10:46:10.043864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预处理后的数据: 605 行 × 21 列\n",
      "警告: interaction_view_cnt 的最小值为 0，包含零值或负值\n",
      "将使用log(1+x)转换\n",
      "已创建对数转换变量: log_interaction_view_cnt\n",
      "回归公式:\n",
      "log_interaction_view_cnt ~ 安全性需求表达 + 空间效率表达 + 环保材质偏好 + 组装便捷性表达 + 设计美感表达 + 层高可调节性表达 + 防尘功能表达 + 价格表达 + 多功能性表达 + 便携性表达 + 承重能力表达 + 耐用性表达 + 颜色选择表达 + 季节适应性表达 + 品牌声誉表达 + 创新功能表达 + 儿童友好设计表达 + 组合灵活性表达 + author_followers_cnt + author_friends_cnt\n",
      "\n",
      "多重共线性检验 (VIF):\n",
      "VIF > 10 表示可能存在严重的多重共线性问题\n",
      "                      变量       VIF\n",
      "12                颜色选择表达  5.844991\n",
      "4                 设计美感表达  5.432510\n",
      "0                安全性需求表达  3.560953\n",
      "8                 多功能性表达  3.394563\n",
      "11                 耐用性表达  3.326069\n",
      "3                组装便捷性表达  3.258193\n",
      "2                 环保材质偏好  3.220954\n",
      "10                承重能力表达  3.209544\n",
      "13               季节适应性表达  3.190966\n",
      "9                  便携性表达  3.183719\n",
      "17               组合灵活性表达  3.163847\n",
      "1                 空间效率表达  2.904204\n",
      "15                创新功能表达  2.775960\n",
      "14                品牌声誉表达  2.485333\n",
      "6                 防尘功能表达  2.375646\n",
      "16              儿童友好设计表达  2.106301\n",
      "5               层高可调节性表达  1.919452\n",
      "7                   价格表达  1.672822\n",
      "19    author_friends_cnt  1.279311\n",
      "18  author_followers_cnt  1.199435\n"
     ]
    }
   ],
   "source": [
    "# 准备建模数据\n",
    "all_predictors = iv_list + control_vars\n",
    "model_data = data[[dv_col] + all_predictors].copy()\n",
    "model_data = model_data.dropna()  # 移除有缺失值的行\n",
    "print(f\"预处理后的数据: {len(model_data)} 行 × {len(model_data.columns)} 列\")\n",
    "\n",
    "# 处理因变量转换\n",
    "transformed_dv = dv_col\n",
    "if transform_type == \"log\":\n",
    "    # 检查零值和负值\n",
    "    min_value = model_data[dv_col].min()\n",
    "    if min_value <= 0:\n",
    "        print(f\"警告: {dv_col} 的最小值为 {min_value}，包含零值或负值\")\n",
    "        print(\"将使用log(1+x)转换\")\n",
    "        model_data[f'log_{dv_col}'] = np.log1p(model_data[dv_col])\n",
    "    else:\n",
    "        model_data[f'log_{dv_col}'] = np.log(model_data[dv_col])\n",
    "    transformed_dv = f'log_{dv_col}'\n",
    "    print(f\"已创建对数转换变量: {transformed_dv}\")\n",
    "else:\n",
    "    print(f\"使用原始变量: {transformed_dv}\")\n",
    "\n",
    "# 构建公式并显示\n",
    "formula = f\"{transformed_dv} ~ \" + \" + \".join(all_predictors)\n",
    "print(f\"回归公式:\")\n",
    "print(formula)\n",
    "\n",
    "# 检查多重共线性\n",
    "if len(all_predictors) > 1:\n",
    "    X = model_data[all_predictors]\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"变量\"] = X.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    print(\"\\n多重共线性检验 (VIF):\")\n",
    "    print(\"VIF > 10 表示可能存在严重的多重共线性问题\")\n",
    "    print(vif_data.sort_values(\"VIF\", ascending=False))\n",
    "\n",
    "    with open(result_file, 'a', encoding='utf-8') as f:\n",
    "        f.write(\"## 多重共线性检验 (VIF)\\n\\n\")\n",
    "        f.write(\"VIF > 10 表示可能存在严重的多重共线性问题\\n\\n\")\n",
    "        f.write(\"| 变量 | VIF |\\n\")\n",
    "        f.write(\"|------|------|\\n\")\n",
    "        for index, row in vif_data.iterrows():\n",
    "            f.write(f\"| {row['变量']} | {row['VIF']:.4f} |\\n\")\n",
    "        f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780e4c66-0309-4b61-949d-24e8a97f9303",
   "metadata": {},
   "source": [
    "## 模型拟合与结果输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "035c317f-d4c2-4d7b-ba0f-06feb29322ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T10:46:10.043864Z",
     "iopub.status.busy": "2025-04-15T10:46:10.043864Z",
     "iopub.status.idle": "2025-04-15T10:46:10.105433Z",
     "shell.execute_reply": "2025-04-15T10:46:10.105433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始拟合OLS模型...\n",
      "\n",
      "OLS回归结果:\n",
      "                               OLS Regression Results                               \n",
      "====================================================================================\n",
      "Dep. Variable:     log_interaction_view_cnt   R-squared:                       0.361\n",
      "Model:                                  OLS   Adj. R-squared:                  0.339\n",
      "Method:                       Least Squares   F-statistic:                     16.46\n",
      "Date:                      Tue, 15 Apr 2025   Prob (F-statistic):           1.08e-44\n",
      "Time:                              18:46:10   Log-Likelihood:                -1183.8\n",
      "No. Observations:                       605   AIC:                             2410.\n",
      "Df Residuals:                           584   BIC:                             2502.\n",
      "Df Model:                                20                                         \n",
      "Covariance Type:                  nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept                3.2408      0.214     15.161      0.000       2.821       3.661\n",
      "安全性需求表达                  0.2700      0.212      1.276      0.202      -0.146       0.685\n",
      "空间效率表达                   0.1643      0.195      0.842      0.400      -0.219       0.548\n",
      "环保材质偏好                  -0.1986      0.203     -0.979      0.328      -0.597       0.200\n",
      "组装便捷性表达                  0.3338      0.202      1.649      0.100      -0.064       0.731\n",
      "设计美感表达                  -0.3665      0.261     -1.403      0.161      -0.879       0.146\n",
      "层高可调节性表达                 0.4666      0.160      2.917      0.004       0.152       0.781\n",
      "防尘功能表达                  -0.2475      0.173     -1.429      0.153      -0.588       0.093\n",
      "价格表达                     0.3553      0.191      1.859      0.064      -0.020       0.731\n",
      "多功能性表达                  -0.3923      0.207     -1.897      0.058      -0.798       0.014\n",
      "便携性表达                   -0.1496      0.200     -0.748      0.454      -0.542       0.243\n",
      "承重能力表达                  -0.2235      0.203     -1.099      0.272      -0.623       0.176\n",
      "耐用性表达                    0.3449      0.204      1.688      0.092      -0.056       0.746\n",
      "颜色选择表达                  -0.1530      0.270     -0.567      0.571      -0.683       0.377\n",
      "季节适应性表达                 -0.1596      0.202     -0.790      0.430      -0.556       0.237\n",
      "品牌声誉表达                   0.3055      0.181      1.685      0.093      -0.051       0.662\n",
      "创新功能表达                  -0.1577      0.190     -0.828      0.408      -0.532       0.216\n",
      "儿童友好设计表达                -0.1951      0.167     -1.168      0.243      -0.523       0.133\n",
      "组合灵活性表达                 -0.2943      0.199     -1.482      0.139      -0.684       0.096\n",
      "author_followers_cnt  5.124e-06   3.46e-07     14.790      0.000    4.44e-06     5.8e-06\n",
      "author_friends_cnt   -1.446e-06   4.09e-05     -0.035      0.972   -8.18e-05    7.89e-05\n",
      "==============================================================================\n",
      "Omnibus:                      120.501   Durbin-Watson:                   1.664\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1937.433\n",
      "Skew:                          -0.346   Prob(JB):                         0.00\n",
      "Kurtosis:                      11.740   Cond. No.                     1.11e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.11e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "模型解读:\n",
      "- 模型解释力 (R²): 0.3605\n",
      "- 调整后的R²: 0.3386\n",
      "- 模型整体显著性: F(20,584)=16.4626, p=0.000000\n",
      "  结论: 模型整体上显著\n",
      "\n",
      "显著的变量 (p < 0.05): 2/20\n",
      "\n",
      "显著的自变量: 1/18\n",
      "- 层高可调节性表达: 系数=0.4666, p=0.003674\n",
      "\n",
      "显著的控制变量: 1/2\n",
      "- author_followers_cnt: 系数=0.0000, p=0.000000\n",
      "\n",
      "模型解读:\n",
      "- 模型解释力 (R²): 0.3605\n",
      "- 调整后的R²: 0.3386\n",
      "- 模型整体显著性: F(20,584)=16.4626, p=0.000000\n",
      "  结论: 模型整体上显著\n",
      "\n",
      "显著的变量 (p < 0.05): 2/20\n",
      "\n",
      "显著的自变量: 1/18\n",
      "- 层高可调节性表达: 系数=0.4666, p=0.003674\n",
      "\n",
      "显著的控制变量: 1/2\n",
      "- author_followers_cnt: 系数=0.0000, p=0.000000\n",
      "\n",
      "所有分析结果已保存到 生成结果/social_media/View-模型结果.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_27916\\1668281642.py:212: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  coef = results.params[idx + 1]  # +1 to skip intercept\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_27916\\1668281642.py:213: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  p = p_values[idx]\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_27916\\1668281642.py:220: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  coef = results.params[idx + 1]  # +1 to skip intercept\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_27916\\1668281642.py:221: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  p = p_values[idx]\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_27916\\1668281642.py:272: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  coef = results.params[idx + 1]  # +1 to skip intercept\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_27916\\1668281642.py:273: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  p = p_values[idx]\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_27916\\1668281642.py:280: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  coef = results.params[idx + 1]  # +1 to skip intercept\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_27916\\1668281642.py:281: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  p = p_values[idx]\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_27916\\1668281642.py:308: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  coef = results.params[idx + 1]\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_27916\\1668281642.py:309: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  p = p_values[idx]\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_27916\\1668281642.py:315: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  coef = results.params[idx + 1]\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_27916\\1668281642.py:316: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  p = p_values[idx]\n"
     ]
    }
   ],
   "source": [
    "print(f\"开始拟合{model_type.upper()}模型...\")\n",
    "\n",
    "if model_type == \"tobit\":\n",
    "    # 尝试不同的导入方式\n",
    "    try:\n",
    "        # 尝试从truncated_model模块导入\n",
    "        from statsmodels.discrete.truncated_model import Tobit\n",
    "        \n",
    "        # 准备数据\n",
    "        y = model_data[transformed_dv].values\n",
    "        X = sm.add_constant(model_data[all_predictors])\n",
    "        \n",
    "        print(\"使用statsmodels.discrete.truncated_model中的Tobit模型...\")\n",
    "        tobit_model = Tobit(y, X, left=0)\n",
    "        results = tobit_model.fit(method='powell', disp=0, maxiter=10000)\n",
    "        \n",
    "    except (ImportError, AttributeError):\n",
    "        # 如果上述导入失败，使用censored_model模块\n",
    "        try:\n",
    "            from statsmodels.regression.censored_model import Tobit\n",
    "            \n",
    "            # 准备数据\n",
    "            y = model_data[transformed_dv].values\n",
    "            X = sm.add_constant(model_data[all_predictors])\n",
    "            \n",
    "            print(\"使用statsmodels.regression.censored_model中的Tobit模型...\")\n",
    "            tobit_model = Tobit(y, X, left=0)\n",
    "            results = tobit_model.fit(method='powell', disp=0, maxiter=10000)\n",
    "            \n",
    "        except (ImportError, AttributeError):\n",
    "            # 如果上述方法都失败，使用改进的自定义实现\n",
    "            print(\"使用改进的自定义Tobit模型实现...\")\n",
    "            from scipy.stats import norm\n",
    "            from scipy import optimize\n",
    "            from statsmodels.regression.linear_model import OLS\n",
    "            from statsmodels.base.model import GenericLikelihoodModel\n",
    "            \n",
    "            class TobitModel(GenericLikelihoodModel):\n",
    "                def __init__(self, endog, exog, left=0, **kwds):\n",
    "                    self.left = left\n",
    "                    super(TobitModel, self).__init__(endog, exog, **kwds)\n",
    "                \n",
    "                def loglikeobs(self, params):\n",
    "                    beta = params[:-1]\n",
    "                    sigma = np.abs(params[-1])  # 确保sigma为正\n",
    "                    \n",
    "                    q = self.endog\n",
    "                    x = self.exog\n",
    "                    \n",
    "                    # 计算条件期望\n",
    "                    mu = np.dot(x, beta)\n",
    "                    \n",
    "                    # 分别计算截尾和非截尾值的对数似然\n",
    "                    censored_mask = (q <= self.left)\n",
    "                    z = (self.left - mu) / sigma\n",
    "                    \n",
    "                    ll_censored = censored_mask * norm.logcdf(z)\n",
    "                    \n",
    "                    non_censored_mask = ~censored_mask\n",
    "                    ll_non_censored = non_censored_mask * (\n",
    "                        -np.log(sigma) + \n",
    "                        norm.logpdf((q - mu) / sigma)\n",
    "                    )\n",
    "                    \n",
    "                    # 处理可能的数值问题\n",
    "                    result = ll_censored + ll_non_censored\n",
    "                    # 替换无效值\n",
    "                    result = np.where(np.isnan(result) | np.isinf(result), -1e10, result)\n",
    "                    \n",
    "                    return result\n",
    "                \n",
    "                def nloglikeobs(self, params):\n",
    "                    \"\"\"负对数似然\"\"\"\n",
    "                    return -self.loglikeobs(params)\n",
    "                \n",
    "                def fit(self, start_params=None, method='bfgs', maxiter=50000, **kwds):\n",
    "                    \"\"\"添加更多优化方法选项和更好的初始值策略\"\"\"\n",
    "                    if start_params is None:\n",
    "                        # 使用OLS估计获取更稳定的初始值\n",
    "                        ols_model = OLS(\n",
    "                            np.where(self.endog <= self.left, self.left, self.endog),\n",
    "                            self.exog\n",
    "                        )\n",
    "                        ols_res = ols_model.fit()\n",
    "                        # 使用残差的标准差作为sigma的初始值\n",
    "                        start_params = np.append(ols_res.params, np.std(ols_res.resid))\n",
    "                    \n",
    "                    # 添加更多优化选项\n",
    "                    if 'options' not in kwds:\n",
    "                        kwds['options'] = {}\n",
    "                    kwds['options']['maxiter'] = maxiter\n",
    "                    \n",
    "                    # 添加容错设置\n",
    "                    try:\n",
    "                        return super(TobitModel, self).fit(\n",
    "                            start_params=start_params,\n",
    "                            method=method, \n",
    "                            **kwds\n",
    "                        )\n",
    "                    except Exception as e:\n",
    "                        print(f\"首次优化失败: {str(e)}，尝试备用方法...\")\n",
    "                        try:\n",
    "                            # 尝试Powell方法\n",
    "                            return super(TobitModel, self).fit(\n",
    "                                start_params=start_params,\n",
    "                                method='powell',\n",
    "                                options={'maxiter': 100000, 'ftol': 1e-8, 'xtol': 1e-8},\n",
    "                                **kwds\n",
    "                            )\n",
    "                        except:\n",
    "                            print(\"所有优化方法失败，尝试最简单的优化设置...\")\n",
    "                            return super(TobitModel, self).fit(\n",
    "                                start_params=start_params,\n",
    "                                method='nm',\n",
    "                                options={'maxiter': 100000},\n",
    "                                **kwds\n",
    "                            )\n",
    "            \n",
    "            # 准备数据 - 修改数据准备部分以避免AttributeError\n",
    "            y = model_data[transformed_dv].values\n",
    "            X_df = sm.add_constant(model_data[all_predictors])  # 保持DataFrame格式\n",
    "            X_array = X_df.values  # 数组版本用于拟合\n",
    "            X_columns = X_df.columns.tolist()  # 保存列名供后续使用\n",
    "            \n",
    "            # 拟合Tobit模型，尝试多种方法\n",
    "            tobit_model = TobitModel(y, X_array, left=0)\n",
    "            try:\n",
    "                # 首先尝试Nelder-Mead方法\n",
    "                results = tobit_model.fit(method='nm', disp=0, maxiter=50000)\n",
    "            except:\n",
    "                try:\n",
    "                    # 如果失败，尝试BFGS方法\n",
    "                    results = tobit_model.fit(method='bfgs', disp=0, maxiter=50000)\n",
    "                except:\n",
    "                    # 最后尝试Powell方法\n",
    "                    results = tobit_model.fit(method='powell', disp=0, maxiter=50000)\n",
    "    \n",
    "    # 打印结果\n",
    "    print(\"\\nTobit模型结果:\")\n",
    "    print(results.summary())\n",
    "    \n",
    "else:  # 使用OLS模型 - 保持不变\n",
    "    # 创建并拟合模型\n",
    "    model = smf.ols(formula=formula, data=model_data)\n",
    "    results = model.fit()\n",
    "    \n",
    "    # 显示结果摘要\n",
    "    print(\"\\nOLS回归结果:\")\n",
    "    print(results.summary())\n",
    "\n",
    "# 保存结果\n",
    "with open(result_file, 'a', encoding='utf-8') as f:\n",
    "    f.write(f\"## {model_type.upper()}回归结果\\n\\n\")\n",
    "    f.write(f\"被解释变量: {transformed_dv}\\n\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(str(results.summary()))\n",
    "    f.write(\"\\n\\n\\n\")\n",
    "\n",
    "# 模型结果解读\n",
    "print(\"\\n模型解读:\")\n",
    "\n",
    "if model_type == \"ols\":\n",
    "    # OLS模型特有的解读 - 保持不变\n",
    "    print(f\"- 模型解释力 (R²): {results.rsquared:.4f}\")\n",
    "    print(f\"- 调整后的R²: {results.rsquared_adj:.4f}\")\n",
    "    print(f\"- 模型整体显著性: F({results.df_model:.0f},{results.df_resid:.0f})={results.fvalue:.4f}, p={results.f_pvalue:.6f}\")\n",
    "    \n",
    "    if results.f_pvalue < 0.05:\n",
    "        print(\"  结论: 模型整体上显著\")\n",
    "    else:\n",
    "        print(\"  结论: 模型整体上不显著\")\n",
    "    \n",
    "    # 获取显著的变量\n",
    "    p_values = results.pvalues[1:]  # 跳过截距\n",
    "    var_names = all_predictors\n",
    "    \n",
    "else:  # Tobit模型 - 修改此部分以处理可能的NaN问题\n",
    "    print(\"- Tobit模型统计量:\")\n",
    "    print(f\"  - 对数似然值: {results.llf:.4f}\")\n",
    "    print(f\"  - AIC: {results.aic:.4f}\")\n",
    "    print(f\"  - BIC: {results.bic:.4f}\")\n",
    "    \n",
    "    # 安全获取Tobit模型的系数和p值\n",
    "    if hasattr(results, 'pvalues') and not np.all(np.isnan(results.pvalues)):\n",
    "        p_values = results.pvalues[1:-1]  # 跳过截距和sigma\n",
    "    else:\n",
    "        print(\"警告: p值计算失败，将使用系数作为显著性的近似指标\")\n",
    "        # 使用系数作为显著性的近似指标\n",
    "        coefs = results.params[1:-1]\n",
    "        se = np.ones_like(coefs) * 0.05  # 假设标准误为0.05\n",
    "        p_values = 2 * (1 - norm.cdf(np.abs(coefs / se)))\n",
    "    \n",
    "    # 在自定义Tobit中X_columns已定义，在statsmodels版本中需要定义\n",
    "    if 'X_columns' not in locals():\n",
    "        X_columns = model_data[all_predictors].columns.tolist()\n",
    "        X_columns = ['const'] + X_columns\n",
    "    \n",
    "    var_names = X_columns[1:-1] if model_type == \"tobit\" else X_columns[1:]  # 适应不同情况\n",
    "\n",
    "# 显著变量分析（对两种模型通用）\n",
    "significant_mask = p_values < 0.05\n",
    "significant_vars = [var for var, sig in zip(var_names, significant_mask) if sig]\n",
    "print(f\"\\n显著的变量 (p < 0.05): {len(significant_vars)}/{len(var_names)}\")\n",
    "\n",
    "iv_significant = [var for var in significant_vars if var in iv_list]\n",
    "ctrl_significant = [var for var in significant_vars if var in control_vars]\n",
    "\n",
    "# 显示显著的自变量\n",
    "print(f\"\\n显著的自变量: {len(iv_significant)}/{len(iv_list)}\")\n",
    "for var in iv_significant:\n",
    "    idx = var_names.index(var)\n",
    "    coef = results.params[idx + 1]  # +1 to skip intercept\n",
    "    p = p_values[idx]\n",
    "    print(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\")\n",
    "\n",
    "# 显示显著的控制变量\n",
    "print(f\"\\n显著的控制变量: {len(ctrl_significant)}/{len(control_vars)}\")\n",
    "for var in ctrl_significant:\n",
    "    idx = var_names.index(var)\n",
    "    coef = results.params[idx + 1]  # +1 to skip intercept\n",
    "    p = p_values[idx]\n",
    "    print(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\")\n",
    "\n",
    "# 保存结果\n",
    "with open(result_file, 'a', encoding='utf-8') as f:\n",
    "    f.write(f\"## {model_type.upper()}回归结果\\n\\n\")\n",
    "    f.write(f\"被解释变量: {transformed_dv}\\n\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(str(results.summary()))\n",
    "    f.write(\"\\n\\n\\n\")\n",
    "\n",
    "# 模型结果解读\n",
    "print(\"\\n模型解读:\")\n",
    "\n",
    "if model_type == \"ols\":\n",
    "    # OLS模型特有的解读\n",
    "    print(f\"- 模型解释力 (R²): {results.rsquared:.4f}\")\n",
    "    print(f\"- 调整后的R²: {results.rsquared_adj:.4f}\")\n",
    "    print(f\"- 模型整体显著性: F({results.df_model:.0f},{results.df_resid:.0f})={results.fvalue:.4f}, p={results.f_pvalue:.6f}\")\n",
    "    \n",
    "    if results.f_pvalue < 0.05:\n",
    "        print(\"  结论: 模型整体上显著\")\n",
    "    else:\n",
    "        print(\"  结论: 模型整体上不显著\")\n",
    "    \n",
    "    # 获取显著的变量\n",
    "    p_values = results.pvalues[1:]  # 跳过截距\n",
    "    var_names = all_predictors\n",
    "    \n",
    "else:  # Tobit模型\n",
    "    print(\"- Tobit模型统计量:\")\n",
    "    print(f\"  - 对数似然值: {results.llf:.4f}\")\n",
    "    print(f\"  - AIC: {results.aic:.4f}\")\n",
    "    print(f\"  - BIC: {results.bic:.4f}\")\n",
    "    \n",
    "    # Tobit模型中获取系数和p值\n",
    "    p_values = results.pvalues[1:-1]  # 跳过截距和sigma\n",
    "    var_names = list(X.columns[1:])  # 跳过常数项\n",
    "\n",
    "# 显著变量分析（对两种模型通用）\n",
    "significant_mask = p_values < 0.05\n",
    "significant_vars = [var for var, sig in zip(var_names, significant_mask) if sig]\n",
    "print(f\"\\n显著的变量 (p < 0.05): {len(significant_vars)}/{len(var_names)}\")\n",
    "\n",
    "iv_significant = [var for var in significant_vars if var in iv_list]\n",
    "ctrl_significant = [var for var in significant_vars if var in control_vars]\n",
    "\n",
    "# 显示显著的自变量\n",
    "print(f\"\\n显著的自变量: {len(iv_significant)}/{len(iv_list)}\")\n",
    "for var in iv_significant:\n",
    "    idx = var_names.index(var)\n",
    "    coef = results.params[idx + 1]  # +1 to skip intercept\n",
    "    p = p_values[idx]\n",
    "    print(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\")\n",
    "\n",
    "# 显示显著的控制变量\n",
    "print(f\"\\n显著的控制变量: {len(ctrl_significant)}/{len(control_vars)}\")\n",
    "for var in ctrl_significant:\n",
    "    idx = var_names.index(var)\n",
    "    coef = results.params[idx + 1]  # +1 to skip intercept\n",
    "    p = p_values[idx]\n",
    "    print(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\")\n",
    "\n",
    "# 保存解读结果\n",
    "with open(result_file, 'a', encoding='utf-8') as f:\n",
    "    f.write(\"## 模型结果解读\\n\\n\")\n",
    "    \n",
    "    if model_type == \"ols\":\n",
    "        f.write(f\"- 模型解释力 (R²): {results.rsquared:.4f}\\n\")\n",
    "        f.write(f\"- 调整后的R²: {results.rsquared_adj:.4f}\\n\")\n",
    "        f.write(f\"- 模型整体显著性: F({results.df_model:.0f},{results.df_resid:.0f})={results.fvalue:.4f}, p={results.f_pvalue:.6f}\\n\")\n",
    "        \n",
    "        if results.f_pvalue < 0.05:\n",
    "            f.write(\"  结论: 模型整体上显著\\n\\n\")\n",
    "        else:\n",
    "            f.write(\"  结论: 模型整体上不显著\\n\\n\")\n",
    "    else:\n",
    "        f.write(\"- Tobit模型统计量:\\n\")\n",
    "        f.write(f\"  - 对数似然值: {results.llf:.4f}\\n\")\n",
    "        f.write(f\"  - AIC: {results.aic:.4f}\\n\")\n",
    "        f.write(f\"  - BIC: {results.bic:.4f}\\n\\n\")\n",
    "    \n",
    "    f.write(f\"显著的变量 (p < 0.05): {len(significant_vars)}/{len(var_names)}\\n\\n\")\n",
    "    \n",
    "    f.write(f\"显著的自变量: {len(iv_significant)}/{len(iv_list)}\\n\")\n",
    "    for var in iv_significant:\n",
    "        idx = var_names.index(var)\n",
    "        coef = results.params[idx + 1]\n",
    "        p = p_values[idx]\n",
    "        f.write(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\\n\")\n",
    "    \n",
    "    f.write(f\"\\n显著的控制变量: {len(ctrl_significant)}/{len(control_vars)}\\n\")\n",
    "    for var in ctrl_significant:\n",
    "        idx = var_names.index(var)\n",
    "        coef = results.params[idx + 1]\n",
    "        p = p_values[idx]\n",
    "        f.write(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\\n\")\n",
    "\n",
    "print(f\"\\n所有分析结果已保存到 {result_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dd41c7-6e8a-4a61-bbd1-15c6152a5efc",
   "metadata": {},
   "source": [
    "## 系数归一化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6771c313-7bd5-42f0-b68a-65e6240f87a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T10:46:10.105433Z",
     "iopub.status.busy": "2025-04-15T10:46:10.105433Z",
     "iopub.status.idle": "2025-04-15T10:46:10.120464Z",
     "shell.execute_reply": "2025-04-15T10:46:10.120464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始归一化系数分析...\n",
      "\n",
      "归一化后的系数 (按绝对值排序):\n",
      "-----------------------------------\n",
      "总计 2 个有效变量, 显著 (p<0.05)\n",
      "-----------------------------------\n",
      "\n",
      "自变量:\n",
      "层高可调节性表达: 0.4666 (归一化: 1.0000, 100.00%)*\n",
      "\n",
      "控制变量:\n",
      "author_followers_cnt: 0.0000 (归一化: 0.0000, 0.00%)*\n",
      "-----------------------------------\n",
      "* 标记表示在0.05水平上显著\n",
      "\n",
      "结果已保存到 生成结果/social_media/View-归一化的模型结果.txt\n"
     ]
    }
   ],
   "source": [
    "# 归一化显著系数并输出结果\n",
    "def normalize_significant_coefficients(results, iv_list, control_vars=None, model_type=\"ols\", alpha=0.05):\n",
    "    \"\"\"\n",
    "    归一化显著变量的系数，删除NaN值，按绝对值大小排序并输出结果\n",
    "    \n",
    "    参数:\n",
    "    - results: 回归结果对象\n",
    "    - iv_list: 自变量列表\n",
    "    - control_vars: 控制变量列表，默认为None\n",
    "    - model_type: 模型类型，\"ols\"或\"tobit\"\n",
    "    - alpha: 显著性水平，默认0.05\n",
    "    \"\"\"\n",
    "    if control_vars is None:\n",
    "        control_vars = []\n",
    "    \n",
    "    all_vars = iv_list + control_vars\n",
    "    \n",
    "    # 获取系数和p值 - 需要考虑不同模型类型\n",
    "    if model_type.lower() == \"ols\":\n",
    "        # OLS模型 - 跳过截距\n",
    "        coefs = results.params[1:len(all_vars)+1]\n",
    "        p_values = results.pvalues[1:len(all_vars)+1]\n",
    "    else:\n",
    "        # Tobit模型 - 跳过截距和sigma\n",
    "        coefs = results.params[1:len(all_vars)+1]\n",
    "        p_values = results.pvalues[1:len(all_vars)+1]\n",
    "    \n",
    "    # 创建DataFrame\n",
    "    coef_df = pd.DataFrame({\n",
    "        '变量': all_vars,\n",
    "        '系数': coefs,\n",
    "        'p值': p_values,\n",
    "        '变量类型': ['自变量' if var in iv_list else '控制变量' for var in all_vars]\n",
    "    })\n",
    "    \n",
    "    # 过滤掉NaN系数和非显著的变量\n",
    "    valid_coef_df = coef_df.dropna(subset=['系数'])\n",
    "    sig_coef_df = valid_coef_df[valid_coef_df['p值'] < alpha].copy()\n",
    "    \n",
    "    # 如果没有显著变量，则报告所有有效变量\n",
    "    if len(sig_coef_df) == 0:\n",
    "        print(\"注意: 没有显著的变量 (p < 0.05)，将使用所有非NaN系数变量\")\n",
    "        sig_coef_df = valid_coef_df.copy()\n",
    "    \n",
    "    # 如果没有有效系数，退出\n",
    "    if len(sig_coef_df) == 0:\n",
    "        print(\"警告: 没有有效的系数，无法进行归一化\")\n",
    "        return None\n",
    "    \n",
    "    # 计算系数的绝对值\n",
    "    sig_coef_df['系数绝对值'] = sig_coef_df['系数'].abs()\n",
    "    \n",
    "    # 归一化系数\n",
    "    total_abs = sig_coef_df['系数绝对值'].sum()\n",
    "    sig_coef_df['归一化系数'] = sig_coef_df['系数'] / total_abs\n",
    "    sig_coef_df['归一化系数绝对值'] = sig_coef_df['系数绝对值'] / total_abs\n",
    "    sig_coef_df['归一化系数百分比'] = sig_coef_df['归一化系数绝对值'] * 100\n",
    "    \n",
    "    # 按系数绝对值排序\n",
    "    sig_coef_df = sig_coef_df.sort_values('系数绝对值', ascending=False)\n",
    "    \n",
    "    # 显示结果\n",
    "    print(\"\\n归一化后的系数 (按绝对值排序):\")\n",
    "    print(\"-----------------------------------\")\n",
    "    significant_str = \"显著 (p<0.05)\" if len(sig_coef_df[sig_coef_df['p值'] < alpha]) > 0 else \"无显著变量\"\n",
    "    print(f\"总计 {len(sig_coef_df)} 个有效变量, {significant_str}\")\n",
    "    print(\"-----------------------------------\")\n",
    "    \n",
    "    # 先显示自变量，再显示控制变量\n",
    "    for var_type in ['自变量', '控制变量']:\n",
    "        type_df = sig_coef_df[sig_coef_df['变量类型'] == var_type]\n",
    "        if len(type_df) > 0:\n",
    "            print(f\"\\n{var_type}:\")\n",
    "            for _, row in type_df.iterrows():\n",
    "                sig_mark = \"*\" if row['p值'] < alpha else \"\"\n",
    "                print(f\"{row['变量']}: {row['系数']:.4f} (归一化: {row['归一化系数']:.4f}, {row['归一化系数百分比']:.2f}%){sig_mark}\")\n",
    "    \n",
    "    print(\"-----------------------------------\")\n",
    "    print(\"* 标记表示在0.05水平上显著\")\n",
    "    \n",
    "    # 保存到文件\n",
    "    output_file = os.path.join(folder_name, \"View-归一化的模型结果.txt\")\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"# {model_type.upper()} 模型归一化后的系数 (按绝对值排序)\\n\\n\")\n",
    "        f.write(\"-----------------------------------\\n\")\n",
    "        f.write(f\"总计 {len(sig_coef_df)} 个有效变量, {significant_str}\\n\")\n",
    "        f.write(\"-----------------------------------\\n\\n\")\n",
    "        \n",
    "        # 添加总表\n",
    "        f.write(\"| 变量 | 变量类型 | 系数 | p值 | 归一化系数 | 归一化百分比 | 显著性 |\\n\")\n",
    "        f.write(\"|------|---------|------|------|------------|------------|--------|\\n\")\n",
    "        \n",
    "        for _, row in sig_coef_df.iterrows():\n",
    "            sig = \"是\" if row['p值'] < alpha else \"否\"\n",
    "            f.write(f\"| {row['变量']} | {row['变量类型']} | {row['系数']:.4f} | {row['p值']:.4f} | {row['归一化系数']:.4f} | {row['归一化系数百分比']:.2f}% | {sig} |\\n\")\n",
    "        \n",
    "        f.write(\"\\n\\n## 详细分析\\n\\n\")\n",
    "        \n",
    "        # 先显示自变量，再显示控制变量\n",
    "        for var_type in ['自变量', '控制变量']:\n",
    "            type_df = sig_coef_df[sig_coef_df['变量类型'] == var_type]\n",
    "            if len(type_df) > 0:\n",
    "                f.write(f\"### {var_type}\\n\\n\")\n",
    "                \n",
    "                for _, row in type_df.iterrows():\n",
    "                    sig_symbol = \"*\" if row['p值'] < alpha else \"\"\n",
    "                    direction = \"正向\" if row['系数'] > 0 else \"负向\"\n",
    "                    f.write(f\"#### {row['变量']}{sig_symbol}\\n\\n\")\n",
    "                    f.write(f\"- 系数: {row['系数']:.4f}\\n\")\n",
    "                    f.write(f\"- p值: {row['p值']:.4f}\\n\")\n",
    "                    f.write(f\"- 影响方向: {direction}\\n\")\n",
    "                    f.write(f\"- 归一化系数: {row['归一化系数']:.4f}\\n\")\n",
    "                    f.write(f\"- 归一化百分比: {row['归一化系数百分比']:.2f}%\\n\")\n",
    "                    f.write(f\"- 是否显著: {'是' if row['p值'] < alpha else '否'}\\n\\n\")\n",
    "        \n",
    "        f.write(\"-----------------------------------\\n\")\n",
    "        f.write(\"* 标记表示在0.05水平上显著\\n\")\n",
    "    \n",
    "    print(f\"\\n结果已保存到 {output_file}\")\n",
    "    \n",
    "    return sig_coef_df\n",
    "# 调用归一化函数\n",
    "print(\"\\n开始归一化系数分析...\")\n",
    "normalized_coefs = normalize_significant_coefficients(\n",
    "    results=results,\n",
    "    iv_list=iv_list,\n",
    "    control_vars=control_vars,\n",
    "    model_type=model_type,\n",
    "    alpha=0.05\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0c52ae-6351-44fa-8b5f-f7c653edba7e",
   "metadata": {},
   "source": [
    "## 其他变量分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7e46d5-c7e8-4c26-8b43-b2944f9a656b",
   "metadata": {},
   "source": [
    "### 点赞分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ba720dd-519a-4731-84c6-45e6b3f2a406",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T10:46:10.120464Z",
     "iopub.status.busy": "2025-04-15T10:46:10.120464Z",
     "iopub.status.idle": "2025-04-15T10:46:10.381002Z",
     "shell.execute_reply": "2025-04-15T10:46:10.381002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据加载完成，共 605 行和 67 列\n",
      "从IV.txt加载了 18 个自变量\n",
      "将使用的控制变量: author_followers_cnt, author_friends_cnt\n",
      "已确认因变量'interaction_like_cnt'存在于数据中\n",
      "已确认所有控制变量存在于数据中\n",
      "已创建结果文件: 生成结果/social_media/like-模型结果.txt\n",
      "数据预览:\n",
      "                    id  title  \\\n",
      "0  1909480340126580992    NaN   \n",
      "1  1909020699747886080    NaN   \n",
      "2  1908203431765881088    NaN   \n",
      "3  1908194727209385984    NaN   \n",
      "4  1908053656731087104    NaN   \n",
      "\n",
      "                                             content  url lang  \\\n",
      "0  Metal Shoe Rack\\nUpto 24% off\\nLink for you: h...  NaN   en   \n",
      "1  @emob_ @DamnNearWhite @Tr3sMilagros @MyFirstKi...  NaN   en   \n",
      "2  J.T. Foote Adjustable Shoe Trees - Plastic \\n🛠...  NaN   en   \n",
      "3  EXVITO Metal Shoe Rack for Home – Adjustable &...  NaN   en   \n",
      "4  Closet Shoe Organizer for 24 Pairs with Adjust...  NaN   en   \n",
      "\n",
      "                     publish_time publish_time_date publish_time_time  \\\n",
      "0  Tue Apr 08 05:36:04 +0000 2025        2025-04-08          05:36:04   \n",
      "1  Sun Apr 06 23:09:37 +0000 2025        2025-04-06          23:09:37   \n",
      "2  Fri Apr 04 17:02:05 +0000 2025        2025-04-04          17:02:05   \n",
      "3  Fri Apr 04 16:27:30 +0000 2025        2025-04-04          16:27:30   \n",
      "4  Fri Apr 04 07:06:56 +0000 2025        2025-04-04          07:06:56   \n",
      "\n",
      "   is_truncated  interaction_like_cnt  ...  承重能力表达  耐用性表达  长期满意度表达  颜色选择表达  \\\n",
      "0         False                     0  ...       1      1        1       0   \n",
      "1         False                     1  ...       1      0        1       0   \n",
      "2         False                     0  ...       1      0        0       0   \n",
      "3         False                     0  ...       0      1        1       0   \n",
      "4         False                     0  ...       0      0        0       0   \n",
      "\n",
      "   季节适应性表达  品牌声誉表达  消费者信任度表达  创新功能表达  儿童友好设计表达  组合灵活性表达  \n",
      "0        1       0         1       1         0        1  \n",
      "1        1       0         1       0         1        0  \n",
      "2        0       1         1       1         0        0  \n",
      "3        1       1         0       0         0        0  \n",
      "4        0       0         0       0         0        0  \n",
      "\n",
      "[5 rows x 67 columns]\n",
      "\n",
      "## interaction_like_cnt 分布分析结果:\n",
      "- 样本量: 605\n",
      "- 零值数量: 456\n",
      "- 零值比例: 75.3719\n",
      "- 均值: 1.1256\n",
      "- 中位数: 0.0000\n",
      "- 标准差: 6.3716\n",
      "- 最小值: 0\n",
      "- 最大值: 109\n",
      "- 偏度: 12.4797\n",
      "- 峰度: 180.1477\n",
      "\n",
      "## 推荐的模型: TOBIT\n",
      "- 变量转换: 对数转换\n",
      "- 原因: 数据中零值比例为75.37%，超过20%，使用Tobit模型。数据偏度为12.48，表现为偏态分布，对因变量进行对数转换。\n",
      "预处理后的数据: 605 行 × 21 列\n",
      "警告: interaction_like_cnt 的最小值为 0，包含零值或负值\n",
      "将使用log(1+x)转换\n",
      "已创建对数转换变量: log_interaction_like_cnt\n",
      "回归公式:\n",
      "log_interaction_like_cnt ~ 安全性需求表达 + 空间效率表达 + 环保材质偏好 + 组装便捷性表达 + 设计美感表达 + 层高可调节性表达 + 防尘功能表达 + 价格表达 + 多功能性表达 + 便携性表达 + 承重能力表达 + 耐用性表达 + 颜色选择表达 + 季节适应性表达 + 品牌声誉表达 + 创新功能表达 + 儿童友好设计表达 + 组合灵活性表达 + author_followers_cnt + author_friends_cnt\n",
      "\n",
      "多重共线性检验 (VIF):\n",
      "VIF > 10 表示可能存在严重的多重共线性问题\n",
      "                      变量       VIF\n",
      "12                颜色选择表达  5.844991\n",
      "4                 设计美感表达  5.432510\n",
      "0                安全性需求表达  3.560953\n",
      "8                 多功能性表达  3.394563\n",
      "11                 耐用性表达  3.326069\n",
      "3                组装便捷性表达  3.258193\n",
      "2                 环保材质偏好  3.220954\n",
      "10                承重能力表达  3.209544\n",
      "13               季节适应性表达  3.190966\n",
      "9                  便携性表达  3.183719\n",
      "17               组合灵活性表达  3.163847\n",
      "1                 空间效率表达  2.904204\n",
      "15                创新功能表达  2.775960\n",
      "14                品牌声誉表达  2.485333\n",
      "6                 防尘功能表达  2.375646\n",
      "16              儿童友好设计表达  2.106301\n",
      "5               层高可调节性表达  1.919452\n",
      "7                   价格表达  1.672822\n",
      "19    author_friends_cnt  1.279311\n",
      "18  author_followers_cnt  1.199435\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "data_file = os.path.join(folder_name, \"数据变量语义匹配二元赋值结果.xlsx\")\n",
    "data = pd.read_excel(data_file)\n",
    "print(f\"数据加载完成，共 {len(data)} 行和 {len(data.columns)} 列\")\n",
    "\n",
    "# 修改IV文件路径\n",
    "iv_file = os.path.join(folder_name, 'IV.txt')\n",
    "with open(iv_file, 'r', encoding='utf-8') as f:\n",
    "    iv_list = f.read().splitlines()\n",
    "    iv_list = [iv.strip() for iv in iv_list if iv.strip()]  # 移除空行\n",
    "print(f\"从IV.txt加载了 {len(iv_list)} 个自变量\")\n",
    "\n",
    "# 定义因变量和控制变量\n",
    "dv_col = 'interaction_like_cnt'\n",
    "control_vars = ['author_followers_cnt', 'author_friends_cnt']\n",
    "print(f\"将使用的控制变量: {', '.join(control_vars)}\")\n",
    "\n",
    "# 检查DV列是否存在\n",
    "if dv_col not in data.columns:\n",
    "    print(f\"错误: 数据中不存在列 '{dv_col}'\")\n",
    "    print(\"数据包含的列:\", data.columns.tolist()[:10], \"...\")\n",
    "    raise ValueError(f\"找不到DV列: {dv_col}\")\n",
    "else:\n",
    "    print(f\"已确认因变量'{dv_col}'存在于数据中\")\n",
    "\n",
    "# 检查控制变量是否存在\n",
    "missing_controls = [var for var in control_vars if var not in data.columns]\n",
    "if missing_controls:\n",
    "    print(f\"错误: 以下控制变量在数据中不存在: {missing_controls}\")\n",
    "    raise ValueError(\"缺少必要的控制变量\")\n",
    "else:\n",
    "    print(\"已确认所有控制变量存在于数据中\")\n",
    "\n",
    "# 检查IV列是否都存在\n",
    "missing_ivs = [iv for iv in iv_list if iv not in data.columns]\n",
    "if missing_ivs:\n",
    "    print(f\"警告: 以下IV在数据中不存在: {missing_ivs}\")\n",
    "    iv_list = [iv for iv in iv_list if iv in data.columns]\n",
    "    print(f\"将使用剩余的 {len(iv_list)} 个IV进行建模\")\n",
    "\n",
    "if not iv_list:\n",
    "    raise ValueError(\"没有可用的IV变量进行建模\")\n",
    "\n",
    "# 修改结果文件路径\n",
    "result_file = os.path.join(folder_name, \"like-模型结果.txt\")\n",
    "with open(result_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"# 模型分析结果\\n\\n\")\n",
    "print(f\"已创建结果文件: {result_file}\")\n",
    "\n",
    "# 显示数据前几行\n",
    "print(\"数据预览:\")\n",
    "print(data.head())\n",
    "\n",
    "# 分析DV的分布\n",
    "def analyze_distribution(data, col):\n",
    "    \"\"\"\n",
    "    分析变量分布并返回基本统计量和模型推荐\n",
    "    \"\"\"\n",
    "    # 提取非空数据\n",
    "    valid_data = data[col].dropna()\n",
    "    \n",
    "    # 基本统计量\n",
    "    stats_dict = {\n",
    "        \"样本量\": len(valid_data),\n",
    "        \"零值数量\": (valid_data == 0).sum(),\n",
    "        \"零值比例\": (valid_data == 0).mean() * 100,\n",
    "        \"均值\": valid_data.mean(),\n",
    "        \"中位数\": valid_data.median(),\n",
    "        \"标准差\": valid_data.std(),\n",
    "        \"最小值\": valid_data.min(),\n",
    "        \"最大值\": valid_data.max(),\n",
    "        \"偏度\": skew(valid_data),\n",
    "        \"峰度\": kurtosis(valid_data)\n",
    "    }\n",
    "\n",
    "    # 模型选择逻辑 - 根据零值比例和分布偏度\n",
    "    zero_inflated = stats_dict[\"零值比例\"] > 20  # 如果零值超过20%，使用Tobit\n",
    "    high_skew = abs(stats_dict[\"偏度\"]) > 1.0   # 如果偏度较大，使用对数转换\n",
    "    \n",
    "    model_type = \"ols\"  # 默认模型类型\n",
    "    transform_type = \"none\"  # 默认不转换\n",
    "    reason = \"\"\n",
    "    \n",
    "    if zero_inflated:\n",
    "        model_type = \"tobit\"\n",
    "        reason += f\"数据中零值比例为{stats_dict['零值比例']:.2f}%，超过20%，使用Tobit模型。\"\n",
    "        \n",
    "        if high_skew:\n",
    "            transform_type = \"log\"\n",
    "            reason += f\"数据偏度为{stats_dict['偏度']:.2f}，表现为偏态分布，对因变量进行对数转换。\"\n",
    "    else:\n",
    "        model_type = \"ols\"\n",
    "        reason += f\"数据中零值比例为{stats_dict['零值比例']:.2f}%，不超过20%，使用OLS模型。\"\n",
    "        \n",
    "        if high_skew:\n",
    "            transform_type = \"log\"\n",
    "            reason += f\"数据偏度为{stats_dict['偏度']:.2f}，表现为偏态分布，对因变量进行对数转换。\"\n",
    "    \n",
    "    return model_type, transform_type, reason, stats_dict\n",
    "\n",
    "# 对DV进行分布分析\n",
    "model_type, transform_type, reason, dv_stats = analyze_distribution(data, dv_col)\n",
    "\n",
    "# 显示分析结果\n",
    "print(f\"\\n## {dv_col} 分布分析结果:\")\n",
    "for key, value in dv_stats.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"- {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"- {key}: {value}\")\n",
    "\n",
    "print(f\"\\n## 推荐的模型: {model_type.upper()}\")\n",
    "print(f\"- 变量转换: {'对数转换' if transform_type == 'log' else '不转换'}\")\n",
    "print(f\"- 原因: {reason}\")\n",
    "\n",
    "# 将结果保存到文件\n",
    "with open(result_file, 'a', encoding='utf-8') as f:\n",
    "    f.write(f\"## {dv_col} 分布分析\\n\\n\")\n",
    "    for key, value in dv_stats.items():\n",
    "        if isinstance(value, float):\n",
    "            f.write(f\"- {key}: {value:.4f}\\n\")\n",
    "        else:\n",
    "            f.write(f\"- {key}: {value}\\n\")\n",
    "    \n",
    "    f.write(f\"\\n## 模型选择\\n\\n\")\n",
    "    f.write(f\"- 推荐的模型类型: {model_type.upper()}\\n\")\n",
    "    f.write(f\"- 变量转换: {'对数转换' if transform_type == 'log' else '不转换'}\\n\")\n",
    "    f.write(f\"- 选择原因: {reason}\\n\\n\")\n",
    "\n",
    "# 准备建模数据\n",
    "all_predictors = iv_list + control_vars\n",
    "model_data = data[[dv_col] + all_predictors].copy()\n",
    "model_data = model_data.dropna()  # 移除有缺失值的行\n",
    "print(f\"预处理后的数据: {len(model_data)} 行 × {len(model_data.columns)} 列\")\n",
    "\n",
    "# 处理因变量转换\n",
    "transformed_dv = dv_col\n",
    "if transform_type == \"log\":\n",
    "    # 检查零值和负值\n",
    "    min_value = model_data[dv_col].min()\n",
    "    if min_value <= 0:\n",
    "        print(f\"警告: {dv_col} 的最小值为 {min_value}，包含零值或负值\")\n",
    "        print(\"将使用log(1+x)转换\")\n",
    "        model_data[f'log_{dv_col}'] = np.log1p(model_data[dv_col])\n",
    "    else:\n",
    "        model_data[f'log_{dv_col}'] = np.log(model_data[dv_col])\n",
    "    transformed_dv = f'log_{dv_col}'\n",
    "    print(f\"已创建对数转换变量: {transformed_dv}\")\n",
    "else:\n",
    "    print(f\"使用原始变量: {transformed_dv}\")\n",
    "\n",
    "# 构建公式并显示\n",
    "formula = f\"{transformed_dv} ~ \" + \" + \".join(all_predictors)\n",
    "print(f\"回归公式:\")\n",
    "print(formula)\n",
    "\n",
    "# 检查多重共线性\n",
    "if len(all_predictors) > 1:\n",
    "    X = model_data[all_predictors]\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"变量\"] = X.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    print(\"\\n多重共线性检验 (VIF):\")\n",
    "    print(\"VIF > 10 表示可能存在严重的多重共线性问题\")\n",
    "    print(vif_data.sort_values(\"VIF\", ascending=False))\n",
    "\n",
    "    with open(result_file, 'a', encoding='utf-8') as f:\n",
    "        f.write(\"## 多重共线性检验 (VIF)\\n\\n\")\n",
    "        f.write(\"VIF > 10 表示可能存在严重的多重共线性问题\\n\\n\")\n",
    "        f.write(\"| 变量 | VIF |\\n\")\n",
    "        f.write(\"|------|------|\\n\")\n",
    "        for index, row in vif_data.iterrows():\n",
    "            f.write(f\"| {row['变量']} | {row['VIF']:.4f} |\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e8e3208-f6a1-4ec7-8e1f-2f16ff829e0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T10:46:10.381002Z",
     "iopub.status.busy": "2025-04-15T10:46:10.381002Z",
     "iopub.status.idle": "2025-04-15T10:46:10.687007Z",
     "shell.execute_reply": "2025-04-15T10:46:10.686274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始拟合TOBIT模型...\n",
      "使用改进的自定义Tobit模型实现...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\Lynx\\lib\\site-packages\\statsmodels\\base\\optimizer.py:19: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method nm is: xtol, ftol, maxfun. The list of unsupported keyword arguments passed include: options. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tobit模型结果:\n",
      "                              TobitModel Results                              \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   Log-Likelihood:                -510.58\n",
      "Model:                     TobitModel   AIC:                             1065.\n",
      "Method:            Maximum Likelihood   BIC:                             1162.\n",
      "Date:                Tue, 15 Apr 2025                                         \n",
      "Time:                        18:46:10                                         \n",
      "No. Observations:                 605                                         \n",
      "Df Residuals:                     584                                         \n",
      "Df Model:                          20                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.4700      0.265     -1.774      0.076      -0.989       0.049\n",
      "x1             0.0517      0.252      0.205      0.837      -0.442       0.545\n",
      "x2             0.1916      0.245      0.783      0.434      -0.288       0.671\n",
      "x3            -0.1599      0.246     -0.649      0.516      -0.643       0.323\n",
      "x4            -0.0304      0.248     -0.122      0.903      -0.517       0.457\n",
      "x5            -0.1978      0.325     -0.608      0.543      -0.835       0.440\n",
      "x6             0.1807      0.196      0.921      0.357      -0.204       0.565\n",
      "x7            -0.0544      0.211     -0.258      0.796      -0.467       0.359\n",
      "x8            -0.0888      0.233     -0.382      0.703      -0.545       0.367\n",
      "x9            -0.4646      0.257     -1.805      0.071      -0.969       0.040\n",
      "x10           -0.2227      0.248     -0.898      0.369      -0.709       0.263\n",
      "x11            0.0323      0.249      0.129      0.897      -0.456       0.521\n",
      "x12           -0.0022      0.243     -0.009      0.993      -0.478       0.473\n",
      "x13            0.2072      0.334      0.621      0.534      -0.447       0.861\n",
      "x14           -0.0003      0.248     -0.001      0.999      -0.487       0.486\n",
      "x15           -0.0801      0.234     -0.342      0.732      -0.539       0.379\n",
      "x16            0.0011      0.224      0.005      0.996      -0.439       0.441\n",
      "x17           -0.0078      0.204     -0.038      0.969      -0.407       0.392\n",
      "x18           -0.0427      0.239     -0.179      0.858      -0.511       0.426\n",
      "x19        -1.255e-08   4.63e-07     -0.027      0.978   -9.21e-07    8.96e-07\n",
      "x20         2.226e-05   5.08e-05      0.439      0.661   -7.72e-05       0.000\n",
      "par0           1.6814      0.179      9.377      0.000       1.330       2.033\n",
      "==============================================================================\n",
      "\n",
      "模型解读:\n",
      "- Tobit模型统计量:\n",
      "  - 对数似然值: -510.5803\n",
      "  - AIC: 1065.1605\n",
      "  - BIC: 1162.0756\n",
      "\n",
      "显著的变量 (p < 0.05): 0/19\n",
      "\n",
      "显著的自变量: 0/18\n",
      "\n",
      "显著的控制变量: 0/2\n",
      "\n",
      "模型解读:\n",
      "- Tobit模型统计量:\n",
      "  - 对数似然值: -510.5803\n",
      "  - AIC: 1065.1605\n",
      "  - BIC: 1162.0756\n",
      "\n",
      "显著的变量 (p < 0.05): 0/19\n",
      "\n",
      "显著的自变量: 0/18\n",
      "\n",
      "显著的控制变量: 0/2\n",
      "\n",
      "所有分析结果已保存到 生成结果/social_media/like-模型结果.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\Lynx\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\admin\\anaconda3\\envs\\Lynx\\lib\\site-packages\\statsmodels\\base\\model.py:2748: UserWarning: df_model + k_constant + k_extra differs from k_params\n",
      "  warnings.warn(\"df_model + k_constant + k_extra \"\n",
      "C:\\Users\\admin\\anaconda3\\envs\\Lynx\\lib\\site-packages\\statsmodels\\base\\model.py:2752: UserWarning: df_resid differs from nobs - k_params\n",
      "  warnings.warn(\"df_resid differs from nobs - k_params\")\n"
     ]
    }
   ],
   "source": [
    "print(f\"开始拟合{model_type.upper()}模型...\")\n",
    "\n",
    "if model_type == \"tobit\":\n",
    "    # 尝试不同的导入方式\n",
    "    try:\n",
    "        # 尝试从truncated_model模块导入\n",
    "        from statsmodels.discrete.truncated_model import Tobit\n",
    "        \n",
    "        # 准备数据\n",
    "        y = model_data[transformed_dv].values\n",
    "        X = sm.add_constant(model_data[all_predictors])\n",
    "        \n",
    "        print(\"使用statsmodels.discrete.truncated_model中的Tobit模型...\")\n",
    "        tobit_model = Tobit(y, X, left=0)\n",
    "        results = tobit_model.fit(method='powell', disp=0, maxiter=10000)\n",
    "        \n",
    "    except (ImportError, AttributeError):\n",
    "        # 如果上述导入失败，使用censored_model模块\n",
    "        try:\n",
    "            from statsmodels.regression.censored_model import Tobit\n",
    "            \n",
    "            # 准备数据\n",
    "            y = model_data[transformed_dv].values\n",
    "            X = sm.add_constant(model_data[all_predictors])\n",
    "            \n",
    "            print(\"使用statsmodels.regression.censored_model中的Tobit模型...\")\n",
    "            tobit_model = Tobit(y, X, left=0)\n",
    "            results = tobit_model.fit(method='powell', disp=0, maxiter=10000)\n",
    "            \n",
    "        except (ImportError, AttributeError):\n",
    "            # 如果上述方法都失败，使用改进的自定义实现\n",
    "            print(\"使用改进的自定义Tobit模型实现...\")\n",
    "            from scipy.stats import norm\n",
    "            from scipy import optimize\n",
    "            from statsmodels.regression.linear_model import OLS\n",
    "            from statsmodels.base.model import GenericLikelihoodModel\n",
    "            \n",
    "            class TobitModel(GenericLikelihoodModel):\n",
    "                def __init__(self, endog, exog, left=0, **kwds):\n",
    "                    self.left = left\n",
    "                    super(TobitModel, self).__init__(endog, exog, **kwds)\n",
    "                \n",
    "                def loglikeobs(self, params):\n",
    "                    beta = params[:-1]\n",
    "                    sigma = np.abs(params[-1])  # 确保sigma为正\n",
    "                    \n",
    "                    q = self.endog\n",
    "                    x = self.exog\n",
    "                    \n",
    "                    # 计算条件期望\n",
    "                    mu = np.dot(x, beta)\n",
    "                    \n",
    "                    # 分别计算截尾和非截尾值的对数似然\n",
    "                    censored_mask = (q <= self.left)\n",
    "                    z = (self.left - mu) / sigma\n",
    "                    \n",
    "                    ll_censored = censored_mask * norm.logcdf(z)\n",
    "                    \n",
    "                    non_censored_mask = ~censored_mask\n",
    "                    ll_non_censored = non_censored_mask * (\n",
    "                        -np.log(sigma) + \n",
    "                        norm.logpdf((q - mu) / sigma)\n",
    "                    )\n",
    "                    \n",
    "                    # 处理可能的数值问题\n",
    "                    result = ll_censored + ll_non_censored\n",
    "                    # 替换无效值\n",
    "                    result = np.where(np.isnan(result) | np.isinf(result), -1e10, result)\n",
    "                    \n",
    "                    return result\n",
    "                \n",
    "                def nloglikeobs(self, params):\n",
    "                    \"\"\"负对数似然\"\"\"\n",
    "                    return -self.loglikeobs(params)\n",
    "                \n",
    "                def fit(self, start_params=None, method='bfgs', maxiter=50000, **kwds):\n",
    "                    \"\"\"添加更多优化方法选项和更好的初始值策略\"\"\"\n",
    "                    if start_params is None:\n",
    "                        # 使用OLS估计获取更稳定的初始值\n",
    "                        ols_model = OLS(\n",
    "                            np.where(self.endog <= self.left, self.left, self.endog),\n",
    "                            self.exog\n",
    "                        )\n",
    "                        ols_res = ols_model.fit()\n",
    "                        # 使用残差的标准差作为sigma的初始值\n",
    "                        start_params = np.append(ols_res.params, np.std(ols_res.resid))\n",
    "                    \n",
    "                    # 添加更多优化选项\n",
    "                    if 'options' not in kwds:\n",
    "                        kwds['options'] = {}\n",
    "                    kwds['options']['maxiter'] = maxiter\n",
    "                    \n",
    "                    # 添加容错设置\n",
    "                    try:\n",
    "                        return super(TobitModel, self).fit(\n",
    "                            start_params=start_params,\n",
    "                            method=method, \n",
    "                            **kwds\n",
    "                        )\n",
    "                    except Exception as e:\n",
    "                        print(f\"首次优化失败: {str(e)}，尝试备用方法...\")\n",
    "                        try:\n",
    "                            # 尝试Powell方法\n",
    "                            return super(TobitModel, self).fit(\n",
    "                                start_params=start_params,\n",
    "                                method='powell',\n",
    "                                options={'maxiter': 100000, 'ftol': 1e-8, 'xtol': 1e-8},\n",
    "                                **kwds\n",
    "                            )\n",
    "                        except:\n",
    "                            print(\"所有优化方法失败，尝试最简单的优化设置...\")\n",
    "                            return super(TobitModel, self).fit(\n",
    "                                start_params=start_params,\n",
    "                                method='nm',\n",
    "                                options={'maxiter': 100000},\n",
    "                                **kwds\n",
    "                            )\n",
    "            \n",
    "            # 准备数据 - 修改数据准备部分以避免AttributeError\n",
    "            y = model_data[transformed_dv].values\n",
    "            X_df = sm.add_constant(model_data[all_predictors])  # 保持DataFrame格式\n",
    "            X_array = X_df.values  # 数组版本用于拟合\n",
    "            X_columns = X_df.columns.tolist()  # 保存列名供后续使用\n",
    "            \n",
    "            # 拟合Tobit模型，尝试多种方法\n",
    "            tobit_model = TobitModel(y, X_array, left=0)\n",
    "            try:\n",
    "                # 首先尝试Nelder-Mead方法\n",
    "                results = tobit_model.fit(method='nm', disp=0, maxiter=50000)\n",
    "            except:\n",
    "                try:\n",
    "                    # 如果失败，尝试BFGS方法\n",
    "                    results = tobit_model.fit(method='bfgs', disp=0, maxiter=50000)\n",
    "                except:\n",
    "                    # 最后尝试Powell方法\n",
    "                    results = tobit_model.fit(method='powell', disp=0, maxiter=50000)\n",
    "    \n",
    "    # 打印结果\n",
    "    print(\"\\nTobit模型结果:\")\n",
    "    print(results.summary())\n",
    "    \n",
    "else:  # 使用OLS模型 - 保持不变\n",
    "    # 创建并拟合模型\n",
    "    model = smf.ols(formula=formula, data=model_data)\n",
    "    results = model.fit()\n",
    "    \n",
    "    # 显示结果摘要\n",
    "    print(\"\\nOLS回归结果:\")\n",
    "    print(results.summary())\n",
    "\n",
    "# 保存结果\n",
    "with open(result_file, 'a', encoding='utf-8') as f:\n",
    "    f.write(f\"## {model_type.upper()}回归结果\\n\\n\")\n",
    "    f.write(f\"被解释变量: {transformed_dv}\\n\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(str(results.summary()))\n",
    "    f.write(\"\\n\\n\\n\")\n",
    "\n",
    "# 模型结果解读\n",
    "print(\"\\n模型解读:\")\n",
    "\n",
    "if model_type == \"ols\":\n",
    "    # OLS模型特有的解读 - 保持不变\n",
    "    print(f\"- 模型解释力 (R²): {results.rsquared:.4f}\")\n",
    "    print(f\"- 调整后的R²: {results.rsquared_adj:.4f}\")\n",
    "    print(f\"- 模型整体显著性: F({results.df_model:.0f},{results.df_resid:.0f})={results.fvalue:.4f}, p={results.f_pvalue:.6f}\")\n",
    "    \n",
    "    if results.f_pvalue < 0.05:\n",
    "        print(\"  结论: 模型整体上显著\")\n",
    "    else:\n",
    "        print(\"  结论: 模型整体上不显著\")\n",
    "    \n",
    "    # 获取显著的变量\n",
    "    p_values = results.pvalues[1:]  # 跳过截距\n",
    "    var_names = all_predictors\n",
    "    \n",
    "else:  # Tobit模型 - 修改此部分以处理可能的NaN问题\n",
    "    print(\"- Tobit模型统计量:\")\n",
    "    print(f\"  - 对数似然值: {results.llf:.4f}\")\n",
    "    print(f\"  - AIC: {results.aic:.4f}\")\n",
    "    print(f\"  - BIC: {results.bic:.4f}\")\n",
    "    \n",
    "    # 安全获取Tobit模型的系数和p值\n",
    "    if hasattr(results, 'pvalues') and not np.all(np.isnan(results.pvalues)):\n",
    "        p_values = results.pvalues[1:-1]  # 跳过截距和sigma\n",
    "    else:\n",
    "        print(\"警告: p值计算失败，将使用系数作为显著性的近似指标\")\n",
    "        # 使用系数作为显著性的近似指标\n",
    "        coefs = results.params[1:-1]\n",
    "        se = np.ones_like(coefs) * 0.05  # 假设标准误为0.05\n",
    "        p_values = 2 * (1 - norm.cdf(np.abs(coefs / se)))\n",
    "    \n",
    "    # 在自定义Tobit中X_columns已定义，在statsmodels版本中需要定义\n",
    "    if 'X_columns' not in locals():\n",
    "        X_columns = model_data[all_predictors].columns.tolist()\n",
    "        X_columns = ['const'] + X_columns\n",
    "    \n",
    "    var_names = X_columns[1:-1] if model_type == \"tobit\" else X_columns[1:]  # 适应不同情况\n",
    "\n",
    "# 显著变量分析（对两种模型通用）\n",
    "significant_mask = p_values < 0.05\n",
    "significant_vars = [var for var, sig in zip(var_names, significant_mask) if sig]\n",
    "print(f\"\\n显著的变量 (p < 0.05): {len(significant_vars)}/{len(var_names)}\")\n",
    "\n",
    "iv_significant = [var for var in significant_vars if var in iv_list]\n",
    "ctrl_significant = [var for var in significant_vars if var in control_vars]\n",
    "\n",
    "# 显示显著的自变量\n",
    "print(f\"\\n显著的自变量: {len(iv_significant)}/{len(iv_list)}\")\n",
    "for var in iv_significant:\n",
    "    idx = var_names.index(var)\n",
    "    coef = results.params[idx + 1]  # +1 to skip intercept\n",
    "    p = p_values[idx]\n",
    "    print(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\")\n",
    "\n",
    "# 显示显著的控制变量\n",
    "print(f\"\\n显著的控制变量: {len(ctrl_significant)}/{len(control_vars)}\")\n",
    "for var in ctrl_significant:\n",
    "    idx = var_names.index(var)\n",
    "    coef = results.params[idx + 1]  # +1 to skip intercept\n",
    "    p = p_values[idx]\n",
    "    print(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\")\n",
    "\n",
    "# 保存结果\n",
    "with open(result_file, 'a', encoding='utf-8') as f:\n",
    "    f.write(f\"## {model_type.upper()}回归结果\\n\\n\")\n",
    "    f.write(f\"被解释变量: {transformed_dv}\\n\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(str(results.summary()))\n",
    "    f.write(\"\\n\\n\\n\")\n",
    "\n",
    "# 模型结果解读\n",
    "print(\"\\n模型解读:\")\n",
    "\n",
    "if model_type == \"ols\":\n",
    "    # OLS模型特有的解读\n",
    "    print(f\"- 模型解释力 (R²): {results.rsquared:.4f}\")\n",
    "    print(f\"- 调整后的R²: {results.rsquared_adj:.4f}\")\n",
    "    print(f\"- 模型整体显著性: F({results.df_model:.0f},{results.df_resid:.0f})={results.fvalue:.4f}, p={results.f_pvalue:.6f}\")\n",
    "    \n",
    "    if results.f_pvalue < 0.05:\n",
    "        print(\"  结论: 模型整体上显著\")\n",
    "    else:\n",
    "        print(\"  结论: 模型整体上不显著\")\n",
    "    \n",
    "    # 获取显著的变量\n",
    "    p_values = results.pvalues[1:]  # 跳过截距\n",
    "    var_names = all_predictors\n",
    "    \n",
    "else:  # Tobit模型\n",
    "    print(\"- Tobit模型统计量:\")\n",
    "    print(f\"  - 对数似然值: {results.llf:.4f}\")\n",
    "    print(f\"  - AIC: {results.aic:.4f}\")\n",
    "    print(f\"  - BIC: {results.bic:.4f}\")\n",
    "    \n",
    "    # Tobit模型中获取系数和p值\n",
    "    p_values = results.pvalues[1:-1]  # 跳过截距和sigma\n",
    "    var_names = list(X.columns[1:])  # 跳过常数项\n",
    "\n",
    "# 显著变量分析（对两种模型通用）\n",
    "significant_mask = p_values < 0.05\n",
    "significant_vars = [var for var, sig in zip(var_names, significant_mask) if sig]\n",
    "print(f\"\\n显著的变量 (p < 0.05): {len(significant_vars)}/{len(var_names)}\")\n",
    "\n",
    "iv_significant = [var for var in significant_vars if var in iv_list]\n",
    "ctrl_significant = [var for var in significant_vars if var in control_vars]\n",
    "\n",
    "# 显示显著的自变量\n",
    "print(f\"\\n显著的自变量: {len(iv_significant)}/{len(iv_list)}\")\n",
    "for var in iv_significant:\n",
    "    idx = var_names.index(var)\n",
    "    coef = results.params[idx + 1]  # +1 to skip intercept\n",
    "    p = p_values[idx]\n",
    "    print(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\")\n",
    "\n",
    "# 显示显著的控制变量\n",
    "print(f\"\\n显著的控制变量: {len(ctrl_significant)}/{len(control_vars)}\")\n",
    "for var in ctrl_significant:\n",
    "    idx = var_names.index(var)\n",
    "    coef = results.params[idx + 1]  # +1 to skip intercept\n",
    "    p = p_values[idx]\n",
    "    print(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\")\n",
    "\n",
    "# 保存解读结果\n",
    "with open(result_file, 'a', encoding='utf-8') as f:\n",
    "    f.write(\"## 模型结果解读\\n\\n\")\n",
    "    \n",
    "    if model_type == \"ols\":\n",
    "        f.write(f\"- 模型解释力 (R²): {results.rsquared:.4f}\\n\")\n",
    "        f.write(f\"- 调整后的R²: {results.rsquared_adj:.4f}\\n\")\n",
    "        f.write(f\"- 模型整体显著性: F({results.df_model:.0f},{results.df_resid:.0f})={results.fvalue:.4f}, p={results.f_pvalue:.6f}\\n\")\n",
    "        \n",
    "        if results.f_pvalue < 0.05:\n",
    "            f.write(\"  结论: 模型整体上显著\\n\\n\")\n",
    "        else:\n",
    "            f.write(\"  结论: 模型整体上不显著\\n\\n\")\n",
    "    else:\n",
    "        f.write(\"- Tobit模型统计量:\\n\")\n",
    "        f.write(f\"  - 对数似然值: {results.llf:.4f}\\n\")\n",
    "        f.write(f\"  - AIC: {results.aic:.4f}\\n\")\n",
    "        f.write(f\"  - BIC: {results.bic:.4f}\\n\\n\")\n",
    "    \n",
    "    f.write(f\"显著的变量 (p < 0.05): {len(significant_vars)}/{len(var_names)}\\n\\n\")\n",
    "    \n",
    "    f.write(f\"显著的自变量: {len(iv_significant)}/{len(iv_list)}\\n\")\n",
    "    for var in iv_significant:\n",
    "        idx = var_names.index(var)\n",
    "        coef = results.params[idx + 1]\n",
    "        p = p_values[idx]\n",
    "        f.write(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\\n\")\n",
    "    \n",
    "    f.write(f\"\\n显著的控制变量: {len(ctrl_significant)}/{len(control_vars)}\\n\")\n",
    "    for var in ctrl_significant:\n",
    "        idx = var_names.index(var)\n",
    "        coef = results.params[idx + 1]\n",
    "        p = p_values[idx]\n",
    "        f.write(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\\n\")\n",
    "\n",
    "print(f\"\\n所有分析结果已保存到 {result_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48def4cd-8a5d-4146-bea6-b72aa98dd8f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T10:46:10.687007Z",
     "iopub.status.busy": "2025-04-15T10:46:10.687007Z",
     "iopub.status.idle": "2025-04-15T10:46:10.717063Z",
     "shell.execute_reply": "2025-04-15T10:46:10.716367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始归一化系数分析...\n",
      "注意: 没有显著的变量 (p < 0.05)，将使用所有非NaN系数变量\n",
      "\n",
      "归一化后的系数 (按绝对值排序):\n",
      "-----------------------------------\n",
      "总计 20 个有效变量, 无显著变量\n",
      "-----------------------------------\n",
      "\n",
      "自变量:\n",
      "多功能性表达: -0.4646 (归一化: -0.2304, 23.04%)\n",
      "便携性表达: -0.2227 (归一化: -0.1105, 11.05%)\n",
      "颜色选择表达: 0.2072 (归一化: 0.1028, 10.28%)\n",
      "设计美感表达: -0.1978 (归一化: -0.0981, 9.81%)\n",
      "空间效率表达: 0.1916 (归一化: 0.0950, 9.50%)\n",
      "层高可调节性表达: 0.1807 (归一化: 0.0896, 8.96%)\n",
      "环保材质偏好: -0.1599 (归一化: -0.0793, 7.93%)\n",
      "价格表达: -0.0888 (归一化: -0.0440, 4.40%)\n",
      "品牌声誉表达: -0.0801 (归一化: -0.0397, 3.97%)\n",
      "防尘功能表达: -0.0544 (归一化: -0.0270, 2.70%)\n",
      "安全性需求表达: 0.0517 (归一化: 0.0256, 2.56%)\n",
      "组合灵活性表达: -0.0427 (归一化: -0.0212, 2.12%)\n",
      "承重能力表达: 0.0323 (归一化: 0.0160, 1.60%)\n",
      "组装便捷性表达: -0.0304 (归一化: -0.0151, 1.51%)\n",
      "儿童友好设计表达: -0.0078 (归一化: -0.0039, 0.39%)\n",
      "耐用性表达: -0.0022 (归一化: -0.0011, 0.11%)\n",
      "创新功能表达: 0.0011 (归一化: 0.0006, 0.06%)\n",
      "季节适应性表达: -0.0003 (归一化: -0.0001, 0.01%)\n",
      "\n",
      "控制变量:\n",
      "author_friends_cnt: 0.0000 (归一化: 0.0000, 0.00%)\n",
      "author_followers_cnt: -0.0000 (归一化: -0.0000, 0.00%)\n",
      "-----------------------------------\n",
      "* 标记表示在0.05水平上显著\n",
      "\n",
      "结果已保存到 生成结果/social_media/Like-归一化的模型结果.txt\n"
     ]
    }
   ],
   "source": [
    "# 归一化显著系数并输出结果\n",
    "def normalize_significant_coefficients(results, iv_list, control_vars=None, model_type=\"ols\", alpha=0.05):\n",
    "    \"\"\"\n",
    "    归一化显著变量的系数，删除NaN值，按绝对值大小排序并输出结果\n",
    "    \n",
    "    参数:\n",
    "    - results: 回归结果对象\n",
    "    - iv_list: 自变量列表\n",
    "    - control_vars: 控制变量列表，默认为None\n",
    "    - model_type: 模型类型，\"ols\"或\"tobit\"\n",
    "    - alpha: 显著性水平，默认0.05\n",
    "    \"\"\"\n",
    "    if control_vars is None:\n",
    "        control_vars = []\n",
    "    \n",
    "    all_vars = iv_list + control_vars\n",
    "    \n",
    "    # 获取系数和p值 - 需要考虑不同模型类型\n",
    "    if model_type.lower() == \"ols\":\n",
    "        # OLS模型 - 跳过截距\n",
    "        coefs = results.params[1:len(all_vars)+1]\n",
    "        p_values = results.pvalues[1:len(all_vars)+1]\n",
    "    else:\n",
    "        # Tobit模型 - 跳过截距和sigma\n",
    "        coefs = results.params[1:len(all_vars)+1]\n",
    "        p_values = results.pvalues[1:len(all_vars)+1]\n",
    "    \n",
    "    # 创建DataFrame\n",
    "    coef_df = pd.DataFrame({\n",
    "        '变量': all_vars,\n",
    "        '系数': coefs,\n",
    "        'p值': p_values,\n",
    "        '变量类型': ['自变量' if var in iv_list else '控制变量' for var in all_vars]\n",
    "    })\n",
    "    \n",
    "    # 过滤掉NaN系数和非显著的变量\n",
    "    valid_coef_df = coef_df.dropna(subset=['系数'])\n",
    "    sig_coef_df = valid_coef_df[valid_coef_df['p值'] < alpha].copy()\n",
    "    \n",
    "    # 如果没有显著变量，则报告所有有效变量\n",
    "    if len(sig_coef_df) == 0:\n",
    "        print(\"注意: 没有显著的变量 (p < 0.05)，将使用所有非NaN系数变量\")\n",
    "        sig_coef_df = valid_coef_df.copy()\n",
    "    \n",
    "    # 如果没有有效系数，退出\n",
    "    if len(sig_coef_df) == 0:\n",
    "        print(\"警告: 没有有效的系数，无法进行归一化\")\n",
    "        return None\n",
    "    \n",
    "    # 计算系数的绝对值\n",
    "    sig_coef_df['系数绝对值'] = sig_coef_df['系数'].abs()\n",
    "    \n",
    "    # 归一化系数\n",
    "    total_abs = sig_coef_df['系数绝对值'].sum()\n",
    "    sig_coef_df['归一化系数'] = sig_coef_df['系数'] / total_abs\n",
    "    sig_coef_df['归一化系数绝对值'] = sig_coef_df['系数绝对值'] / total_abs\n",
    "    sig_coef_df['归一化系数百分比'] = sig_coef_df['归一化系数绝对值'] * 100\n",
    "    \n",
    "    # 按系数绝对值排序\n",
    "    sig_coef_df = sig_coef_df.sort_values('系数绝对值', ascending=False)\n",
    "    \n",
    "    # 显示结果\n",
    "    print(\"\\n归一化后的系数 (按绝对值排序):\")\n",
    "    print(\"-----------------------------------\")\n",
    "    significant_str = \"显著 (p<0.05)\" if len(sig_coef_df[sig_coef_df['p值'] < alpha]) > 0 else \"无显著变量\"\n",
    "    print(f\"总计 {len(sig_coef_df)} 个有效变量, {significant_str}\")\n",
    "    print(\"-----------------------------------\")\n",
    "    \n",
    "    # 先显示自变量，再显示控制变量\n",
    "    for var_type in ['自变量', '控制变量']:\n",
    "        type_df = sig_coef_df[sig_coef_df['变量类型'] == var_type]\n",
    "        if len(type_df) > 0:\n",
    "            print(f\"\\n{var_type}:\")\n",
    "            for _, row in type_df.iterrows():\n",
    "                sig_mark = \"*\" if row['p值'] < alpha else \"\"\n",
    "                print(f\"{row['变量']}: {row['系数']:.4f} (归一化: {row['归一化系数']:.4f}, {row['归一化系数百分比']:.2f}%){sig_mark}\")\n",
    "    \n",
    "    print(\"-----------------------------------\")\n",
    "    print(\"* 标记表示在0.05水平上显著\")\n",
    "    \n",
    "    # 保存到文件\n",
    "    output_file = os.path.join(folder_name, \"Like-归一化的模型结果.txt\")\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"# {model_type.upper()} 模型归一化后的系数 (按绝对值排序)\\n\\n\")\n",
    "        f.write(\"-----------------------------------\\n\")\n",
    "        f.write(f\"总计 {len(sig_coef_df)} 个有效变量, {significant_str}\\n\")\n",
    "        f.write(\"-----------------------------------\\n\\n\")\n",
    "        \n",
    "        # 添加总表\n",
    "        f.write(\"| 变量 | 变量类型 | 系数 | p值 | 归一化系数 | 归一化百分比 | 显著性 |\\n\")\n",
    "        f.write(\"|------|---------|------|------|------------|------------|--------|\\n\")\n",
    "        \n",
    "        for _, row in sig_coef_df.iterrows():\n",
    "            sig = \"是\" if row['p值'] < alpha else \"否\"\n",
    "            f.write(f\"| {row['变量']} | {row['变量类型']} | {row['系数']:.4f} | {row['p值']:.4f} | {row['归一化系数']:.4f} | {row['归一化系数百分比']:.2f}% | {sig} |\\n\")\n",
    "        \n",
    "        f.write(\"\\n\\n## 详细分析\\n\\n\")\n",
    "        \n",
    "        # 先显示自变量，再显示控制变量\n",
    "        for var_type in ['自变量', '控制变量']:\n",
    "            type_df = sig_coef_df[sig_coef_df['变量类型'] == var_type]\n",
    "            if len(type_df) > 0:\n",
    "                f.write(f\"### {var_type}\\n\\n\")\n",
    "                \n",
    "                for _, row in type_df.iterrows():\n",
    "                    sig_symbol = \"*\" if row['p值'] < alpha else \"\"\n",
    "                    direction = \"正向\" if row['系数'] > 0 else \"负向\"\n",
    "                    f.write(f\"#### {row['变量']}{sig_symbol}\\n\\n\")\n",
    "                    f.write(f\"- 系数: {row['系数']:.4f}\\n\")\n",
    "                    f.write(f\"- p值: {row['p值']:.4f}\\n\")\n",
    "                    f.write(f\"- 影响方向: {direction}\\n\")\n",
    "                    f.write(f\"- 归一化系数: {row['归一化系数']:.4f}\\n\")\n",
    "                    f.write(f\"- 归一化百分比: {row['归一化系数百分比']:.2f}%\\n\")\n",
    "                    f.write(f\"- 是否显著: {'是' if row['p值'] < alpha else '否'}\\n\\n\")\n",
    "        \n",
    "        f.write(\"-----------------------------------\\n\")\n",
    "        f.write(\"* 标记表示在0.05水平上显著\\n\")\n",
    "    \n",
    "    print(f\"\\n结果已保存到 {output_file}\")\n",
    "    \n",
    "    return sig_coef_df\n",
    "# 调用归一化函数\n",
    "print(\"\\n开始归一化系数分析...\")\n",
    "normalized_coefs = normalize_significant_coefficients(\n",
    "    results=results,\n",
    "    iv_list=iv_list,\n",
    "    control_vars=control_vars,\n",
    "    model_type=model_type,\n",
    "    alpha=0.05\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770ec908-b739-411d-9dba-ed4f6b3df633",
   "metadata": {},
   "source": [
    "### 评论数分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74c1ae70-08fa-4cb5-9e89-37eeece295fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T10:46:10.717063Z",
     "iopub.status.busy": "2025-04-15T10:46:10.717063Z",
     "iopub.status.idle": "2025-04-15T10:46:11.265615Z",
     "shell.execute_reply": "2025-04-15T10:46:11.265615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据加载完成，共 605 行和 67 列\n",
      "从IV.txt加载了 18 个自变量\n",
      "将使用的控制变量: author_followers_cnt, author_friends_cnt\n",
      "已确认因变量'interaction_comment_cnt'存在于数据中\n",
      "已确认所有控制变量存在于数据中\n",
      "已创建结果文件: 生成结果/social_media/comment-模型结果.txt\n",
      "数据预览:\n",
      "                    id  title  \\\n",
      "0  1909480340126580992    NaN   \n",
      "1  1909020699747886080    NaN   \n",
      "2  1908203431765881088    NaN   \n",
      "3  1908194727209385984    NaN   \n",
      "4  1908053656731087104    NaN   \n",
      "\n",
      "                                             content  url lang  \\\n",
      "0  Metal Shoe Rack\\nUpto 24% off\\nLink for you: h...  NaN   en   \n",
      "1  @emob_ @DamnNearWhite @Tr3sMilagros @MyFirstKi...  NaN   en   \n",
      "2  J.T. Foote Adjustable Shoe Trees - Plastic \\n🛠...  NaN   en   \n",
      "3  EXVITO Metal Shoe Rack for Home – Adjustable &...  NaN   en   \n",
      "4  Closet Shoe Organizer for 24 Pairs with Adjust...  NaN   en   \n",
      "\n",
      "                     publish_time publish_time_date publish_time_time  \\\n",
      "0  Tue Apr 08 05:36:04 +0000 2025        2025-04-08          05:36:04   \n",
      "1  Sun Apr 06 23:09:37 +0000 2025        2025-04-06          23:09:37   \n",
      "2  Fri Apr 04 17:02:05 +0000 2025        2025-04-04          17:02:05   \n",
      "3  Fri Apr 04 16:27:30 +0000 2025        2025-04-04          16:27:30   \n",
      "4  Fri Apr 04 07:06:56 +0000 2025        2025-04-04          07:06:56   \n",
      "\n",
      "   is_truncated  interaction_like_cnt  ...  承重能力表达  耐用性表达  长期满意度表达  颜色选择表达  \\\n",
      "0         False                     0  ...       1      1        1       0   \n",
      "1         False                     1  ...       1      0        1       0   \n",
      "2         False                     0  ...       1      0        0       0   \n",
      "3         False                     0  ...       0      1        1       0   \n",
      "4         False                     0  ...       0      0        0       0   \n",
      "\n",
      "   季节适应性表达  品牌声誉表达  消费者信任度表达  创新功能表达  儿童友好设计表达  组合灵活性表达  \n",
      "0        1       0         1       1         0        1  \n",
      "1        1       0         1       0         1        0  \n",
      "2        0       1         1       1         0        0  \n",
      "3        1       1         0       0         0        0  \n",
      "4        0       0         0       0         0        0  \n",
      "\n",
      "[5 rows x 67 columns]\n",
      "\n",
      "## interaction_comment_cnt 分布分析结果:\n",
      "- 样本量: 605\n",
      "- 零值数量: 577\n",
      "- 零值比例: 95.3719\n",
      "- 均值: 0.0860\n",
      "- 中位数: 0.0000\n",
      "- 标准差: 0.4772\n",
      "- 最小值: 0\n",
      "- 最大值: 6\n",
      "- 偏度: 7.5665\n",
      "- 峰度: 68.8174\n",
      "\n",
      "## 推荐的模型: TOBIT\n",
      "- 变量转换: 对数转换\n",
      "- 原因: 数据中零值比例为95.37%，超过20%，使用Tobit模型。数据偏度为7.57，表现为偏态分布，对因变量进行对数转换。\n",
      "预处理后的数据: 605 行 × 21 列\n",
      "警告: interaction_comment_cnt 的最小值为 0，包含零值或负值\n",
      "将使用log(1+x)转换\n",
      "已创建对数转换变量: log_interaction_comment_cnt\n",
      "回归公式:\n",
      "log_interaction_comment_cnt ~ 安全性需求表达 + 空间效率表达 + 环保材质偏好 + 组装便捷性表达 + 设计美感表达 + 层高可调节性表达 + 防尘功能表达 + 价格表达 + 多功能性表达 + 便携性表达 + 承重能力表达 + 耐用性表达 + 颜色选择表达 + 季节适应性表达 + 品牌声誉表达 + 创新功能表达 + 儿童友好设计表达 + 组合灵活性表达 + author_followers_cnt + author_friends_cnt\n",
      "\n",
      "多重共线性检验 (VIF):\n",
      "VIF > 10 表示可能存在严重的多重共线性问题\n",
      "                      变量       VIF\n",
      "12                颜色选择表达  5.844991\n",
      "4                 设计美感表达  5.432510\n",
      "0                安全性需求表达  3.560953\n",
      "8                 多功能性表达  3.394563\n",
      "11                 耐用性表达  3.326069\n",
      "3                组装便捷性表达  3.258193\n",
      "2                 环保材质偏好  3.220954\n",
      "10                承重能力表达  3.209544\n",
      "13               季节适应性表达  3.190966\n",
      "9                  便携性表达  3.183719\n",
      "17               组合灵活性表达  3.163847\n",
      "1                 空间效率表达  2.904204\n",
      "15                创新功能表达  2.775960\n",
      "14                品牌声誉表达  2.485333\n",
      "6                 防尘功能表达  2.375646\n",
      "16              儿童友好设计表达  2.106301\n",
      "5               层高可调节性表达  1.919452\n",
      "7                   价格表达  1.672822\n",
      "19    author_friends_cnt  1.279311\n",
      "18  author_followers_cnt  1.199435\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "data_file = os.path.join(folder_name, \"数据变量语义匹配二元赋值结果.xlsx\")\n",
    "data = pd.read_excel(data_file)\n",
    "print(f\"数据加载完成，共 {len(data)} 行和 {len(data.columns)} 列\")\n",
    "\n",
    "# 修改IV文件路径\n",
    "iv_file = os.path.join(folder_name, 'IV.txt')\n",
    "with open(iv_file, 'r', encoding='utf-8') as f:\n",
    "    iv_list = f.read().splitlines()\n",
    "    iv_list = [iv.strip() for iv in iv_list if iv.strip()]  # 移除空行\n",
    "print(f\"从IV.txt加载了 {len(iv_list)} 个自变量\")\n",
    "\n",
    "# 定义因变量和控制变量\n",
    "dv_col = 'interaction_comment_cnt'\n",
    "control_vars = ['author_followers_cnt', 'author_friends_cnt']\n",
    "print(f\"将使用的控制变量: {', '.join(control_vars)}\")\n",
    "\n",
    "# 检查DV列是否存在\n",
    "if dv_col not in data.columns:\n",
    "    print(f\"错误: 数据中不存在列 '{dv_col}'\")\n",
    "    print(\"数据包含的列:\", data.columns.tolist()[:10], \"...\")\n",
    "    raise ValueError(f\"找不到DV列: {dv_col}\")\n",
    "else:\n",
    "    print(f\"已确认因变量'{dv_col}'存在于数据中\")\n",
    "\n",
    "# 检查控制变量是否存在\n",
    "missing_controls = [var for var in control_vars if var not in data.columns]\n",
    "if missing_controls:\n",
    "    print(f\"错误: 以下控制变量在数据中不存在: {missing_controls}\")\n",
    "    raise ValueError(\"缺少必要的控制变量\")\n",
    "else:\n",
    "    print(\"已确认所有控制变量存在于数据中\")\n",
    "\n",
    "# 检查IV列是否都存在\n",
    "missing_ivs = [iv for iv in iv_list if iv not in data.columns]\n",
    "if missing_ivs:\n",
    "    print(f\"警告: 以下IV在数据中不存在: {missing_ivs}\")\n",
    "    iv_list = [iv for iv in iv_list if iv in data.columns]\n",
    "    print(f\"将使用剩余的 {len(iv_list)} 个IV进行建模\")\n",
    "\n",
    "if not iv_list:\n",
    "    raise ValueError(\"没有可用的IV变量进行建模\")\n",
    "\n",
    "# 修改结果文件路径\n",
    "result_file = os.path.join(folder_name, \"comment-模型结果.txt\")\n",
    "with open(result_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"# 模型分析结果\\n\\n\")\n",
    "print(f\"已创建结果文件: {result_file}\")\n",
    "\n",
    "# 显示数据前几行\n",
    "print(\"数据预览:\")\n",
    "print(data.head())\n",
    "\n",
    "# 分析DV的分布\n",
    "def analyze_distribution(data, col):\n",
    "    \"\"\"\n",
    "    分析变量分布并返回基本统计量和模型推荐\n",
    "    \"\"\"\n",
    "    # 提取非空数据\n",
    "    valid_data = data[col].dropna()\n",
    "    \n",
    "    # 基本统计量\n",
    "    stats_dict = {\n",
    "        \"样本量\": len(valid_data),\n",
    "        \"零值数量\": (valid_data == 0).sum(),\n",
    "        \"零值比例\": (valid_data == 0).mean() * 100,\n",
    "        \"均值\": valid_data.mean(),\n",
    "        \"中位数\": valid_data.median(),\n",
    "        \"标准差\": valid_data.std(),\n",
    "        \"最小值\": valid_data.min(),\n",
    "        \"最大值\": valid_data.max(),\n",
    "        \"偏度\": skew(valid_data),\n",
    "        \"峰度\": kurtosis(valid_data)\n",
    "    }\n",
    "\n",
    "    # 模型选择逻辑 - 根据零值比例和分布偏度\n",
    "    zero_inflated = stats_dict[\"零值比例\"] > 20  # 如果零值超过20%，使用Tobit\n",
    "    high_skew = abs(stats_dict[\"偏度\"]) > 1.0   # 如果偏度较大，使用对数转换\n",
    "    \n",
    "    model_type = \"ols\"  # 默认模型类型\n",
    "    transform_type = \"none\"  # 默认不转换\n",
    "    reason = \"\"\n",
    "    \n",
    "    if zero_inflated:\n",
    "        model_type = \"tobit\"\n",
    "        reason += f\"数据中零值比例为{stats_dict['零值比例']:.2f}%，超过20%，使用Tobit模型。\"\n",
    "        \n",
    "        if high_skew:\n",
    "            transform_type = \"log\"\n",
    "            reason += f\"数据偏度为{stats_dict['偏度']:.2f}，表现为偏态分布，对因变量进行对数转换。\"\n",
    "    else:\n",
    "        model_type = \"ols\"\n",
    "        reason += f\"数据中零值比例为{stats_dict['零值比例']:.2f}%，不超过20%，使用OLS模型。\"\n",
    "        \n",
    "        if high_skew:\n",
    "            transform_type = \"log\"\n",
    "            reason += f\"数据偏度为{stats_dict['偏度']:.2f}，表现为偏态分布，对因变量进行对数转换。\"\n",
    "    \n",
    "    return model_type, transform_type, reason, stats_dict\n",
    "\n",
    "# 对DV进行分布分析\n",
    "model_type, transform_type, reason, dv_stats = analyze_distribution(data, dv_col)\n",
    "\n",
    "# 显示分析结果\n",
    "print(f\"\\n## {dv_col} 分布分析结果:\")\n",
    "for key, value in dv_stats.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"- {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"- {key}: {value}\")\n",
    "\n",
    "print(f\"\\n## 推荐的模型: {model_type.upper()}\")\n",
    "print(f\"- 变量转换: {'对数转换' if transform_type == 'log' else '不转换'}\")\n",
    "print(f\"- 原因: {reason}\")\n",
    "\n",
    "# 将结果保存到文件\n",
    "with open(result_file, 'a', encoding='utf-8') as f:\n",
    "    f.write(f\"## {dv_col} 分布分析\\n\\n\")\n",
    "    for key, value in dv_stats.items():\n",
    "        if isinstance(value, float):\n",
    "            f.write(f\"- {key}: {value:.4f}\\n\")\n",
    "        else:\n",
    "            f.write(f\"- {key}: {value}\\n\")\n",
    "    \n",
    "    f.write(f\"\\n## 模型选择\\n\\n\")\n",
    "    f.write(f\"- 推荐的模型类型: {model_type.upper()}\\n\")\n",
    "    f.write(f\"- 变量转换: {'对数转换' if transform_type == 'log' else '不转换'}\\n\")\n",
    "    f.write(f\"- 选择原因: {reason}\\n\\n\")\n",
    "\n",
    "# 准备建模数据\n",
    "all_predictors = iv_list + control_vars\n",
    "model_data = data[[dv_col] + all_predictors].copy()\n",
    "model_data = model_data.dropna()  # 移除有缺失值的行\n",
    "print(f\"预处理后的数据: {len(model_data)} 行 × {len(model_data.columns)} 列\")\n",
    "\n",
    "# 处理因变量转换\n",
    "transformed_dv = dv_col\n",
    "if transform_type == \"log\":\n",
    "    # 检查零值和负值\n",
    "    min_value = model_data[dv_col].min()\n",
    "    if min_value <= 0:\n",
    "        print(f\"警告: {dv_col} 的最小值为 {min_value}，包含零值或负值\")\n",
    "        print(\"将使用log(1+x)转换\")\n",
    "        model_data[f'log_{dv_col}'] = np.log1p(model_data[dv_col])\n",
    "    else:\n",
    "        model_data[f'log_{dv_col}'] = np.log(model_data[dv_col])\n",
    "    transformed_dv = f'log_{dv_col}'\n",
    "    print(f\"已创建对数转换变量: {transformed_dv}\")\n",
    "else:\n",
    "    print(f\"使用原始变量: {transformed_dv}\")\n",
    "\n",
    "# 构建公式并显示\n",
    "formula = f\"{transformed_dv} ~ \" + \" + \".join(all_predictors)\n",
    "print(f\"回归公式:\")\n",
    "print(formula)\n",
    "\n",
    "# 检查多重共线性\n",
    "if len(all_predictors) > 1:\n",
    "    X = model_data[all_predictors]\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"变量\"] = X.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    print(\"\\n多重共线性检验 (VIF):\")\n",
    "    print(\"VIF > 10 表示可能存在严重的多重共线性问题\")\n",
    "    print(vif_data.sort_values(\"VIF\", ascending=False))\n",
    "\n",
    "    with open(result_file, 'a', encoding='utf-8') as f:\n",
    "        f.write(\"## 多重共线性检验 (VIF)\\n\\n\")\n",
    "        f.write(\"VIF > 10 表示可能存在严重的多重共线性问题\\n\\n\")\n",
    "        f.write(\"| 变量 | VIF |\\n\")\n",
    "        f.write(\"|------|------|\\n\")\n",
    "        for index, row in vif_data.iterrows():\n",
    "            f.write(f\"| {row['变量']} | {row['VIF']:.4f} |\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ec5d3a8-68e9-4f6a-a330-21b7b4a890d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T10:46:11.266984Z",
     "iopub.status.busy": "2025-04-15T10:46:11.266984Z",
     "iopub.status.idle": "2025-04-15T10:46:11.616160Z",
     "shell.execute_reply": "2025-04-15T10:46:11.615326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始拟合TOBIT模型...\n",
      "使用改进的自定义Tobit模型实现...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\Lynx\\lib\\site-packages\\statsmodels\\base\\optimizer.py:19: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method nm is: xtol, ftol, maxfun. The list of unsupported keyword arguments passed include: options. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tobit模型结果:\n",
      "                              TobitModel Results                              \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   Log-Likelihood:                -257.69\n",
      "Model:                     TobitModel   AIC:                             559.4\n",
      "Method:            Maximum Likelihood   BIC:                             656.3\n",
      "Date:                Tue, 15 Apr 2025                                         \n",
      "Time:                        18:46:11                                         \n",
      "No. Observations:                 605                                         \n",
      "Df Residuals:                     584                                         \n",
      "Df Model:                          20                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.3341        nan        nan        nan         nan         nan\n",
      "x1             0.0123        nan        nan        nan         nan         nan\n",
      "x2             0.0072        nan        nan        nan         nan         nan\n",
      "x3            -0.0094        nan        nan        nan         nan         nan\n",
      "x4            -0.0099        nan        nan        nan         nan         nan\n",
      "x5            -0.0387        nan        nan        nan         nan         nan\n",
      "x6            -0.0026        nan        nan        nan         nan         nan\n",
      "x7            -0.0012        nan        nan        nan         nan         nan\n",
      "x8            -0.0923        nan        nan        nan         nan         nan\n",
      "x9             0.0029        nan        nan        nan         nan         nan\n",
      "x10           -0.0319        nan        nan        nan         nan         nan\n",
      "x11           -0.0002        nan        nan        nan         nan         nan\n",
      "x12            0.0066        nan        nan        nan         nan         nan\n",
      "x13           -0.0008        nan        nan        nan         nan         nan\n",
      "x14           -0.2104        nan        nan        nan         nan         nan\n",
      "x15            0.1089        nan        nan        nan         nan         nan\n",
      "x16           -0.0283        nan        nan        nan         nan         nan\n",
      "x17           -0.0002        nan        nan        nan         nan         nan\n",
      "x18            0.0464        nan        nan        nan         nan         nan\n",
      "x19         7.124e-08        nan        nan        nan         nan         nan\n",
      "x20         7.063e-07        nan        nan        nan         nan         nan\n",
      "par0           0.7473        nan        nan        nan         nan         nan\n",
      "==============================================================================\n",
      "\n",
      "模型解读:\n",
      "- Tobit模型统计量:\n",
      "  - 对数似然值: -257.6885\n",
      "  - AIC: 559.3771\n",
      "  - BIC: 656.2921\n",
      "警告: p值计算失败，将使用系数作为显著性的近似指标\n",
      "\n",
      "显著的变量 (p < 0.05): 2/19\n",
      "\n",
      "显著的自变量: 2/18\n",
      "- 季节适应性表达: 系数=-0.2104, p=0.000026\n",
      "- 品牌声誉表达: 系数=0.1089, p=0.029333\n",
      "\n",
      "显著的控制变量: 0/2\n",
      "\n",
      "模型解读:\n",
      "- Tobit模型统计量:\n",
      "  - 对数似然值: -257.6885\n",
      "  - AIC: 559.3771\n",
      "  - BIC: 656.2921\n",
      "\n",
      "显著的变量 (p < 0.05): 0/19\n",
      "\n",
      "显著的自变量: 0/18\n",
      "\n",
      "显著的控制变量: 0/2\n",
      "\n",
      "所有分析结果已保存到 生成结果/social_media/comment-模型结果.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\Lynx\\lib\\site-packages\\statsmodels\\base\\model.py:595: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  warnings.warn('Inverting hessian failed, no bse or cov_params '\n",
      "C:\\Users\\admin\\anaconda3\\envs\\Lynx\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\admin\\anaconda3\\envs\\Lynx\\lib\\site-packages\\statsmodels\\base\\model.py:2748: UserWarning: df_model + k_constant + k_extra differs from k_params\n",
      "  warnings.warn(\"df_model + k_constant + k_extra \"\n",
      "C:\\Users\\admin\\anaconda3\\envs\\Lynx\\lib\\site-packages\\statsmodels\\base\\model.py:2752: UserWarning: df_resid differs from nobs - k_params\n",
      "  warnings.warn(\"df_resid differs from nobs - k_params\")\n"
     ]
    }
   ],
   "source": [
    "print(f\"开始拟合{model_type.upper()}模型...\")\n",
    "\n",
    "if model_type == \"tobit\":\n",
    "    # 尝试不同的导入方式\n",
    "    try:\n",
    "        # 尝试从truncated_model模块导入\n",
    "        from statsmodels.discrete.truncated_model import Tobit\n",
    "        \n",
    "        # 准备数据\n",
    "        y = model_data[transformed_dv].values\n",
    "        X = sm.add_constant(model_data[all_predictors])\n",
    "        \n",
    "        print(\"使用statsmodels.discrete.truncated_model中的Tobit模型...\")\n",
    "        tobit_model = Tobit(y, X, left=0)\n",
    "        results = tobit_model.fit(method='powell', disp=0, maxiter=10000)\n",
    "        \n",
    "    except (ImportError, AttributeError):\n",
    "        # 如果上述导入失败，使用censored_model模块\n",
    "        try:\n",
    "            from statsmodels.regression.censored_model import Tobit\n",
    "            \n",
    "            # 准备数据\n",
    "            y = model_data[transformed_dv].values\n",
    "            X = sm.add_constant(model_data[all_predictors])\n",
    "            \n",
    "            print(\"使用statsmodels.regression.censored_model中的Tobit模型...\")\n",
    "            tobit_model = Tobit(y, X, left=0)\n",
    "            results = tobit_model.fit(method='powell', disp=0, maxiter=10000)\n",
    "            \n",
    "        except (ImportError, AttributeError):\n",
    "            # 如果上述方法都失败，使用改进的自定义实现\n",
    "            print(\"使用改进的自定义Tobit模型实现...\")\n",
    "            from scipy.stats import norm\n",
    "            from scipy import optimize\n",
    "            from statsmodels.regression.linear_model import OLS\n",
    "            from statsmodels.base.model import GenericLikelihoodModel\n",
    "            \n",
    "            class TobitModel(GenericLikelihoodModel):\n",
    "                def __init__(self, endog, exog, left=0, **kwds):\n",
    "                    self.left = left\n",
    "                    super(TobitModel, self).__init__(endog, exog, **kwds)\n",
    "                \n",
    "                def loglikeobs(self, params):\n",
    "                    beta = params[:-1]\n",
    "                    sigma = np.abs(params[-1])  # 确保sigma为正\n",
    "                    \n",
    "                    q = self.endog\n",
    "                    x = self.exog\n",
    "                    \n",
    "                    # 计算条件期望\n",
    "                    mu = np.dot(x, beta)\n",
    "                    \n",
    "                    # 分别计算截尾和非截尾值的对数似然\n",
    "                    censored_mask = (q <= self.left)\n",
    "                    z = (self.left - mu) / sigma\n",
    "                    \n",
    "                    ll_censored = censored_mask * norm.logcdf(z)\n",
    "                    \n",
    "                    non_censored_mask = ~censored_mask\n",
    "                    ll_non_censored = non_censored_mask * (\n",
    "                        -np.log(sigma) + \n",
    "                        norm.logpdf((q - mu) / sigma)\n",
    "                    )\n",
    "                    \n",
    "                    # 处理可能的数值问题\n",
    "                    result = ll_censored + ll_non_censored\n",
    "                    # 替换无效值\n",
    "                    result = np.where(np.isnan(result) | np.isinf(result), -1e10, result)\n",
    "                    \n",
    "                    return result\n",
    "                \n",
    "                def nloglikeobs(self, params):\n",
    "                    \"\"\"负对数似然\"\"\"\n",
    "                    return -self.loglikeobs(params)\n",
    "                \n",
    "                def fit(self, start_params=None, method='bfgs', maxiter=50000, **kwds):\n",
    "                    \"\"\"添加更多优化方法选项和更好的初始值策略\"\"\"\n",
    "                    if start_params is None:\n",
    "                        # 使用OLS估计获取更稳定的初始值\n",
    "                        ols_model = OLS(\n",
    "                            np.where(self.endog <= self.left, self.left, self.endog),\n",
    "                            self.exog\n",
    "                        )\n",
    "                        ols_res = ols_model.fit()\n",
    "                        # 使用残差的标准差作为sigma的初始值\n",
    "                        start_params = np.append(ols_res.params, np.std(ols_res.resid))\n",
    "                    \n",
    "                    # 添加更多优化选项\n",
    "                    if 'options' not in kwds:\n",
    "                        kwds['options'] = {}\n",
    "                    kwds['options']['maxiter'] = maxiter\n",
    "                    \n",
    "                    # 添加容错设置\n",
    "                    try:\n",
    "                        return super(TobitModel, self).fit(\n",
    "                            start_params=start_params,\n",
    "                            method=method, \n",
    "                            **kwds\n",
    "                        )\n",
    "                    except Exception as e:\n",
    "                        print(f\"首次优化失败: {str(e)}，尝试备用方法...\")\n",
    "                        try:\n",
    "                            # 尝试Powell方法\n",
    "                            return super(TobitModel, self).fit(\n",
    "                                start_params=start_params,\n",
    "                                method='powell',\n",
    "                                options={'maxiter': 100000, 'ftol': 1e-8, 'xtol': 1e-8},\n",
    "                                **kwds\n",
    "                            )\n",
    "                        except:\n",
    "                            print(\"所有优化方法失败，尝试最简单的优化设置...\")\n",
    "                            return super(TobitModel, self).fit(\n",
    "                                start_params=start_params,\n",
    "                                method='nm',\n",
    "                                options={'maxiter': 100000},\n",
    "                                **kwds\n",
    "                            )\n",
    "            \n",
    "            # 准备数据 - 修改数据准备部分以避免AttributeError\n",
    "            y = model_data[transformed_dv].values\n",
    "            X_df = sm.add_constant(model_data[all_predictors])  # 保持DataFrame格式\n",
    "            X_array = X_df.values  # 数组版本用于拟合\n",
    "            X_columns = X_df.columns.tolist()  # 保存列名供后续使用\n",
    "            \n",
    "            # 拟合Tobit模型，尝试多种方法\n",
    "            tobit_model = TobitModel(y, X_array, left=0)\n",
    "            try:\n",
    "                # 首先尝试Nelder-Mead方法\n",
    "                results = tobit_model.fit(method='nm', disp=0, maxiter=50000)\n",
    "            except:\n",
    "                try:\n",
    "                    # 如果失败，尝试BFGS方法\n",
    "                    results = tobit_model.fit(method='bfgs', disp=0, maxiter=50000)\n",
    "                except:\n",
    "                    # 最后尝试Powell方法\n",
    "                    results = tobit_model.fit(method='powell', disp=0, maxiter=50000)\n",
    "    \n",
    "    # 打印结果\n",
    "    print(\"\\nTobit模型结果:\")\n",
    "    print(results.summary())\n",
    "    \n",
    "else:  # 使用OLS模型 - 保持不变\n",
    "    # 创建并拟合模型\n",
    "    model = smf.ols(formula=formula, data=model_data)\n",
    "    results = model.fit()\n",
    "    \n",
    "    # 显示结果摘要\n",
    "    print(\"\\nOLS回归结果:\")\n",
    "    print(results.summary())\n",
    "\n",
    "# 保存结果\n",
    "with open(result_file, 'a', encoding='utf-8') as f:\n",
    "    f.write(f\"## {model_type.upper()}回归结果\\n\\n\")\n",
    "    f.write(f\"被解释变量: {transformed_dv}\\n\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(str(results.summary()))\n",
    "    f.write(\"\\n\\n\\n\")\n",
    "\n",
    "# 模型结果解读\n",
    "print(\"\\n模型解读:\")\n",
    "\n",
    "if model_type == \"ols\":\n",
    "    # OLS模型特有的解读 - 保持不变\n",
    "    print(f\"- 模型解释力 (R²): {results.rsquared:.4f}\")\n",
    "    print(f\"- 调整后的R²: {results.rsquared_adj:.4f}\")\n",
    "    print(f\"- 模型整体显著性: F({results.df_model:.0f},{results.df_resid:.0f})={results.fvalue:.4f}, p={results.f_pvalue:.6f}\")\n",
    "    \n",
    "    if results.f_pvalue < 0.05:\n",
    "        print(\"  结论: 模型整体上显著\")\n",
    "    else:\n",
    "        print(\"  结论: 模型整体上不显著\")\n",
    "    \n",
    "    # 获取显著的变量\n",
    "    p_values = results.pvalues[1:]  # 跳过截距\n",
    "    var_names = all_predictors\n",
    "    \n",
    "else:  # Tobit模型 - 修改此部分以处理可能的NaN问题\n",
    "    print(\"- Tobit模型统计量:\")\n",
    "    print(f\"  - 对数似然值: {results.llf:.4f}\")\n",
    "    print(f\"  - AIC: {results.aic:.4f}\")\n",
    "    print(f\"  - BIC: {results.bic:.4f}\")\n",
    "    \n",
    "    # 安全获取Tobit模型的系数和p值\n",
    "    if hasattr(results, 'pvalues') and not np.all(np.isnan(results.pvalues)):\n",
    "        p_values = results.pvalues[1:-1]  # 跳过截距和sigma\n",
    "    else:\n",
    "        print(\"警告: p值计算失败，将使用系数作为显著性的近似指标\")\n",
    "        # 使用系数作为显著性的近似指标\n",
    "        coefs = results.params[1:-1]\n",
    "        se = np.ones_like(coefs) * 0.05  # 假设标准误为0.05\n",
    "        p_values = 2 * (1 - norm.cdf(np.abs(coefs / se)))\n",
    "    \n",
    "    # 在自定义Tobit中X_columns已定义，在statsmodels版本中需要定义\n",
    "    if 'X_columns' not in locals():\n",
    "        X_columns = model_data[all_predictors].columns.tolist()\n",
    "        X_columns = ['const'] + X_columns\n",
    "    \n",
    "    var_names = X_columns[1:-1] if model_type == \"tobit\" else X_columns[1:]  # 适应不同情况\n",
    "\n",
    "# 显著变量分析（对两种模型通用）\n",
    "significant_mask = p_values < 0.05\n",
    "significant_vars = [var for var, sig in zip(var_names, significant_mask) if sig]\n",
    "print(f\"\\n显著的变量 (p < 0.05): {len(significant_vars)}/{len(var_names)}\")\n",
    "\n",
    "iv_significant = [var for var in significant_vars if var in iv_list]\n",
    "ctrl_significant = [var for var in significant_vars if var in control_vars]\n",
    "\n",
    "# 显示显著的自变量\n",
    "print(f\"\\n显著的自变量: {len(iv_significant)}/{len(iv_list)}\")\n",
    "for var in iv_significant:\n",
    "    idx = var_names.index(var)\n",
    "    coef = results.params[idx + 1]  # +1 to skip intercept\n",
    "    p = p_values[idx]\n",
    "    print(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\")\n",
    "\n",
    "# 显示显著的控制变量\n",
    "print(f\"\\n显著的控制变量: {len(ctrl_significant)}/{len(control_vars)}\")\n",
    "for var in ctrl_significant:\n",
    "    idx = var_names.index(var)\n",
    "    coef = results.params[idx + 1]  # +1 to skip intercept\n",
    "    p = p_values[idx]\n",
    "    print(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\")\n",
    "\n",
    "# 保存结果\n",
    "with open(result_file, 'a', encoding='utf-8') as f:\n",
    "    f.write(f\"## {model_type.upper()}回归结果\\n\\n\")\n",
    "    f.write(f\"被解释变量: {transformed_dv}\\n\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(str(results.summary()))\n",
    "    f.write(\"\\n\\n\\n\")\n",
    "\n",
    "# 模型结果解读\n",
    "print(\"\\n模型解读:\")\n",
    "\n",
    "if model_type == \"ols\":\n",
    "    # OLS模型特有的解读\n",
    "    print(f\"- 模型解释力 (R²): {results.rsquared:.4f}\")\n",
    "    print(f\"- 调整后的R²: {results.rsquared_adj:.4f}\")\n",
    "    print(f\"- 模型整体显著性: F({results.df_model:.0f},{results.df_resid:.0f})={results.fvalue:.4f}, p={results.f_pvalue:.6f}\")\n",
    "    \n",
    "    if results.f_pvalue < 0.05:\n",
    "        print(\"  结论: 模型整体上显著\")\n",
    "    else:\n",
    "        print(\"  结论: 模型整体上不显著\")\n",
    "    \n",
    "    # 获取显著的变量\n",
    "    p_values = results.pvalues[1:]  # 跳过截距\n",
    "    var_names = all_predictors\n",
    "    \n",
    "else:  # Tobit模型\n",
    "    print(\"- Tobit模型统计量:\")\n",
    "    print(f\"  - 对数似然值: {results.llf:.4f}\")\n",
    "    print(f\"  - AIC: {results.aic:.4f}\")\n",
    "    print(f\"  - BIC: {results.bic:.4f}\")\n",
    "    \n",
    "    # Tobit模型中获取系数和p值\n",
    "    p_values = results.pvalues[1:-1]  # 跳过截距和sigma\n",
    "    var_names = list(X.columns[1:])  # 跳过常数项\n",
    "\n",
    "# 显著变量分析（对两种模型通用）\n",
    "significant_mask = p_values < 0.05\n",
    "significant_vars = [var for var, sig in zip(var_names, significant_mask) if sig]\n",
    "print(f\"\\n显著的变量 (p < 0.05): {len(significant_vars)}/{len(var_names)}\")\n",
    "\n",
    "iv_significant = [var for var in significant_vars if var in iv_list]\n",
    "ctrl_significant = [var for var in significant_vars if var in control_vars]\n",
    "\n",
    "# 显示显著的自变量\n",
    "print(f\"\\n显著的自变量: {len(iv_significant)}/{len(iv_list)}\")\n",
    "for var in iv_significant:\n",
    "    idx = var_names.index(var)\n",
    "    coef = results.params[idx + 1]  # +1 to skip intercept\n",
    "    p = p_values[idx]\n",
    "    print(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\")\n",
    "\n",
    "# 显示显著的控制变量\n",
    "print(f\"\\n显著的控制变量: {len(ctrl_significant)}/{len(control_vars)}\")\n",
    "for var in ctrl_significant:\n",
    "    idx = var_names.index(var)\n",
    "    coef = results.params[idx + 1]  # +1 to skip intercept\n",
    "    p = p_values[idx]\n",
    "    print(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\")\n",
    "\n",
    "# 保存解读结果\n",
    "with open(result_file, 'a', encoding='utf-8') as f:\n",
    "    f.write(\"## 模型结果解读\\n\\n\")\n",
    "    \n",
    "    if model_type == \"ols\":\n",
    "        f.write(f\"- 模型解释力 (R²): {results.rsquared:.4f}\\n\")\n",
    "        f.write(f\"- 调整后的R²: {results.rsquared_adj:.4f}\\n\")\n",
    "        f.write(f\"- 模型整体显著性: F({results.df_model:.0f},{results.df_resid:.0f})={results.fvalue:.4f}, p={results.f_pvalue:.6f}\\n\")\n",
    "        \n",
    "        if results.f_pvalue < 0.05:\n",
    "            f.write(\"  结论: 模型整体上显著\\n\\n\")\n",
    "        else:\n",
    "            f.write(\"  结论: 模型整体上不显著\\n\\n\")\n",
    "    else:\n",
    "        f.write(\"- Tobit模型统计量:\\n\")\n",
    "        f.write(f\"  - 对数似然值: {results.llf:.4f}\\n\")\n",
    "        f.write(f\"  - AIC: {results.aic:.4f}\\n\")\n",
    "        f.write(f\"  - BIC: {results.bic:.4f}\\n\\n\")\n",
    "    \n",
    "    f.write(f\"显著的变量 (p < 0.05): {len(significant_vars)}/{len(var_names)}\\n\\n\")\n",
    "    \n",
    "    f.write(f\"显著的自变量: {len(iv_significant)}/{len(iv_list)}\\n\")\n",
    "    for var in iv_significant:\n",
    "        idx = var_names.index(var)\n",
    "        coef = results.params[idx + 1]\n",
    "        p = p_values[idx]\n",
    "        f.write(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\\n\")\n",
    "    \n",
    "    f.write(f\"\\n显著的控制变量: {len(ctrl_significant)}/{len(control_vars)}\\n\")\n",
    "    for var in ctrl_significant:\n",
    "        idx = var_names.index(var)\n",
    "        coef = results.params[idx + 1]\n",
    "        p = p_values[idx]\n",
    "        f.write(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\\n\")\n",
    "\n",
    "print(f\"\\n所有分析结果已保存到 {result_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5414a449-d579-4a71-824c-dc48ac3b4b31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T10:46:11.616160Z",
     "iopub.status.busy": "2025-04-15T10:46:11.616160Z",
     "iopub.status.idle": "2025-04-15T10:46:11.645553Z",
     "shell.execute_reply": "2025-04-15T10:46:11.645553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始归一化系数分析...\n",
      "注意: 没有显著的变量 (p < 0.05)，将使用所有非NaN系数变量\n",
      "\n",
      "归一化后的系数 (按绝对值排序):\n",
      "-----------------------------------\n",
      "总计 20 个有效变量, 无显著变量\n",
      "-----------------------------------\n",
      "\n",
      "自变量:\n",
      "季节适应性表达: -0.2104 (归一化: -0.3447, 34.47%)\n",
      "品牌声誉表达: 0.1089 (归一化: 0.1785, 17.85%)\n",
      "价格表达: -0.0923 (归一化: -0.1512, 15.12%)\n",
      "组合灵活性表达: 0.0464 (归一化: 0.0760, 7.60%)\n",
      "设计美感表达: -0.0387 (归一化: -0.0634, 6.34%)\n",
      "便携性表达: -0.0319 (归一化: -0.0523, 5.23%)\n",
      "创新功能表达: -0.0283 (归一化: -0.0464, 4.64%)\n",
      "安全性需求表达: 0.0123 (归一化: 0.0202, 2.02%)\n",
      "组装便捷性表达: -0.0099 (归一化: -0.0161, 1.61%)\n",
      "环保材质偏好: -0.0094 (归一化: -0.0154, 1.54%)\n",
      "空间效率表达: 0.0072 (归一化: 0.0118, 1.18%)\n",
      "耐用性表达: 0.0066 (归一化: 0.0109, 1.09%)\n",
      "多功能性表达: 0.0029 (归一化: 0.0047, 0.47%)\n",
      "层高可调节性表达: -0.0026 (归一化: -0.0043, 0.43%)\n",
      "防尘功能表达: -0.0012 (归一化: -0.0020, 0.20%)\n",
      "颜色选择表达: -0.0008 (归一化: -0.0014, 0.14%)\n",
      "承重能力表达: -0.0002 (归一化: -0.0004, 0.04%)\n",
      "儿童友好设计表达: -0.0002 (归一化: -0.0003, 0.03%)\n",
      "\n",
      "控制变量:\n",
      "author_friends_cnt: 0.0000 (归一化: 0.0000, 0.00%)\n",
      "author_followers_cnt: 0.0000 (归一化: 0.0000, 0.00%)\n",
      "-----------------------------------\n",
      "* 标记表示在0.05水平上显著\n",
      "\n",
      "结果已保存到 生成结果/social_media/Comment-归一化的模型结果.txt\n"
     ]
    }
   ],
   "source": [
    "# 归一化显著系数并输出结果\n",
    "def normalize_significant_coefficients(results, iv_list, control_vars=None, model_type=\"ols\", alpha=0.05):\n",
    "    \"\"\"\n",
    "    归一化显著变量的系数，删除NaN值，按绝对值大小排序并输出结果\n",
    "    \n",
    "    参数:\n",
    "    - results: 回归结果对象\n",
    "    - iv_list: 自变量列表\n",
    "    - control_vars: 控制变量列表，默认为None\n",
    "    - model_type: 模型类型，\"ols\"或\"tobit\"\n",
    "    - alpha: 显著性水平，默认0.05\n",
    "    \"\"\"\n",
    "    if control_vars is None:\n",
    "        control_vars = []\n",
    "    \n",
    "    all_vars = iv_list + control_vars\n",
    "    \n",
    "    # 获取系数和p值 - 需要考虑不同模型类型\n",
    "    if model_type.lower() == \"ols\":\n",
    "        # OLS模型 - 跳过截距\n",
    "        coefs = results.params[1:len(all_vars)+1]\n",
    "        p_values = results.pvalues[1:len(all_vars)+1]\n",
    "    else:\n",
    "        # Tobit模型 - 跳过截距和sigma\n",
    "        coefs = results.params[1:len(all_vars)+1]\n",
    "        p_values = results.pvalues[1:len(all_vars)+1]\n",
    "    \n",
    "    # 创建DataFrame\n",
    "    coef_df = pd.DataFrame({\n",
    "        '变量': all_vars,\n",
    "        '系数': coefs,\n",
    "        'p值': p_values,\n",
    "        '变量类型': ['自变量' if var in iv_list else '控制变量' for var in all_vars]\n",
    "    })\n",
    "    \n",
    "    # 过滤掉NaN系数和非显著的变量\n",
    "    valid_coef_df = coef_df.dropna(subset=['系数'])\n",
    "    sig_coef_df = valid_coef_df[valid_coef_df['p值'] < alpha].copy()\n",
    "    \n",
    "    # 如果没有显著变量，则报告所有有效变量\n",
    "    if len(sig_coef_df) == 0:\n",
    "        print(\"注意: 没有显著的变量 (p < 0.05)，将使用所有非NaN系数变量\")\n",
    "        sig_coef_df = valid_coef_df.copy()\n",
    "    \n",
    "    # 如果没有有效系数，退出\n",
    "    if len(sig_coef_df) == 0:\n",
    "        print(\"警告: 没有有效的系数，无法进行归一化\")\n",
    "        return None\n",
    "    \n",
    "    # 计算系数的绝对值\n",
    "    sig_coef_df['系数绝对值'] = sig_coef_df['系数'].abs()\n",
    "    \n",
    "    # 归一化系数\n",
    "    total_abs = sig_coef_df['系数绝对值'].sum()\n",
    "    sig_coef_df['归一化系数'] = sig_coef_df['系数'] / total_abs\n",
    "    sig_coef_df['归一化系数绝对值'] = sig_coef_df['系数绝对值'] / total_abs\n",
    "    sig_coef_df['归一化系数百分比'] = sig_coef_df['归一化系数绝对值'] * 100\n",
    "    \n",
    "    # 按系数绝对值排序\n",
    "    sig_coef_df = sig_coef_df.sort_values('系数绝对值', ascending=False)\n",
    "    \n",
    "    # 显示结果\n",
    "    print(\"\\n归一化后的系数 (按绝对值排序):\")\n",
    "    print(\"-----------------------------------\")\n",
    "    significant_str = \"显著 (p<0.05)\" if len(sig_coef_df[sig_coef_df['p值'] < alpha]) > 0 else \"无显著变量\"\n",
    "    print(f\"总计 {len(sig_coef_df)} 个有效变量, {significant_str}\")\n",
    "    print(\"-----------------------------------\")\n",
    "    \n",
    "    # 先显示自变量，再显示控制变量\n",
    "    for var_type in ['自变量', '控制变量']:\n",
    "        type_df = sig_coef_df[sig_coef_df['变量类型'] == var_type]\n",
    "        if len(type_df) > 0:\n",
    "            print(f\"\\n{var_type}:\")\n",
    "            for _, row in type_df.iterrows():\n",
    "                sig_mark = \"*\" if row['p值'] < alpha else \"\"\n",
    "                print(f\"{row['变量']}: {row['系数']:.4f} (归一化: {row['归一化系数']:.4f}, {row['归一化系数百分比']:.2f}%){sig_mark}\")\n",
    "    \n",
    "    print(\"-----------------------------------\")\n",
    "    print(\"* 标记表示在0.05水平上显著\")\n",
    "    \n",
    "    # 保存到文件\n",
    "    output_file = os.path.join(folder_name, \"Comment-归一化的模型结果.txt\")\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"# {model_type.upper()} 模型归一化后的系数 (按绝对值排序)\\n\\n\")\n",
    "        f.write(\"-----------------------------------\\n\")\n",
    "        f.write(f\"总计 {len(sig_coef_df)} 个有效变量, {significant_str}\\n\")\n",
    "        f.write(\"-----------------------------------\\n\\n\")\n",
    "        \n",
    "        # 添加总表\n",
    "        f.write(\"| 变量 | 变量类型 | 系数 | p值 | 归一化系数 | 归一化百分比 | 显著性 |\\n\")\n",
    "        f.write(\"|------|---------|------|------|------------|------------|--------|\\n\")\n",
    "        \n",
    "        for _, row in sig_coef_df.iterrows():\n",
    "            sig = \"是\" if row['p值'] < alpha else \"否\"\n",
    "            f.write(f\"| {row['变量']} | {row['变量类型']} | {row['系数']:.4f} | {row['p值']:.4f} | {row['归一化系数']:.4f} | {row['归一化系数百分比']:.2f}% | {sig} |\\n\")\n",
    "        \n",
    "        f.write(\"\\n\\n## 详细分析\\n\\n\")\n",
    "        \n",
    "        # 先显示自变量，再显示控制变量\n",
    "        for var_type in ['自变量', '控制变量']:\n",
    "            type_df = sig_coef_df[sig_coef_df['变量类型'] == var_type]\n",
    "            if len(type_df) > 0:\n",
    "                f.write(f\"### {var_type}\\n\\n\")\n",
    "                \n",
    "                for _, row in type_df.iterrows():\n",
    "                    sig_symbol = \"*\" if row['p值'] < alpha else \"\"\n",
    "                    direction = \"正向\" if row['系数'] > 0 else \"负向\"\n",
    "                    f.write(f\"#### {row['变量']}{sig_symbol}\\n\\n\")\n",
    "                    f.write(f\"- 系数: {row['系数']:.4f}\\n\")\n",
    "                    f.write(f\"- p值: {row['p值']:.4f}\\n\")\n",
    "                    f.write(f\"- 影响方向: {direction}\\n\")\n",
    "                    f.write(f\"- 归一化系数: {row['归一化系数']:.4f}\\n\")\n",
    "                    f.write(f\"- 归一化百分比: {row['归一化系数百分比']:.2f}%\\n\")\n",
    "                    f.write(f\"- 是否显著: {'是' if row['p值'] < alpha else '否'}\\n\\n\")\n",
    "        \n",
    "        f.write(\"-----------------------------------\\n\")\n",
    "        f.write(\"* 标记表示在0.05水平上显著\\n\")\n",
    "    \n",
    "    print(f\"\\n结果已保存到 {output_file}\")\n",
    "    \n",
    "    return sig_coef_df\n",
    "# 调用归一化函数\n",
    "print(\"\\n开始归一化系数分析...\")\n",
    "normalized_coefs = normalize_significant_coefficients(\n",
    "    results=results,\n",
    "    iv_list=iv_list,\n",
    "    control_vars=control_vars,\n",
    "    model_type=model_type,\n",
    "    alpha=0.05\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206da568-3853-4630-97ae-945e9ba8e95c",
   "metadata": {},
   "source": [
    "### 转帖分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19e8255b-e00a-46e2-8609-f2da668b5a98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T10:46:11.645553Z",
     "iopub.status.busy": "2025-04-15T10:46:11.645553Z",
     "iopub.status.idle": "2025-04-15T10:46:12.104126Z",
     "shell.execute_reply": "2025-04-15T10:46:12.103122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据加载完成，共 605 行和 67 列\n",
      "从IV.txt加载了 18 个自变量\n",
      "将使用的控制变量: author_followers_cnt, author_friends_cnt\n",
      "已确认因变量'interaction_repost_cnt'存在于数据中\n",
      "已确认所有控制变量存在于数据中\n",
      "已创建结果文件: 生成结果/social_media/repost-模型结果.txt\n",
      "数据预览:\n",
      "                    id  title  \\\n",
      "0  1909480340126580992    NaN   \n",
      "1  1909020699747886080    NaN   \n",
      "2  1908203431765881088    NaN   \n",
      "3  1908194727209385984    NaN   \n",
      "4  1908053656731087104    NaN   \n",
      "\n",
      "                                             content  url lang  \\\n",
      "0  Metal Shoe Rack\\nUpto 24% off\\nLink for you: h...  NaN   en   \n",
      "1  @emob_ @DamnNearWhite @Tr3sMilagros @MyFirstKi...  NaN   en   \n",
      "2  J.T. Foote Adjustable Shoe Trees - Plastic \\n🛠...  NaN   en   \n",
      "3  EXVITO Metal Shoe Rack for Home – Adjustable &...  NaN   en   \n",
      "4  Closet Shoe Organizer for 24 Pairs with Adjust...  NaN   en   \n",
      "\n",
      "                     publish_time publish_time_date publish_time_time  \\\n",
      "0  Tue Apr 08 05:36:04 +0000 2025        2025-04-08          05:36:04   \n",
      "1  Sun Apr 06 23:09:37 +0000 2025        2025-04-06          23:09:37   \n",
      "2  Fri Apr 04 17:02:05 +0000 2025        2025-04-04          17:02:05   \n",
      "3  Fri Apr 04 16:27:30 +0000 2025        2025-04-04          16:27:30   \n",
      "4  Fri Apr 04 07:06:56 +0000 2025        2025-04-04          07:06:56   \n",
      "\n",
      "   is_truncated  interaction_like_cnt  ...  承重能力表达  耐用性表达  长期满意度表达  颜色选择表达  \\\n",
      "0         False                     0  ...       1      1        1       0   \n",
      "1         False                     1  ...       1      0        1       0   \n",
      "2         False                     0  ...       1      0        0       0   \n",
      "3         False                     0  ...       0      1        1       0   \n",
      "4         False                     0  ...       0      0        0       0   \n",
      "\n",
      "   季节适应性表达  品牌声誉表达  消费者信任度表达  创新功能表达  儿童友好设计表达  组合灵活性表达  \n",
      "0        1       0         1       1         0        1  \n",
      "1        1       0         1       0         1        0  \n",
      "2        0       1         1       1         0        0  \n",
      "3        1       1         0       0         0        0  \n",
      "4        0       0         0       0         0        0  \n",
      "\n",
      "[5 rows x 67 columns]\n",
      "\n",
      "## interaction_repost_cnt 分布分析结果:\n",
      "- 样本量: 605\n",
      "- 零值数量: 547\n",
      "- 零值比例: 90.4132\n",
      "- 均值: 0.4529\n",
      "- 中位数: 0.0000\n",
      "- 标准差: 3.4101\n",
      "- 最小值: 0\n",
      "- 最大值: 60\n",
      "- 偏度: 12.7440\n",
      "- 峰度: 188.0635\n",
      "\n",
      "## 推荐的模型: TOBIT\n",
      "- 变量转换: 对数转换\n",
      "- 原因: 数据中零值比例为90.41%，超过20%，使用Tobit模型。数据偏度为12.74，表现为偏态分布，对因变量进行对数转换。\n",
      "预处理后的数据: 605 行 × 21 列\n",
      "警告: interaction_repost_cnt 的最小值为 0，包含零值或负值\n",
      "将使用log(1+x)转换\n",
      "已创建对数转换变量: log_interaction_repost_cnt\n",
      "回归公式:\n",
      "log_interaction_repost_cnt ~ 安全性需求表达 + 空间效率表达 + 环保材质偏好 + 组装便捷性表达 + 设计美感表达 + 层高可调节性表达 + 防尘功能表达 + 价格表达 + 多功能性表达 + 便携性表达 + 承重能力表达 + 耐用性表达 + 颜色选择表达 + 季节适应性表达 + 品牌声誉表达 + 创新功能表达 + 儿童友好设计表达 + 组合灵活性表达 + author_followers_cnt + author_friends_cnt\n",
      "\n",
      "多重共线性检验 (VIF):\n",
      "VIF > 10 表示可能存在严重的多重共线性问题\n",
      "                      变量       VIF\n",
      "12                颜色选择表达  5.844991\n",
      "4                 设计美感表达  5.432510\n",
      "0                安全性需求表达  3.560953\n",
      "8                 多功能性表达  3.394563\n",
      "11                 耐用性表达  3.326069\n",
      "3                组装便捷性表达  3.258193\n",
      "2                 环保材质偏好  3.220954\n",
      "10                承重能力表达  3.209544\n",
      "13               季节适应性表达  3.190966\n",
      "9                  便携性表达  3.183719\n",
      "17               组合灵活性表达  3.163847\n",
      "1                 空间效率表达  2.904204\n",
      "15                创新功能表达  2.775960\n",
      "14                品牌声誉表达  2.485333\n",
      "6                 防尘功能表达  2.375646\n",
      "16              儿童友好设计表达  2.106301\n",
      "5               层高可调节性表达  1.919452\n",
      "7                   价格表达  1.672822\n",
      "19    author_friends_cnt  1.279311\n",
      "18  author_followers_cnt  1.199435\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "data_file = os.path.join(folder_name, \"数据变量语义匹配二元赋值结果.xlsx\")\n",
    "data = pd.read_excel(data_file)\n",
    "print(f\"数据加载完成，共 {len(data)} 行和 {len(data.columns)} 列\")\n",
    "\n",
    "# 修改IV文件路径\n",
    "iv_file = os.path.join(folder_name, 'IV.txt')\n",
    "with open(iv_file, 'r', encoding='utf-8') as f:\n",
    "    iv_list = f.read().splitlines()\n",
    "    iv_list = [iv.strip() for iv in iv_list if iv.strip()]  # 移除空行\n",
    "print(f\"从IV.txt加载了 {len(iv_list)} 个自变量\")\n",
    "\n",
    "# 定义因变量和控制变量\n",
    "dv_col = 'interaction_repost_cnt'\n",
    "control_vars = ['author_followers_cnt', 'author_friends_cnt']\n",
    "print(f\"将使用的控制变量: {', '.join(control_vars)}\")\n",
    "\n",
    "# 检查DV列是否存在\n",
    "if dv_col not in data.columns:\n",
    "    print(f\"错误: 数据中不存在列 '{dv_col}'\")\n",
    "    print(\"数据包含的列:\", data.columns.tolist()[:10], \"...\")\n",
    "    raise ValueError(f\"找不到DV列: {dv_col}\")\n",
    "else:\n",
    "    print(f\"已确认因变量'{dv_col}'存在于数据中\")\n",
    "\n",
    "# 检查控制变量是否存在\n",
    "missing_controls = [var for var in control_vars if var not in data.columns]\n",
    "if missing_controls:\n",
    "    print(f\"错误: 以下控制变量在数据中不存在: {missing_controls}\")\n",
    "    raise ValueError(\"缺少必要的控制变量\")\n",
    "else:\n",
    "    print(\"已确认所有控制变量存在于数据中\")\n",
    "\n",
    "# 检查IV列是否都存在\n",
    "missing_ivs = [iv for iv in iv_list if iv not in data.columns]\n",
    "if missing_ivs:\n",
    "    print(f\"警告: 以下IV在数据中不存在: {missing_ivs}\")\n",
    "    iv_list = [iv for iv in iv_list if iv in data.columns]\n",
    "    print(f\"将使用剩余的 {len(iv_list)} 个IV进行建模\")\n",
    "\n",
    "if not iv_list:\n",
    "    raise ValueError(\"没有可用的IV变量进行建模\")\n",
    "\n",
    "# 修改结果文件路径\n",
    "result_file = os.path.join(folder_name, \"repost-模型结果.txt\")\n",
    "with open(result_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"# 模型分析结果\\n\\n\")\n",
    "print(f\"已创建结果文件: {result_file}\")\n",
    "\n",
    "# 显示数据前几行\n",
    "print(\"数据预览:\")\n",
    "print(data.head())\n",
    "\n",
    "# 分析DV的分布\n",
    "def analyze_distribution(data, col):\n",
    "    \"\"\"\n",
    "    分析变量分布并返回基本统计量和模型推荐\n",
    "    \"\"\"\n",
    "    # 提取非空数据\n",
    "    valid_data = data[col].dropna()\n",
    "    \n",
    "    # 基本统计量\n",
    "    stats_dict = {\n",
    "        \"样本量\": len(valid_data),\n",
    "        \"零值数量\": (valid_data == 0).sum(),\n",
    "        \"零值比例\": (valid_data == 0).mean() * 100,\n",
    "        \"均值\": valid_data.mean(),\n",
    "        \"中位数\": valid_data.median(),\n",
    "        \"标准差\": valid_data.std(),\n",
    "        \"最小值\": valid_data.min(),\n",
    "        \"最大值\": valid_data.max(),\n",
    "        \"偏度\": skew(valid_data),\n",
    "        \"峰度\": kurtosis(valid_data)\n",
    "    }\n",
    "\n",
    "    # 模型选择逻辑 - 根据零值比例和分布偏度\n",
    "    zero_inflated = stats_dict[\"零值比例\"] > 20  # 如果零值超过20%，使用Tobit\n",
    "    high_skew = abs(stats_dict[\"偏度\"]) > 1.0   # 如果偏度较大，使用对数转换\n",
    "    \n",
    "    model_type = \"ols\"  # 默认模型类型\n",
    "    transform_type = \"none\"  # 默认不转换\n",
    "    reason = \"\"\n",
    "    \n",
    "    if zero_inflated:\n",
    "        model_type = \"tobit\"\n",
    "        reason += f\"数据中零值比例为{stats_dict['零值比例']:.2f}%，超过20%，使用Tobit模型。\"\n",
    "        \n",
    "        if high_skew:\n",
    "            transform_type = \"log\"\n",
    "            reason += f\"数据偏度为{stats_dict['偏度']:.2f}，表现为偏态分布，对因变量进行对数转换。\"\n",
    "    else:\n",
    "        model_type = \"ols\"\n",
    "        reason += f\"数据中零值比例为{stats_dict['零值比例']:.2f}%，不超过20%，使用OLS模型。\"\n",
    "        \n",
    "        if high_skew:\n",
    "            transform_type = \"log\"\n",
    "            reason += f\"数据偏度为{stats_dict['偏度']:.2f}，表现为偏态分布，对因变量进行对数转换。\"\n",
    "    \n",
    "    return model_type, transform_type, reason, stats_dict\n",
    "\n",
    "# 对DV进行分布分析\n",
    "model_type, transform_type, reason, dv_stats = analyze_distribution(data, dv_col)\n",
    "\n",
    "# 显示分析结果\n",
    "print(f\"\\n## {dv_col} 分布分析结果:\")\n",
    "for key, value in dv_stats.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"- {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"- {key}: {value}\")\n",
    "\n",
    "print(f\"\\n## 推荐的模型: {model_type.upper()}\")\n",
    "print(f\"- 变量转换: {'对数转换' if transform_type == 'log' else '不转换'}\")\n",
    "print(f\"- 原因: {reason}\")\n",
    "\n",
    "# 将结果保存到文件\n",
    "with open(result_file, 'a', encoding='utf-8') as f:\n",
    "    f.write(f\"## {dv_col} 分布分析\\n\\n\")\n",
    "    for key, value in dv_stats.items():\n",
    "        if isinstance(value, float):\n",
    "            f.write(f\"- {key}: {value:.4f}\\n\")\n",
    "        else:\n",
    "            f.write(f\"- {key}: {value}\\n\")\n",
    "    \n",
    "    f.write(f\"\\n## 模型选择\\n\\n\")\n",
    "    f.write(f\"- 推荐的模型类型: {model_type.upper()}\\n\")\n",
    "    f.write(f\"- 变量转换: {'对数转换' if transform_type == 'log' else '不转换'}\\n\")\n",
    "    f.write(f\"- 选择原因: {reason}\\n\\n\")\n",
    "\n",
    "# 准备建模数据\n",
    "all_predictors = iv_list + control_vars\n",
    "model_data = data[[dv_col] + all_predictors].copy()\n",
    "model_data = model_data.dropna()  # 移除有缺失值的行\n",
    "print(f\"预处理后的数据: {len(model_data)} 行 × {len(model_data.columns)} 列\")\n",
    "\n",
    "# 处理因变量转换\n",
    "transformed_dv = dv_col\n",
    "if transform_type == \"log\":\n",
    "    # 检查零值和负值\n",
    "    min_value = model_data[dv_col].min()\n",
    "    if min_value <= 0:\n",
    "        print(f\"警告: {dv_col} 的最小值为 {min_value}，包含零值或负值\")\n",
    "        print(\"将使用log(1+x)转换\")\n",
    "        model_data[f'log_{dv_col}'] = np.log1p(model_data[dv_col])\n",
    "    else:\n",
    "        model_data[f'log_{dv_col}'] = np.log(model_data[dv_col])\n",
    "    transformed_dv = f'log_{dv_col}'\n",
    "    print(f\"已创建对数转换变量: {transformed_dv}\")\n",
    "else:\n",
    "    print(f\"使用原始变量: {transformed_dv}\")\n",
    "\n",
    "# 构建公式并显示\n",
    "formula = f\"{transformed_dv} ~ \" + \" + \".join(all_predictors)\n",
    "print(f\"回归公式:\")\n",
    "print(formula)\n",
    "\n",
    "# 检查多重共线性\n",
    "if len(all_predictors) > 1:\n",
    "    X = model_data[all_predictors]\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"变量\"] = X.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    print(\"\\n多重共线性检验 (VIF):\")\n",
    "    print(\"VIF > 10 表示可能存在严重的多重共线性问题\")\n",
    "    print(vif_data.sort_values(\"VIF\", ascending=False))\n",
    "\n",
    "    with open(result_file, 'a', encoding='utf-8') as f:\n",
    "        f.write(\"## 多重共线性检验 (VIF)\\n\\n\")\n",
    "        f.write(\"VIF > 10 表示可能存在严重的多重共线性问题\\n\\n\")\n",
    "        f.write(\"| 变量 | VIF |\\n\")\n",
    "        f.write(\"|------|------|\\n\")\n",
    "        for index, row in vif_data.iterrows():\n",
    "            f.write(f\"| {row['变量']} | {row['VIF']:.4f} |\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4004311b-3759-4073-b2fc-7d72aafa7f98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T10:46:12.104126Z",
     "iopub.status.busy": "2025-04-15T10:46:12.104126Z",
     "iopub.status.idle": "2025-04-15T10:46:12.590886Z",
     "shell.execute_reply": "2025-04-15T10:46:12.590886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始拟合TOBIT模型...\n",
      "使用改进的自定义Tobit模型实现...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\Lynx\\lib\\site-packages\\statsmodels\\base\\optimizer.py:19: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method nm is: xtol, ftol, maxfun. The list of unsupported keyword arguments passed include: options. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tobit模型结果:\n",
      "                              TobitModel Results                              \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   Log-Likelihood:                -376.47\n",
      "Model:                     TobitModel   AIC:                             796.9\n",
      "Method:            Maximum Likelihood   BIC:                             893.9\n",
      "Date:                Tue, 15 Apr 2025                                         \n",
      "Time:                        18:46:12                                         \n",
      "No. Observations:                 605                                         \n",
      "Df Residuals:                     584                                         \n",
      "Df Model:                          20                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0062        nan        nan        nan         nan         nan\n",
      "x1            -0.4776        nan        nan        nan         nan         nan\n",
      "x2            -0.1491        nan        nan        nan         nan         nan\n",
      "x3             0.1470        nan        nan        nan         nan         nan\n",
      "x4            -0.0402        nan        nan        nan         nan         nan\n",
      "x5            -0.0003        nan        nan        nan         nan         nan\n",
      "x6            -0.1915        nan        nan        nan         nan         nan\n",
      "x7             0.0037        nan        nan        nan         nan         nan\n",
      "x8             0.1713        nan        nan        nan         nan         nan\n",
      "x9            -0.0902        nan        nan        nan         nan         nan\n",
      "x10           -0.2699        nan        nan        nan         nan         nan\n",
      "x11           -0.0998        nan        nan        nan         nan         nan\n",
      "x12           -0.1068        nan        nan        nan         nan         nan\n",
      "x13           -0.0052        nan        nan        nan         nan         nan\n",
      "x14           -0.1740        nan        nan        nan         nan         nan\n",
      "x15           -0.3071        nan        nan        nan         nan         nan\n",
      "x16           -0.0277        nan        nan        nan         nan         nan\n",
      "x17           -0.2253        nan        nan        nan         nan         nan\n",
      "x18            0.1302        nan        nan        nan         nan         nan\n",
      "x19         -2.22e-08        nan        nan        nan         nan         nan\n",
      "x20         6.498e-05        nan        nan        nan         nan         nan\n",
      "par0           1.3872        nan        nan        nan         nan         nan\n",
      "==============================================================================\n",
      "\n",
      "模型解读:\n",
      "- Tobit模型统计量:\n",
      "  - 对数似然值: -376.4680\n",
      "  - AIC: 796.9360\n",
      "  - BIC: 893.8511\n",
      "警告: p值计算失败，将使用系数作为显著性的近似指标\n",
      "\n",
      "显著的变量 (p < 0.05): 12/19\n",
      "\n",
      "显著的自变量: 12/18\n",
      "- 安全性需求表达: 系数=-0.4776, p=0.000000\n",
      "- 空间效率表达: 系数=-0.1491, p=0.002860\n",
      "- 环保材质偏好: 系数=0.1470, p=0.003292\n",
      "- 层高可调节性表达: 系数=-0.1915, p=0.000128\n",
      "- 价格表达: 系数=0.1713, p=0.000614\n",
      "- 便携性表达: 系数=-0.2699, p=0.000000\n",
      "- 承重能力表达: 系数=-0.0998, p=0.045950\n",
      "- 耐用性表达: 系数=-0.1068, p=0.032646\n",
      "- 季节适应性表达: 系数=-0.1740, p=0.000503\n",
      "- 品牌声誉表达: 系数=-0.3071, p=0.000000\n",
      "- 儿童友好设计表达: 系数=-0.2253, p=0.000007\n",
      "- 组合灵活性表达: 系数=0.1302, p=0.009215\n",
      "\n",
      "显著的控制变量: 0/2\n",
      "\n",
      "模型解读:\n",
      "- Tobit模型统计量:\n",
      "  - 对数似然值: -376.4680\n",
      "  - AIC: 796.9360\n",
      "  - BIC: 893.8511\n",
      "\n",
      "显著的变量 (p < 0.05): 0/19\n",
      "\n",
      "显著的自变量: 0/18\n",
      "\n",
      "显著的控制变量: 0/2\n",
      "\n",
      "所有分析结果已保存到 生成结果/social_media/repost-模型结果.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\Lynx\\lib\\site-packages\\statsmodels\\base\\model.py:595: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  warnings.warn('Inverting hessian failed, no bse or cov_params '\n",
      "C:\\Users\\admin\\anaconda3\\envs\\Lynx\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\admin\\anaconda3\\envs\\Lynx\\lib\\site-packages\\statsmodels\\base\\model.py:2748: UserWarning: df_model + k_constant + k_extra differs from k_params\n",
      "  warnings.warn(\"df_model + k_constant + k_extra \"\n",
      "C:\\Users\\admin\\anaconda3\\envs\\Lynx\\lib\\site-packages\\statsmodels\\base\\model.py:2752: UserWarning: df_resid differs from nobs - k_params\n",
      "  warnings.warn(\"df_resid differs from nobs - k_params\")\n"
     ]
    }
   ],
   "source": [
    "print(f\"开始拟合{model_type.upper()}模型...\")\n",
    "\n",
    "if model_type == \"tobit\":\n",
    "    # 尝试不同的导入方式\n",
    "    try:\n",
    "        # 尝试从truncated_model模块导入\n",
    "        from statsmodels.discrete.truncated_model import Tobit\n",
    "        \n",
    "        # 准备数据\n",
    "        y = model_data[transformed_dv].values\n",
    "        X = sm.add_constant(model_data[all_predictors])\n",
    "        \n",
    "        print(\"使用statsmodels.discrete.truncated_model中的Tobit模型...\")\n",
    "        tobit_model = Tobit(y, X, left=0)\n",
    "        results = tobit_model.fit(method='powell', disp=0, maxiter=10000)\n",
    "        \n",
    "    except (ImportError, AttributeError):\n",
    "        # 如果上述导入失败，使用censored_model模块\n",
    "        try:\n",
    "            from statsmodels.regression.censored_model import Tobit\n",
    "            \n",
    "            # 准备数据\n",
    "            y = model_data[transformed_dv].values\n",
    "            X = sm.add_constant(model_data[all_predictors])\n",
    "            \n",
    "            print(\"使用statsmodels.regression.censored_model中的Tobit模型...\")\n",
    "            tobit_model = Tobit(y, X, left=0)\n",
    "            results = tobit_model.fit(method='powell', disp=0, maxiter=10000)\n",
    "            \n",
    "        except (ImportError, AttributeError):\n",
    "            # 如果上述方法都失败，使用改进的自定义实现\n",
    "            print(\"使用改进的自定义Tobit模型实现...\")\n",
    "            from scipy.stats import norm\n",
    "            from scipy import optimize\n",
    "            from statsmodels.regression.linear_model import OLS\n",
    "            from statsmodels.base.model import GenericLikelihoodModel\n",
    "            \n",
    "            class TobitModel(GenericLikelihoodModel):\n",
    "                def __init__(self, endog, exog, left=0, **kwds):\n",
    "                    self.left = left\n",
    "                    super(TobitModel, self).__init__(endog, exog, **kwds)\n",
    "                \n",
    "                def loglikeobs(self, params):\n",
    "                    beta = params[:-1]\n",
    "                    sigma = np.abs(params[-1])  # 确保sigma为正\n",
    "                    \n",
    "                    q = self.endog\n",
    "                    x = self.exog\n",
    "                    \n",
    "                    # 计算条件期望\n",
    "                    mu = np.dot(x, beta)\n",
    "                    \n",
    "                    # 分别计算截尾和非截尾值的对数似然\n",
    "                    censored_mask = (q <= self.left)\n",
    "                    z = (self.left - mu) / sigma\n",
    "                    \n",
    "                    ll_censored = censored_mask * norm.logcdf(z)\n",
    "                    \n",
    "                    non_censored_mask = ~censored_mask\n",
    "                    ll_non_censored = non_censored_mask * (\n",
    "                        -np.log(sigma) + \n",
    "                        norm.logpdf((q - mu) / sigma)\n",
    "                    )\n",
    "                    \n",
    "                    # 处理可能的数值问题\n",
    "                    result = ll_censored + ll_non_censored\n",
    "                    # 替换无效值\n",
    "                    result = np.where(np.isnan(result) | np.isinf(result), -1e10, result)\n",
    "                    \n",
    "                    return result\n",
    "                \n",
    "                def nloglikeobs(self, params):\n",
    "                    \"\"\"负对数似然\"\"\"\n",
    "                    return -self.loglikeobs(params)\n",
    "                \n",
    "                def fit(self, start_params=None, method='bfgs', maxiter=50000, **kwds):\n",
    "                    \"\"\"添加更多优化方法选项和更好的初始值策略\"\"\"\n",
    "                    if start_params is None:\n",
    "                        # 使用OLS估计获取更稳定的初始值\n",
    "                        ols_model = OLS(\n",
    "                            np.where(self.endog <= self.left, self.left, self.endog),\n",
    "                            self.exog\n",
    "                        )\n",
    "                        ols_res = ols_model.fit()\n",
    "                        # 使用残差的标准差作为sigma的初始值\n",
    "                        start_params = np.append(ols_res.params, np.std(ols_res.resid))\n",
    "                    \n",
    "                    # 添加更多优化选项\n",
    "                    if 'options' not in kwds:\n",
    "                        kwds['options'] = {}\n",
    "                    kwds['options']['maxiter'] = maxiter\n",
    "                    \n",
    "                    # 添加容错设置\n",
    "                    try:\n",
    "                        return super(TobitModel, self).fit(\n",
    "                            start_params=start_params,\n",
    "                            method=method, \n",
    "                            **kwds\n",
    "                        )\n",
    "                    except Exception as e:\n",
    "                        print(f\"首次优化失败: {str(e)}，尝试备用方法...\")\n",
    "                        try:\n",
    "                            # 尝试Powell方法\n",
    "                            return super(TobitModel, self).fit(\n",
    "                                start_params=start_params,\n",
    "                                method='powell',\n",
    "                                options={'maxiter': 100000, 'ftol': 1e-8, 'xtol': 1e-8},\n",
    "                                **kwds\n",
    "                            )\n",
    "                        except:\n",
    "                            print(\"所有优化方法失败，尝试最简单的优化设置...\")\n",
    "                            return super(TobitModel, self).fit(\n",
    "                                start_params=start_params,\n",
    "                                method='nm',\n",
    "                                options={'maxiter': 100000},\n",
    "                                **kwds\n",
    "                            )\n",
    "            \n",
    "            # 准备数据 - 修改数据准备部分以避免AttributeError\n",
    "            y = model_data[transformed_dv].values\n",
    "            X_df = sm.add_constant(model_data[all_predictors])  # 保持DataFrame格式\n",
    "            X_array = X_df.values  # 数组版本用于拟合\n",
    "            X_columns = X_df.columns.tolist()  # 保存列名供后续使用\n",
    "            \n",
    "            # 拟合Tobit模型，尝试多种方法\n",
    "            tobit_model = TobitModel(y, X_array, left=0)\n",
    "            try:\n",
    "                # 首先尝试Nelder-Mead方法\n",
    "                results = tobit_model.fit(method='nm', disp=0, maxiter=50000)\n",
    "            except:\n",
    "                try:\n",
    "                    # 如果失败，尝试BFGS方法\n",
    "                    results = tobit_model.fit(method='bfgs', disp=0, maxiter=50000)\n",
    "                except:\n",
    "                    # 最后尝试Powell方法\n",
    "                    results = tobit_model.fit(method='powell', disp=0, maxiter=50000)\n",
    "    \n",
    "    # 打印结果\n",
    "    print(\"\\nTobit模型结果:\")\n",
    "    print(results.summary())\n",
    "    \n",
    "else:  # 使用OLS模型 - 保持不变\n",
    "    # 创建并拟合模型\n",
    "    model = smf.ols(formula=formula, data=model_data)\n",
    "    results = model.fit()\n",
    "    \n",
    "    # 显示结果摘要\n",
    "    print(\"\\nOLS回归结果:\")\n",
    "    print(results.summary())\n",
    "\n",
    "# 保存结果\n",
    "with open(result_file, 'a', encoding='utf-8') as f:\n",
    "    f.write(f\"## {model_type.upper()}回归结果\\n\\n\")\n",
    "    f.write(f\"被解释变量: {transformed_dv}\\n\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(str(results.summary()))\n",
    "    f.write(\"\\n\\n\\n\")\n",
    "\n",
    "# 模型结果解读\n",
    "print(\"\\n模型解读:\")\n",
    "\n",
    "if model_type == \"ols\":\n",
    "    # OLS模型特有的解读 - 保持不变\n",
    "    print(f\"- 模型解释力 (R²): {results.rsquared:.4f}\")\n",
    "    print(f\"- 调整后的R²: {results.rsquared_adj:.4f}\")\n",
    "    print(f\"- 模型整体显著性: F({results.df_model:.0f},{results.df_resid:.0f})={results.fvalue:.4f}, p={results.f_pvalue:.6f}\")\n",
    "    \n",
    "    if results.f_pvalue < 0.05:\n",
    "        print(\"  结论: 模型整体上显著\")\n",
    "    else:\n",
    "        print(\"  结论: 模型整体上不显著\")\n",
    "    \n",
    "    # 获取显著的变量\n",
    "    p_values = results.pvalues[1:]  # 跳过截距\n",
    "    var_names = all_predictors\n",
    "    \n",
    "else:  # Tobit模型 - 修改此部分以处理可能的NaN问题\n",
    "    print(\"- Tobit模型统计量:\")\n",
    "    print(f\"  - 对数似然值: {results.llf:.4f}\")\n",
    "    print(f\"  - AIC: {results.aic:.4f}\")\n",
    "    print(f\"  - BIC: {results.bic:.4f}\")\n",
    "    \n",
    "    # 安全获取Tobit模型的系数和p值\n",
    "    if hasattr(results, 'pvalues') and not np.all(np.isnan(results.pvalues)):\n",
    "        p_values = results.pvalues[1:-1]  # 跳过截距和sigma\n",
    "    else:\n",
    "        print(\"警告: p值计算失败，将使用系数作为显著性的近似指标\")\n",
    "        # 使用系数作为显著性的近似指标\n",
    "        coefs = results.params[1:-1]\n",
    "        se = np.ones_like(coefs) * 0.05  # 假设标准误为0.05\n",
    "        p_values = 2 * (1 - norm.cdf(np.abs(coefs / se)))\n",
    "    \n",
    "    # 在自定义Tobit中X_columns已定义，在statsmodels版本中需要定义\n",
    "    if 'X_columns' not in locals():\n",
    "        X_columns = model_data[all_predictors].columns.tolist()\n",
    "        X_columns = ['const'] + X_columns\n",
    "    \n",
    "    var_names = X_columns[1:-1] if model_type == \"tobit\" else X_columns[1:]  # 适应不同情况\n",
    "\n",
    "# 显著变量分析（对两种模型通用）\n",
    "significant_mask = p_values < 0.05\n",
    "significant_vars = [var for var, sig in zip(var_names, significant_mask) if sig]\n",
    "print(f\"\\n显著的变量 (p < 0.05): {len(significant_vars)}/{len(var_names)}\")\n",
    "\n",
    "iv_significant = [var for var in significant_vars if var in iv_list]\n",
    "ctrl_significant = [var for var in significant_vars if var in control_vars]\n",
    "\n",
    "# 显示显著的自变量\n",
    "print(f\"\\n显著的自变量: {len(iv_significant)}/{len(iv_list)}\")\n",
    "for var in iv_significant:\n",
    "    idx = var_names.index(var)\n",
    "    coef = results.params[idx + 1]  # +1 to skip intercept\n",
    "    p = p_values[idx]\n",
    "    print(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\")\n",
    "\n",
    "# 显示显著的控制变量\n",
    "print(f\"\\n显著的控制变量: {len(ctrl_significant)}/{len(control_vars)}\")\n",
    "for var in ctrl_significant:\n",
    "    idx = var_names.index(var)\n",
    "    coef = results.params[idx + 1]  # +1 to skip intercept\n",
    "    p = p_values[idx]\n",
    "    print(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\")\n",
    "\n",
    "# 保存结果\n",
    "with open(result_file, 'a', encoding='utf-8') as f:\n",
    "    f.write(f\"## {model_type.upper()}回归结果\\n\\n\")\n",
    "    f.write(f\"被解释变量: {transformed_dv}\\n\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(str(results.summary()))\n",
    "    f.write(\"\\n\\n\\n\")\n",
    "\n",
    "# 模型结果解读\n",
    "print(\"\\n模型解读:\")\n",
    "\n",
    "if model_type == \"ols\":\n",
    "    # OLS模型特有的解读\n",
    "    print(f\"- 模型解释力 (R²): {results.rsquared:.4f}\")\n",
    "    print(f\"- 调整后的R²: {results.rsquared_adj:.4f}\")\n",
    "    print(f\"- 模型整体显著性: F({results.df_model:.0f},{results.df_resid:.0f})={results.fvalue:.4f}, p={results.f_pvalue:.6f}\")\n",
    "    \n",
    "    if results.f_pvalue < 0.05:\n",
    "        print(\"  结论: 模型整体上显著\")\n",
    "    else:\n",
    "        print(\"  结论: 模型整体上不显著\")\n",
    "    \n",
    "    # 获取显著的变量\n",
    "    p_values = results.pvalues[1:]  # 跳过截距\n",
    "    var_names = all_predictors\n",
    "    \n",
    "else:  # Tobit模型\n",
    "    print(\"- Tobit模型统计量:\")\n",
    "    print(f\"  - 对数似然值: {results.llf:.4f}\")\n",
    "    print(f\"  - AIC: {results.aic:.4f}\")\n",
    "    print(f\"  - BIC: {results.bic:.4f}\")\n",
    "    \n",
    "    # Tobit模型中获取系数和p值\n",
    "    p_values = results.pvalues[1:-1]  # 跳过截距和sigma\n",
    "    var_names = list(X.columns[1:])  # 跳过常数项\n",
    "\n",
    "# 显著变量分析（对两种模型通用）\n",
    "significant_mask = p_values < 0.05\n",
    "significant_vars = [var for var, sig in zip(var_names, significant_mask) if sig]\n",
    "print(f\"\\n显著的变量 (p < 0.05): {len(significant_vars)}/{len(var_names)}\")\n",
    "\n",
    "iv_significant = [var for var in significant_vars if var in iv_list]\n",
    "ctrl_significant = [var for var in significant_vars if var in control_vars]\n",
    "\n",
    "# 显示显著的自变量\n",
    "print(f\"\\n显著的自变量: {len(iv_significant)}/{len(iv_list)}\")\n",
    "for var in iv_significant:\n",
    "    idx = var_names.index(var)\n",
    "    coef = results.params[idx + 1]  # +1 to skip intercept\n",
    "    p = p_values[idx]\n",
    "    print(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\")\n",
    "\n",
    "# 显示显著的控制变量\n",
    "print(f\"\\n显著的控制变量: {len(ctrl_significant)}/{len(control_vars)}\")\n",
    "for var in ctrl_significant:\n",
    "    idx = var_names.index(var)\n",
    "    coef = results.params[idx + 1]  # +1 to skip intercept\n",
    "    p = p_values[idx]\n",
    "    print(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\")\n",
    "\n",
    "# 保存解读结果\n",
    "with open(result_file, 'a', encoding='utf-8') as f:\n",
    "    f.write(\"## 模型结果解读\\n\\n\")\n",
    "    \n",
    "    if model_type == \"ols\":\n",
    "        f.write(f\"- 模型解释力 (R²): {results.rsquared:.4f}\\n\")\n",
    "        f.write(f\"- 调整后的R²: {results.rsquared_adj:.4f}\\n\")\n",
    "        f.write(f\"- 模型整体显著性: F({results.df_model:.0f},{results.df_resid:.0f})={results.fvalue:.4f}, p={results.f_pvalue:.6f}\\n\")\n",
    "        \n",
    "        if results.f_pvalue < 0.05:\n",
    "            f.write(\"  结论: 模型整体上显著\\n\\n\")\n",
    "        else:\n",
    "            f.write(\"  结论: 模型整体上不显著\\n\\n\")\n",
    "    else:\n",
    "        f.write(\"- Tobit模型统计量:\\n\")\n",
    "        f.write(f\"  - 对数似然值: {results.llf:.4f}\\n\")\n",
    "        f.write(f\"  - AIC: {results.aic:.4f}\\n\")\n",
    "        f.write(f\"  - BIC: {results.bic:.4f}\\n\\n\")\n",
    "    \n",
    "    f.write(f\"显著的变量 (p < 0.05): {len(significant_vars)}/{len(var_names)}\\n\\n\")\n",
    "    \n",
    "    f.write(f\"显著的自变量: {len(iv_significant)}/{len(iv_list)}\\n\")\n",
    "    for var in iv_significant:\n",
    "        idx = var_names.index(var)\n",
    "        coef = results.params[idx + 1]\n",
    "        p = p_values[idx]\n",
    "        f.write(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\\n\")\n",
    "    \n",
    "    f.write(f\"\\n显著的控制变量: {len(ctrl_significant)}/{len(control_vars)}\\n\")\n",
    "    for var in ctrl_significant:\n",
    "        idx = var_names.index(var)\n",
    "        coef = results.params[idx + 1]\n",
    "        p = p_values[idx]\n",
    "        f.write(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\\n\")\n",
    "\n",
    "print(f\"\\n所有分析结果已保存到 {result_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a737a6b-afeb-4d91-a1e7-f4f8ede9aaea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T10:46:12.592568Z",
     "iopub.status.busy": "2025-04-15T10:46:12.592568Z",
     "iopub.status.idle": "2025-04-15T10:46:12.621050Z",
     "shell.execute_reply": "2025-04-15T10:46:12.621050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始归一化系数分析...\n",
      "注意: 没有显著的变量 (p < 0.05)，将使用所有非NaN系数变量\n",
      "\n",
      "归一化后的系数 (按绝对值排序):\n",
      "-----------------------------------\n",
      "总计 20 个有效变量, 无显著变量\n",
      "-----------------------------------\n",
      "\n",
      "自变量:\n",
      "安全性需求表达: -0.4776 (归一化: -0.1825, 18.25%)\n",
      "品牌声誉表达: -0.3071 (归一化: -0.1173, 11.73%)\n",
      "便携性表达: -0.2699 (归一化: -0.1032, 10.32%)\n",
      "儿童友好设计表达: -0.2253 (归一化: -0.0861, 8.61%)\n",
      "层高可调节性表达: -0.1915 (归一化: -0.0732, 7.32%)\n",
      "季节适应性表达: -0.1740 (归一化: -0.0665, 6.65%)\n",
      "价格表达: 0.1713 (归一化: 0.0655, 6.55%)\n",
      "空间效率表达: -0.1491 (归一化: -0.0570, 5.70%)\n",
      "环保材质偏好: 0.1470 (归一化: 0.0562, 5.62%)\n",
      "组合灵活性表达: 0.1302 (归一化: 0.0498, 4.98%)\n",
      "耐用性表达: -0.1068 (归一化: -0.0408, 4.08%)\n",
      "承重能力表达: -0.0998 (归一化: -0.0381, 3.81%)\n",
      "多功能性表达: -0.0902 (归一化: -0.0345, 3.45%)\n",
      "组装便捷性表达: -0.0402 (归一化: -0.0154, 1.54%)\n",
      "创新功能表达: -0.0277 (归一化: -0.0106, 1.06%)\n",
      "颜色选择表达: -0.0052 (归一化: -0.0020, 0.20%)\n",
      "防尘功能表达: 0.0037 (归一化: 0.0014, 0.14%)\n",
      "设计美感表达: -0.0003 (归一化: -0.0001, 0.01%)\n",
      "\n",
      "控制变量:\n",
      "author_friends_cnt: 0.0001 (归一化: 0.0000, 0.00%)\n",
      "author_followers_cnt: -0.0000 (归一化: -0.0000, 0.00%)\n",
      "-----------------------------------\n",
      "* 标记表示在0.05水平上显著\n",
      "\n",
      "结果已保存到 生成结果/social_media/Repost-归一化的模型结果.txt\n"
     ]
    }
   ],
   "source": [
    "# 归一化显著系数并输出结果\n",
    "def normalize_significant_coefficients(results, iv_list, control_vars=None, model_type=\"ols\", alpha=0.05):\n",
    "    \"\"\"\n",
    "    归一化显著变量的系数，删除NaN值，按绝对值大小排序并输出结果\n",
    "    \n",
    "    参数:\n",
    "    - results: 回归结果对象\n",
    "    - iv_list: 自变量列表\n",
    "    - control_vars: 控制变量列表，默认为None\n",
    "    - model_type: 模型类型，\"ols\"或\"tobit\"\n",
    "    - alpha: 显著性水平，默认0.05\n",
    "    \"\"\"\n",
    "    if control_vars is None:\n",
    "        control_vars = []\n",
    "    \n",
    "    all_vars = iv_list + control_vars\n",
    "    \n",
    "    # 获取系数和p值 - 需要考虑不同模型类型\n",
    "    if model_type.lower() == \"ols\":\n",
    "        # OLS模型 - 跳过截距\n",
    "        coefs = results.params[1:len(all_vars)+1]\n",
    "        p_values = results.pvalues[1:len(all_vars)+1]\n",
    "    else:\n",
    "        # Tobit模型 - 跳过截距和sigma\n",
    "        coefs = results.params[1:len(all_vars)+1]\n",
    "        p_values = results.pvalues[1:len(all_vars)+1]\n",
    "    \n",
    "    # 创建DataFrame\n",
    "    coef_df = pd.DataFrame({\n",
    "        '变量': all_vars,\n",
    "        '系数': coefs,\n",
    "        'p值': p_values,\n",
    "        '变量类型': ['自变量' if var in iv_list else '控制变量' for var in all_vars]\n",
    "    })\n",
    "    \n",
    "    # 过滤掉NaN系数和非显著的变量\n",
    "    valid_coef_df = coef_df.dropna(subset=['系数'])\n",
    "    sig_coef_df = valid_coef_df[valid_coef_df['p值'] < alpha].copy()\n",
    "    \n",
    "    # 如果没有显著变量，则报告所有有效变量\n",
    "    if len(sig_coef_df) == 0:\n",
    "        print(\"注意: 没有显著的变量 (p < 0.05)，将使用所有非NaN系数变量\")\n",
    "        sig_coef_df = valid_coef_df.copy()\n",
    "    \n",
    "    # 如果没有有效系数，退出\n",
    "    if len(sig_coef_df) == 0:\n",
    "        print(\"警告: 没有有效的系数，无法进行归一化\")\n",
    "        return None\n",
    "    \n",
    "    # 计算系数的绝对值\n",
    "    sig_coef_df['系数绝对值'] = sig_coef_df['系数'].abs()\n",
    "    \n",
    "    # 归一化系数\n",
    "    total_abs = sig_coef_df['系数绝对值'].sum()\n",
    "    sig_coef_df['归一化系数'] = sig_coef_df['系数'] / total_abs\n",
    "    sig_coef_df['归一化系数绝对值'] = sig_coef_df['系数绝对值'] / total_abs\n",
    "    sig_coef_df['归一化系数百分比'] = sig_coef_df['归一化系数绝对值'] * 100\n",
    "    \n",
    "    # 按系数绝对值排序\n",
    "    sig_coef_df = sig_coef_df.sort_values('系数绝对值', ascending=False)\n",
    "    \n",
    "    # 显示结果\n",
    "    print(\"\\n归一化后的系数 (按绝对值排序):\")\n",
    "    print(\"-----------------------------------\")\n",
    "    significant_str = \"显著 (p<0.05)\" if len(sig_coef_df[sig_coef_df['p值'] < alpha]) > 0 else \"无显著变量\"\n",
    "    print(f\"总计 {len(sig_coef_df)} 个有效变量, {significant_str}\")\n",
    "    print(\"-----------------------------------\")\n",
    "    \n",
    "    # 先显示自变量，再显示控制变量\n",
    "    for var_type in ['自变量', '控制变量']:\n",
    "        type_df = sig_coef_df[sig_coef_df['变量类型'] == var_type]\n",
    "        if len(type_df) > 0:\n",
    "            print(f\"\\n{var_type}:\")\n",
    "            for _, row in type_df.iterrows():\n",
    "                sig_mark = \"*\" if row['p值'] < alpha else \"\"\n",
    "                print(f\"{row['变量']}: {row['系数']:.4f} (归一化: {row['归一化系数']:.4f}, {row['归一化系数百分比']:.2f}%){sig_mark}\")\n",
    "    \n",
    "    print(\"-----------------------------------\")\n",
    "    print(\"* 标记表示在0.05水平上显著\")\n",
    "    \n",
    "    # 保存到文件\n",
    "    output_file = os.path.join(folder_name, \"Repost-归一化的模型结果.txt\")\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"# {model_type.upper()} 模型归一化后的系数 (按绝对值排序)\\n\\n\")\n",
    "        f.write(\"-----------------------------------\\n\")\n",
    "        f.write(f\"总计 {len(sig_coef_df)} 个有效变量, {significant_str}\\n\")\n",
    "        f.write(\"-----------------------------------\\n\\n\")\n",
    "        \n",
    "        # 添加总表\n",
    "        f.write(\"| 变量 | 变量类型 | 系数 | p值 | 归一化系数 | 归一化百分比 | 显著性 |\\n\")\n",
    "        f.write(\"|------|---------|------|------|------------|------------|--------|\\n\")\n",
    "        \n",
    "        for _, row in sig_coef_df.iterrows():\n",
    "            sig = \"是\" if row['p值'] < alpha else \"否\"\n",
    "            f.write(f\"| {row['变量']} | {row['变量类型']} | {row['系数']:.4f} | {row['p值']:.4f} | {row['归一化系数']:.4f} | {row['归一化系数百分比']:.2f}% | {sig} |\\n\")\n",
    "        \n",
    "        f.write(\"\\n\\n## 详细分析\\n\\n\")\n",
    "        \n",
    "        # 先显示自变量，再显示控制变量\n",
    "        for var_type in ['自变量', '控制变量']:\n",
    "            type_df = sig_coef_df[sig_coef_df['变量类型'] == var_type]\n",
    "            if len(type_df) > 0:\n",
    "                f.write(f\"### {var_type}\\n\\n\")\n",
    "                \n",
    "                for _, row in type_df.iterrows():\n",
    "                    sig_symbol = \"*\" if row['p值'] < alpha else \"\"\n",
    "                    direction = \"正向\" if row['系数'] > 0 else \"负向\"\n",
    "                    f.write(f\"#### {row['变量']}{sig_symbol}\\n\\n\")\n",
    "                    f.write(f\"- 系数: {row['系数']:.4f}\\n\")\n",
    "                    f.write(f\"- p值: {row['p值']:.4f}\\n\")\n",
    "                    f.write(f\"- 影响方向: {direction}\\n\")\n",
    "                    f.write(f\"- 归一化系数: {row['归一化系数']:.4f}\\n\")\n",
    "                    f.write(f\"- 归一化百分比: {row['归一化系数百分比']:.2f}%\\n\")\n",
    "                    f.write(f\"- 是否显著: {'是' if row['p值'] < alpha else '否'}\\n\\n\")\n",
    "        \n",
    "        f.write(\"-----------------------------------\\n\")\n",
    "        f.write(\"* 标记表示在0.05水平上显著\\n\")\n",
    "    \n",
    "    print(f\"\\n结果已保存到 {output_file}\")\n",
    "    \n",
    "    return sig_coef_df\n",
    "# 调用归一化函数\n",
    "print(\"\\n开始归一化系数分析...\")\n",
    "normalized_coefs = normalize_significant_coefficients(\n",
    "    results=results,\n",
    "    iv_list=iv_list,\n",
    "    control_vars=control_vars,\n",
    "    model_type=model_type,\n",
    "    alpha=0.05\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04c4713-30a8-42cb-b400-894fd87bb7aa",
   "metadata": {},
   "source": [
    "### 分享分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "680658d8-ada1-46a3-8e71-bc9efe08b485",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T10:46:12.621050Z",
     "iopub.status.busy": "2025-04-15T10:46:12.621050Z",
     "iopub.status.idle": "2025-04-15T10:46:13.155661Z",
     "shell.execute_reply": "2025-04-15T10:46:13.154902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据加载完成，共 605 行和 67 列\n",
      "从IV.txt加载了 18 个自变量\n",
      "将使用的控制变量: author_followers_cnt, author_friends_cnt\n",
      "已确认因变量'interaction_share_cnt'存在于数据中\n",
      "已确认所有控制变量存在于数据中\n",
      "已创建结果文件: 生成结果/social_media/share-模型结果.txt\n",
      "数据预览:\n",
      "                    id  title  \\\n",
      "0  1909480340126580992    NaN   \n",
      "1  1909020699747886080    NaN   \n",
      "2  1908203431765881088    NaN   \n",
      "3  1908194727209385984    NaN   \n",
      "4  1908053656731087104    NaN   \n",
      "\n",
      "                                             content  url lang  \\\n",
      "0  Metal Shoe Rack\\nUpto 24% off\\nLink for you: h...  NaN   en   \n",
      "1  @emob_ @DamnNearWhite @Tr3sMilagros @MyFirstKi...  NaN   en   \n",
      "2  J.T. Foote Adjustable Shoe Trees - Plastic \\n🛠...  NaN   en   \n",
      "3  EXVITO Metal Shoe Rack for Home – Adjustable &...  NaN   en   \n",
      "4  Closet Shoe Organizer for 24 Pairs with Adjust...  NaN   en   \n",
      "\n",
      "                     publish_time publish_time_date publish_time_time  \\\n",
      "0  Tue Apr 08 05:36:04 +0000 2025        2025-04-08          05:36:04   \n",
      "1  Sun Apr 06 23:09:37 +0000 2025        2025-04-06          23:09:37   \n",
      "2  Fri Apr 04 17:02:05 +0000 2025        2025-04-04          17:02:05   \n",
      "3  Fri Apr 04 16:27:30 +0000 2025        2025-04-04          16:27:30   \n",
      "4  Fri Apr 04 07:06:56 +0000 2025        2025-04-04          07:06:56   \n",
      "\n",
      "   is_truncated  interaction_like_cnt  ...  承重能力表达  耐用性表达  长期满意度表达  颜色选择表达  \\\n",
      "0         False                     0  ...       1      1        1       0   \n",
      "1         False                     1  ...       1      0        1       0   \n",
      "2         False                     0  ...       1      0        0       0   \n",
      "3         False                     0  ...       0      1        1       0   \n",
      "4         False                     0  ...       0      0        0       0   \n",
      "\n",
      "   季节适应性表达  品牌声誉表达  消费者信任度表达  创新功能表达  儿童友好设计表达  组合灵活性表达  \n",
      "0        1       0         1       1         0        1  \n",
      "1        1       0         1       0         1        0  \n",
      "2        0       1         1       1         0        0  \n",
      "3        1       1         0       0         0        0  \n",
      "4        0       0         0       0         0        0  \n",
      "\n",
      "[5 rows x 67 columns]\n",
      "\n",
      "## interaction_share_cnt 分布分析结果:\n",
      "- 样本量: 605\n",
      "- 零值数量: 597\n",
      "- 零值比例: 98.6777\n",
      "- 均值: 0.0149\n",
      "- 中位数: 0.0000\n",
      "- 标准差: 0.1341\n",
      "- 最小值: 0\n",
      "- 最大值: 2\n",
      "- 偏度: 9.9661\n",
      "- 峰度: 110.3523\n",
      "\n",
      "## 推荐的模型: TOBIT\n",
      "- 变量转换: 对数转换\n",
      "- 原因: 数据中零值比例为98.68%，超过20%，使用Tobit模型。数据偏度为9.97，表现为偏态分布，对因变量进行对数转换。\n",
      "预处理后的数据: 605 行 × 21 列\n",
      "警告: interaction_share_cnt 的最小值为 0，包含零值或负值\n",
      "将使用log(1+x)转换\n",
      "已创建对数转换变量: log_interaction_share_cnt\n",
      "回归公式:\n",
      "log_interaction_share_cnt ~ 安全性需求表达 + 空间效率表达 + 环保材质偏好 + 组装便捷性表达 + 设计美感表达 + 层高可调节性表达 + 防尘功能表达 + 价格表达 + 多功能性表达 + 便携性表达 + 承重能力表达 + 耐用性表达 + 颜色选择表达 + 季节适应性表达 + 品牌声誉表达 + 创新功能表达 + 儿童友好设计表达 + 组合灵活性表达 + author_followers_cnt + author_friends_cnt\n",
      "\n",
      "多重共线性检验 (VIF):\n",
      "VIF > 10 表示可能存在严重的多重共线性问题\n",
      "                      变量       VIF\n",
      "12                颜色选择表达  5.844991\n",
      "4                 设计美感表达  5.432510\n",
      "0                安全性需求表达  3.560953\n",
      "8                 多功能性表达  3.394563\n",
      "11                 耐用性表达  3.326069\n",
      "3                组装便捷性表达  3.258193\n",
      "2                 环保材质偏好  3.220954\n",
      "10                承重能力表达  3.209544\n",
      "13               季节适应性表达  3.190966\n",
      "9                  便携性表达  3.183719\n",
      "17               组合灵活性表达  3.163847\n",
      "1                 空间效率表达  2.904204\n",
      "15                创新功能表达  2.775960\n",
      "14                品牌声誉表达  2.485333\n",
      "6                 防尘功能表达  2.375646\n",
      "16              儿童友好设计表达  2.106301\n",
      "5               层高可调节性表达  1.919452\n",
      "7                   价格表达  1.672822\n",
      "19    author_friends_cnt  1.279311\n",
      "18  author_followers_cnt  1.199435\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "data_file = os.path.join(folder_name, \"数据变量语义匹配二元赋值结果.xlsx\")\n",
    "data = pd.read_excel(data_file)\n",
    "print(f\"数据加载完成，共 {len(data)} 行和 {len(data.columns)} 列\")\n",
    "\n",
    "# 修改IV文件路径\n",
    "iv_file = os.path.join(folder_name, 'IV.txt')\n",
    "with open(iv_file, 'r', encoding='utf-8') as f:\n",
    "    iv_list = f.read().splitlines()\n",
    "    iv_list = [iv.strip() for iv in iv_list if iv.strip()]  # 移除空行\n",
    "print(f\"从IV.txt加载了 {len(iv_list)} 个自变量\")\n",
    "\n",
    "# 定义因变量和控制变量\n",
    "dv_col = 'interaction_share_cnt'\n",
    "control_vars = ['author_followers_cnt', 'author_friends_cnt']\n",
    "print(f\"将使用的控制变量: {', '.join(control_vars)}\")\n",
    "\n",
    "# 检查DV列是否存在\n",
    "if dv_col not in data.columns:\n",
    "    print(f\"错误: 数据中不存在列 '{dv_col}'\")\n",
    "    print(\"数据包含的列:\", data.columns.tolist()[:10], \"...\")\n",
    "    raise ValueError(f\"找不到DV列: {dv_col}\")\n",
    "else:\n",
    "    print(f\"已确认因变量'{dv_col}'存在于数据中\")\n",
    "\n",
    "# 检查控制变量是否存在\n",
    "missing_controls = [var for var in control_vars if var not in data.columns]\n",
    "if missing_controls:\n",
    "    print(f\"错误: 以下控制变量在数据中不存在: {missing_controls}\")\n",
    "    raise ValueError(\"缺少必要的控制变量\")\n",
    "else:\n",
    "    print(\"已确认所有控制变量存在于数据中\")\n",
    "\n",
    "# 检查IV列是否都存在\n",
    "missing_ivs = [iv for iv in iv_list if iv not in data.columns]\n",
    "if missing_ivs:\n",
    "    print(f\"警告: 以下IV在数据中不存在: {missing_ivs}\")\n",
    "    iv_list = [iv for iv in iv_list if iv in data.columns]\n",
    "    print(f\"将使用剩余的 {len(iv_list)} 个IV进行建模\")\n",
    "\n",
    "if not iv_list:\n",
    "    raise ValueError(\"没有可用的IV变量进行建模\")\n",
    "\n",
    "# 修改结果文件路径\n",
    "result_file = os.path.join(folder_name, \"share-模型结果.txt\")\n",
    "with open(result_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"# 模型分析结果\\n\\n\")\n",
    "print(f\"已创建结果文件: {result_file}\")\n",
    "\n",
    "# 显示数据前几行\n",
    "print(\"数据预览:\")\n",
    "print(data.head())\n",
    "\n",
    "# 分析DV的分布\n",
    "def analyze_distribution(data, col):\n",
    "    \"\"\"\n",
    "    分析变量分布并返回基本统计量和模型推荐\n",
    "    \"\"\"\n",
    "    # 提取非空数据\n",
    "    valid_data = data[col].dropna()\n",
    "    \n",
    "    # 基本统计量\n",
    "    stats_dict = {\n",
    "        \"样本量\": len(valid_data),\n",
    "        \"零值数量\": (valid_data == 0).sum(),\n",
    "        \"零值比例\": (valid_data == 0).mean() * 100,\n",
    "        \"均值\": valid_data.mean(),\n",
    "        \"中位数\": valid_data.median(),\n",
    "        \"标准差\": valid_data.std(),\n",
    "        \"最小值\": valid_data.min(),\n",
    "        \"最大值\": valid_data.max(),\n",
    "        \"偏度\": skew(valid_data),\n",
    "        \"峰度\": kurtosis(valid_data)\n",
    "    }\n",
    "\n",
    "    # 模型选择逻辑 - 根据零值比例和分布偏度\n",
    "    zero_inflated = stats_dict[\"零值比例\"] > 20  # 如果零值超过20%，使用Tobit\n",
    "    high_skew = abs(stats_dict[\"偏度\"]) > 1.0   # 如果偏度较大，使用对数转换\n",
    "    \n",
    "    model_type = \"ols\"  # 默认模型类型\n",
    "    transform_type = \"none\"  # 默认不转换\n",
    "    reason = \"\"\n",
    "    \n",
    "    if zero_inflated:\n",
    "        model_type = \"tobit\"\n",
    "        reason += f\"数据中零值比例为{stats_dict['零值比例']:.2f}%，超过20%，使用Tobit模型。\"\n",
    "        \n",
    "        if high_skew:\n",
    "            transform_type = \"log\"\n",
    "            reason += f\"数据偏度为{stats_dict['偏度']:.2f}，表现为偏态分布，对因变量进行对数转换。\"\n",
    "    else:\n",
    "        model_type = \"ols\"\n",
    "        reason += f\"数据中零值比例为{stats_dict['零值比例']:.2f}%，不超过20%，使用OLS模型。\"\n",
    "        \n",
    "        if high_skew:\n",
    "            transform_type = \"log\"\n",
    "            reason += f\"数据偏度为{stats_dict['偏度']:.2f}，表现为偏态分布，对因变量进行对数转换。\"\n",
    "    \n",
    "    return model_type, transform_type, reason, stats_dict\n",
    "\n",
    "# 对DV进行分布分析\n",
    "model_type, transform_type, reason, dv_stats = analyze_distribution(data, dv_col)\n",
    "\n",
    "# 显示分析结果\n",
    "print(f\"\\n## {dv_col} 分布分析结果:\")\n",
    "for key, value in dv_stats.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"- {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"- {key}: {value}\")\n",
    "\n",
    "print(f\"\\n## 推荐的模型: {model_type.upper()}\")\n",
    "print(f\"- 变量转换: {'对数转换' if transform_type == 'log' else '不转换'}\")\n",
    "print(f\"- 原因: {reason}\")\n",
    "\n",
    "# 将结果保存到文件\n",
    "with open(result_file, 'a', encoding='utf-8') as f:\n",
    "    f.write(f\"## {dv_col} 分布分析\\n\\n\")\n",
    "    for key, value in dv_stats.items():\n",
    "        if isinstance(value, float):\n",
    "            f.write(f\"- {key}: {value:.4f}\\n\")\n",
    "        else:\n",
    "            f.write(f\"- {key}: {value}\\n\")\n",
    "    \n",
    "    f.write(f\"\\n## 模型选择\\n\\n\")\n",
    "    f.write(f\"- 推荐的模型类型: {model_type.upper()}\\n\")\n",
    "    f.write(f\"- 变量转换: {'对数转换' if transform_type == 'log' else '不转换'}\\n\")\n",
    "    f.write(f\"- 选择原因: {reason}\\n\\n\")\n",
    "\n",
    "# 准备建模数据\n",
    "all_predictors = iv_list + control_vars\n",
    "model_data = data[[dv_col] + all_predictors].copy()\n",
    "model_data = model_data.dropna()  # 移除有缺失值的行\n",
    "print(f\"预处理后的数据: {len(model_data)} 行 × {len(model_data.columns)} 列\")\n",
    "\n",
    "# 处理因变量转换\n",
    "transformed_dv = dv_col\n",
    "if transform_type == \"log\":\n",
    "    # 检查零值和负值\n",
    "    min_value = model_data[dv_col].min()\n",
    "    if min_value <= 0:\n",
    "        print(f\"警告: {dv_col} 的最小值为 {min_value}，包含零值或负值\")\n",
    "        print(\"将使用log(1+x)转换\")\n",
    "        model_data[f'log_{dv_col}'] = np.log1p(model_data[dv_col])\n",
    "    else:\n",
    "        model_data[f'log_{dv_col}'] = np.log(model_data[dv_col])\n",
    "    transformed_dv = f'log_{dv_col}'\n",
    "    print(f\"已创建对数转换变量: {transformed_dv}\")\n",
    "else:\n",
    "    print(f\"使用原始变量: {transformed_dv}\")\n",
    "\n",
    "# 构建公式并显示\n",
    "formula = f\"{transformed_dv} ~ \" + \" + \".join(all_predictors)\n",
    "print(f\"回归公式:\")\n",
    "print(formula)\n",
    "\n",
    "# 检查多重共线性\n",
    "if len(all_predictors) > 1:\n",
    "    X = model_data[all_predictors]\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"变量\"] = X.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    print(\"\\n多重共线性检验 (VIF):\")\n",
    "    print(\"VIF > 10 表示可能存在严重的多重共线性问题\")\n",
    "    print(vif_data.sort_values(\"VIF\", ascending=False))\n",
    "\n",
    "    with open(result_file, 'a', encoding='utf-8') as f:\n",
    "        f.write(\"## 多重共线性检验 (VIF)\\n\\n\")\n",
    "        f.write(\"VIF > 10 表示可能存在严重的多重共线性问题\\n\\n\")\n",
    "        f.write(\"| 变量 | VIF |\\n\")\n",
    "        f.write(\"|------|------|\\n\")\n",
    "        for index, row in vif_data.iterrows():\n",
    "            f.write(f\"| {row['变量']} | {row['VIF']:.4f} |\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9909bec7-5654-4a7d-ab28-87b9b9edd852",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T10:46:13.155661Z",
     "iopub.status.busy": "2025-04-15T10:46:13.155661Z",
     "iopub.status.idle": "2025-04-15T10:46:13.657581Z",
     "shell.execute_reply": "2025-04-15T10:46:13.657581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始拟合TOBIT模型...\n",
      "使用改进的自定义Tobit模型实现...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\Lynx\\lib\\site-packages\\statsmodels\\base\\optimizer.py:19: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method nm is: xtol, ftol, maxfun. The list of unsupported keyword arguments passed include: options. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tobit模型结果:\n",
      "                              TobitModel Results                              \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   Log-Likelihood:                -376.93\n",
      "Model:                     TobitModel   AIC:                             797.9\n",
      "Method:            Maximum Likelihood   BIC:                             894.8\n",
      "Date:                Tue, 15 Apr 2025                                         \n",
      "Time:                        18:46:13                                         \n",
      "No. Observations:                 605                                         \n",
      "Df Residuals:                     584                                         \n",
      "Df Model:                          20                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       3.256e-05        nan        nan        nan         nan         nan\n",
      "x1            -0.0127        nan        nan        nan         nan         nan\n",
      "x2            -0.0212        nan        nan        nan         nan         nan\n",
      "x3            -0.0037        nan        nan        nan         nan         nan\n",
      "x4             0.0039        nan        nan        nan         nan         nan\n",
      "x5            -0.0312        nan        nan        nan         nan         nan\n",
      "x6            -0.0008        nan        nan        nan         nan         nan\n",
      "x7            -0.0003        nan        nan        nan         nan         nan\n",
      "x8             0.0015        nan        nan        nan         nan         nan\n",
      "x9            -0.0054        nan        nan        nan         nan         nan\n",
      "x10            0.0039        nan        nan        nan         nan         nan\n",
      "x11           -0.0024        nan        nan        nan         nan         nan\n",
      "x12            0.0019        nan        nan        nan         nan         nan\n",
      "x13            0.0079        nan        nan        nan         nan         nan\n",
      "x14           -0.0766        nan        nan        nan         nan         nan\n",
      "x15           -0.0032        nan        nan        nan         nan         nan\n",
      "x16            0.0027        nan        nan        nan         nan         nan\n",
      "x17            0.0008        nan        nan        nan         nan         nan\n",
      "x18            0.0062        nan        nan        nan         nan         nan\n",
      "x19          2.53e-08        nan        nan        nan         nan         nan\n",
      "x20          2.14e-06        nan        nan        nan         nan         nan\n",
      "par0           0.1881        nan        nan        nan         nan         nan\n",
      "==============================================================================\n",
      "\n",
      "模型解读:\n",
      "- Tobit模型统计量:\n",
      "  - 对数似然值: -376.9268\n",
      "  - AIC: 797.8536\n",
      "  - BIC: 894.7686\n",
      "警告: p值计算失败，将使用系数作为显著性的近似指标\n",
      "\n",
      "显著的变量 (p < 0.05): 0/19\n",
      "\n",
      "显著的自变量: 0/18\n",
      "\n",
      "显著的控制变量: 0/2\n",
      "\n",
      "模型解读:\n",
      "- Tobit模型统计量:\n",
      "  - 对数似然值: -376.9268\n",
      "  - AIC: 797.8536\n",
      "  - BIC: 894.7686\n",
      "\n",
      "显著的变量 (p < 0.05): 0/19\n",
      "\n",
      "显著的自变量: 0/18\n",
      "\n",
      "显著的控制变量: 0/2\n",
      "\n",
      "所有分析结果已保存到 生成结果/social_media/share-模型结果.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\Lynx\\lib\\site-packages\\statsmodels\\base\\model.py:595: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  warnings.warn('Inverting hessian failed, no bse or cov_params '\n",
      "C:\\Users\\admin\\anaconda3\\envs\\Lynx\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\admin\\anaconda3\\envs\\Lynx\\lib\\site-packages\\statsmodels\\base\\model.py:2748: UserWarning: df_model + k_constant + k_extra differs from k_params\n",
      "  warnings.warn(\"df_model + k_constant + k_extra \"\n",
      "C:\\Users\\admin\\anaconda3\\envs\\Lynx\\lib\\site-packages\\statsmodels\\base\\model.py:2752: UserWarning: df_resid differs from nobs - k_params\n",
      "  warnings.warn(\"df_resid differs from nobs - k_params\")\n"
     ]
    }
   ],
   "source": [
    "print(f\"开始拟合{model_type.upper()}模型...\")\n",
    "\n",
    "if model_type == \"tobit\":\n",
    "    # 尝试不同的导入方式\n",
    "    try:\n",
    "        # 尝试从truncated_model模块导入\n",
    "        from statsmodels.discrete.truncated_model import Tobit\n",
    "        \n",
    "        # 准备数据\n",
    "        y = model_data[transformed_dv].values\n",
    "        X = sm.add_constant(model_data[all_predictors])\n",
    "        \n",
    "        print(\"使用statsmodels.discrete.truncated_model中的Tobit模型...\")\n",
    "        tobit_model = Tobit(y, X, left=0)\n",
    "        results = tobit_model.fit(method='powell', disp=0, maxiter=10000)\n",
    "        \n",
    "    except (ImportError, AttributeError):\n",
    "        # 如果上述导入失败，使用censored_model模块\n",
    "        try:\n",
    "            from statsmodels.regression.censored_model import Tobit\n",
    "            \n",
    "            # 准备数据\n",
    "            y = model_data[transformed_dv].values\n",
    "            X = sm.add_constant(model_data[all_predictors])\n",
    "            \n",
    "            print(\"使用statsmodels.regression.censored_model中的Tobit模型...\")\n",
    "            tobit_model = Tobit(y, X, left=0)\n",
    "            results = tobit_model.fit(method='powell', disp=0, maxiter=10000)\n",
    "            \n",
    "        except (ImportError, AttributeError):\n",
    "            # 如果上述方法都失败，使用改进的自定义实现\n",
    "            print(\"使用改进的自定义Tobit模型实现...\")\n",
    "            from scipy.stats import norm\n",
    "            from scipy import optimize\n",
    "            from statsmodels.regression.linear_model import OLS\n",
    "            from statsmodels.base.model import GenericLikelihoodModel\n",
    "            \n",
    "            class TobitModel(GenericLikelihoodModel):\n",
    "                def __init__(self, endog, exog, left=0, **kwds):\n",
    "                    self.left = left\n",
    "                    super(TobitModel, self).__init__(endog, exog, **kwds)\n",
    "                \n",
    "                def loglikeobs(self, params):\n",
    "                    beta = params[:-1]\n",
    "                    sigma = np.abs(params[-1])  # 确保sigma为正\n",
    "                    \n",
    "                    q = self.endog\n",
    "                    x = self.exog\n",
    "                    \n",
    "                    # 计算条件期望\n",
    "                    mu = np.dot(x, beta)\n",
    "                    \n",
    "                    # 分别计算截尾和非截尾值的对数似然\n",
    "                    censored_mask = (q <= self.left)\n",
    "                    z = (self.left - mu) / sigma\n",
    "                    \n",
    "                    ll_censored = censored_mask * norm.logcdf(z)\n",
    "                    \n",
    "                    non_censored_mask = ~censored_mask\n",
    "                    ll_non_censored = non_censored_mask * (\n",
    "                        -np.log(sigma) + \n",
    "                        norm.logpdf((q - mu) / sigma)\n",
    "                    )\n",
    "                    \n",
    "                    # 处理可能的数值问题\n",
    "                    result = ll_censored + ll_non_censored\n",
    "                    # 替换无效值\n",
    "                    result = np.where(np.isnan(result) | np.isinf(result), -1e10, result)\n",
    "                    \n",
    "                    return result\n",
    "                \n",
    "                def nloglikeobs(self, params):\n",
    "                    \"\"\"负对数似然\"\"\"\n",
    "                    return -self.loglikeobs(params)\n",
    "                \n",
    "                def fit(self, start_params=None, method='bfgs', maxiter=50000, **kwds):\n",
    "                    \"\"\"添加更多优化方法选项和更好的初始值策略\"\"\"\n",
    "                    if start_params is None:\n",
    "                        # 使用OLS估计获取更稳定的初始值\n",
    "                        ols_model = OLS(\n",
    "                            np.where(self.endog <= self.left, self.left, self.endog),\n",
    "                            self.exog\n",
    "                        )\n",
    "                        ols_res = ols_model.fit()\n",
    "                        # 使用残差的标准差作为sigma的初始值\n",
    "                        start_params = np.append(ols_res.params, np.std(ols_res.resid))\n",
    "                    \n",
    "                    # 添加更多优化选项\n",
    "                    if 'options' not in kwds:\n",
    "                        kwds['options'] = {}\n",
    "                    kwds['options']['maxiter'] = maxiter\n",
    "                    \n",
    "                    # 添加容错设置\n",
    "                    try:\n",
    "                        return super(TobitModel, self).fit(\n",
    "                            start_params=start_params,\n",
    "                            method=method, \n",
    "                            **kwds\n",
    "                        )\n",
    "                    except Exception as e:\n",
    "                        print(f\"首次优化失败: {str(e)}，尝试备用方法...\")\n",
    "                        try:\n",
    "                            # 尝试Powell方法\n",
    "                            return super(TobitModel, self).fit(\n",
    "                                start_params=start_params,\n",
    "                                method='powell',\n",
    "                                options={'maxiter': 100000, 'ftol': 1e-8, 'xtol': 1e-8},\n",
    "                                **kwds\n",
    "                            )\n",
    "                        except:\n",
    "                            print(\"所有优化方法失败，尝试最简单的优化设置...\")\n",
    "                            return super(TobitModel, self).fit(\n",
    "                                start_params=start_params,\n",
    "                                method='nm',\n",
    "                                options={'maxiter': 100000},\n",
    "                                **kwds\n",
    "                            )\n",
    "            \n",
    "            # 准备数据 - 修改数据准备部分以避免AttributeError\n",
    "            y = model_data[transformed_dv].values\n",
    "            X_df = sm.add_constant(model_data[all_predictors])  # 保持DataFrame格式\n",
    "            X_array = X_df.values  # 数组版本用于拟合\n",
    "            X_columns = X_df.columns.tolist()  # 保存列名供后续使用\n",
    "            \n",
    "            # 拟合Tobit模型，尝试多种方法\n",
    "            tobit_model = TobitModel(y, X_array, left=0)\n",
    "            try:\n",
    "                # 首先尝试Nelder-Mead方法\n",
    "                results = tobit_model.fit(method='nm', disp=0, maxiter=50000)\n",
    "            except:\n",
    "                try:\n",
    "                    # 如果失败，尝试BFGS方法\n",
    "                    results = tobit_model.fit(method='bfgs', disp=0, maxiter=50000)\n",
    "                except:\n",
    "                    # 最后尝试Powell方法\n",
    "                    results = tobit_model.fit(method='powell', disp=0, maxiter=50000)\n",
    "    \n",
    "    # 打印结果\n",
    "    print(\"\\nTobit模型结果:\")\n",
    "    print(results.summary())\n",
    "    \n",
    "else:  # 使用OLS模型 - 保持不变\n",
    "    # 创建并拟合模型\n",
    "    model = smf.ols(formula=formula, data=model_data)\n",
    "    results = model.fit()\n",
    "    \n",
    "    # 显示结果摘要\n",
    "    print(\"\\nOLS回归结果:\")\n",
    "    print(results.summary())\n",
    "\n",
    "# 保存结果\n",
    "with open(result_file, 'a', encoding='utf-8') as f:\n",
    "    f.write(f\"## {model_type.upper()}回归结果\\n\\n\")\n",
    "    f.write(f\"被解释变量: {transformed_dv}\\n\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(str(results.summary()))\n",
    "    f.write(\"\\n\\n\\n\")\n",
    "\n",
    "# 模型结果解读\n",
    "print(\"\\n模型解读:\")\n",
    "\n",
    "if model_type == \"ols\":\n",
    "    # OLS模型特有的解读 - 保持不变\n",
    "    print(f\"- 模型解释力 (R²): {results.rsquared:.4f}\")\n",
    "    print(f\"- 调整后的R²: {results.rsquared_adj:.4f}\")\n",
    "    print(f\"- 模型整体显著性: F({results.df_model:.0f},{results.df_resid:.0f})={results.fvalue:.4f}, p={results.f_pvalue:.6f}\")\n",
    "    \n",
    "    if results.f_pvalue < 0.05:\n",
    "        print(\"  结论: 模型整体上显著\")\n",
    "    else:\n",
    "        print(\"  结论: 模型整体上不显著\")\n",
    "    \n",
    "    # 获取显著的变量\n",
    "    p_values = results.pvalues[1:]  # 跳过截距\n",
    "    var_names = all_predictors\n",
    "    \n",
    "else:  # Tobit模型 - 修改此部分以处理可能的NaN问题\n",
    "    print(\"- Tobit模型统计量:\")\n",
    "    print(f\"  - 对数似然值: {results.llf:.4f}\")\n",
    "    print(f\"  - AIC: {results.aic:.4f}\")\n",
    "    print(f\"  - BIC: {results.bic:.4f}\")\n",
    "    \n",
    "    # 安全获取Tobit模型的系数和p值\n",
    "    if hasattr(results, 'pvalues') and not np.all(np.isnan(results.pvalues)):\n",
    "        p_values = results.pvalues[1:-1]  # 跳过截距和sigma\n",
    "    else:\n",
    "        print(\"警告: p值计算失败，将使用系数作为显著性的近似指标\")\n",
    "        # 使用系数作为显著性的近似指标\n",
    "        coefs = results.params[1:-1]\n",
    "        se = np.ones_like(coefs) * 0.05  # 假设标准误为0.05\n",
    "        p_values = 2 * (1 - norm.cdf(np.abs(coefs / se)))\n",
    "    \n",
    "    # 在自定义Tobit中X_columns已定义，在statsmodels版本中需要定义\n",
    "    if 'X_columns' not in locals():\n",
    "        X_columns = model_data[all_predictors].columns.tolist()\n",
    "        X_columns = ['const'] + X_columns\n",
    "    \n",
    "    var_names = X_columns[1:-1] if model_type == \"tobit\" else X_columns[1:]  # 适应不同情况\n",
    "\n",
    "# 显著变量分析（对两种模型通用）\n",
    "significant_mask = p_values < 0.05\n",
    "significant_vars = [var for var, sig in zip(var_names, significant_mask) if sig]\n",
    "print(f\"\\n显著的变量 (p < 0.05): {len(significant_vars)}/{len(var_names)}\")\n",
    "\n",
    "iv_significant = [var for var in significant_vars if var in iv_list]\n",
    "ctrl_significant = [var for var in significant_vars if var in control_vars]\n",
    "\n",
    "# 显示显著的自变量\n",
    "print(f\"\\n显著的自变量: {len(iv_significant)}/{len(iv_list)}\")\n",
    "for var in iv_significant:\n",
    "    idx = var_names.index(var)\n",
    "    coef = results.params[idx + 1]  # +1 to skip intercept\n",
    "    p = p_values[idx]\n",
    "    print(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\")\n",
    "\n",
    "# 显示显著的控制变量\n",
    "print(f\"\\n显著的控制变量: {len(ctrl_significant)}/{len(control_vars)}\")\n",
    "for var in ctrl_significant:\n",
    "    idx = var_names.index(var)\n",
    "    coef = results.params[idx + 1]  # +1 to skip intercept\n",
    "    p = p_values[idx]\n",
    "    print(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\")\n",
    "\n",
    "# 保存结果\n",
    "with open(result_file, 'a', encoding='utf-8') as f:\n",
    "    f.write(f\"## {model_type.upper()}回归结果\\n\\n\")\n",
    "    f.write(f\"被解释变量: {transformed_dv}\\n\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(str(results.summary()))\n",
    "    f.write(\"\\n\\n\\n\")\n",
    "\n",
    "# 模型结果解读\n",
    "print(\"\\n模型解读:\")\n",
    "\n",
    "if model_type == \"ols\":\n",
    "    # OLS模型特有的解读\n",
    "    print(f\"- 模型解释力 (R²): {results.rsquared:.4f}\")\n",
    "    print(f\"- 调整后的R²: {results.rsquared_adj:.4f}\")\n",
    "    print(f\"- 模型整体显著性: F({results.df_model:.0f},{results.df_resid:.0f})={results.fvalue:.4f}, p={results.f_pvalue:.6f}\")\n",
    "    \n",
    "    if results.f_pvalue < 0.05:\n",
    "        print(\"  结论: 模型整体上显著\")\n",
    "    else:\n",
    "        print(\"  结论: 模型整体上不显著\")\n",
    "    \n",
    "    # 获取显著的变量\n",
    "    p_values = results.pvalues[1:]  # 跳过截距\n",
    "    var_names = all_predictors\n",
    "    \n",
    "else:  # Tobit模型\n",
    "    print(\"- Tobit模型统计量:\")\n",
    "    print(f\"  - 对数似然值: {results.llf:.4f}\")\n",
    "    print(f\"  - AIC: {results.aic:.4f}\")\n",
    "    print(f\"  - BIC: {results.bic:.4f}\")\n",
    "    \n",
    "    # Tobit模型中获取系数和p值\n",
    "    p_values = results.pvalues[1:-1]  # 跳过截距和sigma\n",
    "    var_names = list(X.columns[1:])  # 跳过常数项\n",
    "\n",
    "# 显著变量分析（对两种模型通用）\n",
    "significant_mask = p_values < 0.05\n",
    "significant_vars = [var for var, sig in zip(var_names, significant_mask) if sig]\n",
    "print(f\"\\n显著的变量 (p < 0.05): {len(significant_vars)}/{len(var_names)}\")\n",
    "\n",
    "iv_significant = [var for var in significant_vars if var in iv_list]\n",
    "ctrl_significant = [var for var in significant_vars if var in control_vars]\n",
    "\n",
    "# 显示显著的自变量\n",
    "print(f\"\\n显著的自变量: {len(iv_significant)}/{len(iv_list)}\")\n",
    "for var in iv_significant:\n",
    "    idx = var_names.index(var)\n",
    "    coef = results.params[idx + 1]  # +1 to skip intercept\n",
    "    p = p_values[idx]\n",
    "    print(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\")\n",
    "\n",
    "# 显示显著的控制变量\n",
    "print(f\"\\n显著的控制变量: {len(ctrl_significant)}/{len(control_vars)}\")\n",
    "for var in ctrl_significant:\n",
    "    idx = var_names.index(var)\n",
    "    coef = results.params[idx + 1]  # +1 to skip intercept\n",
    "    p = p_values[idx]\n",
    "    print(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\")\n",
    "\n",
    "# 保存解读结果\n",
    "with open(result_file, 'a', encoding='utf-8') as f:\n",
    "    f.write(\"## 模型结果解读\\n\\n\")\n",
    "    \n",
    "    if model_type == \"ols\":\n",
    "        f.write(f\"- 模型解释力 (R²): {results.rsquared:.4f}\\n\")\n",
    "        f.write(f\"- 调整后的R²: {results.rsquared_adj:.4f}\\n\")\n",
    "        f.write(f\"- 模型整体显著性: F({results.df_model:.0f},{results.df_resid:.0f})={results.fvalue:.4f}, p={results.f_pvalue:.6f}\\n\")\n",
    "        \n",
    "        if results.f_pvalue < 0.05:\n",
    "            f.write(\"  结论: 模型整体上显著\\n\\n\")\n",
    "        else:\n",
    "            f.write(\"  结论: 模型整体上不显著\\n\\n\")\n",
    "    else:\n",
    "        f.write(\"- Tobit模型统计量:\\n\")\n",
    "        f.write(f\"  - 对数似然值: {results.llf:.4f}\\n\")\n",
    "        f.write(f\"  - AIC: {results.aic:.4f}\\n\")\n",
    "        f.write(f\"  - BIC: {results.bic:.4f}\\n\\n\")\n",
    "    \n",
    "    f.write(f\"显著的变量 (p < 0.05): {len(significant_vars)}/{len(var_names)}\\n\\n\")\n",
    "    \n",
    "    f.write(f\"显著的自变量: {len(iv_significant)}/{len(iv_list)}\\n\")\n",
    "    for var in iv_significant:\n",
    "        idx = var_names.index(var)\n",
    "        coef = results.params[idx + 1]\n",
    "        p = p_values[idx]\n",
    "        f.write(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\\n\")\n",
    "    \n",
    "    f.write(f\"\\n显著的控制变量: {len(ctrl_significant)}/{len(control_vars)}\\n\")\n",
    "    for var in ctrl_significant:\n",
    "        idx = var_names.index(var)\n",
    "        coef = results.params[idx + 1]\n",
    "        p = p_values[idx]\n",
    "        f.write(f\"- {var}: 系数={coef:.4f}, p={p:.6f}\\n\")\n",
    "\n",
    "print(f\"\\n所有分析结果已保存到 {result_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "450f06e6-3302-4e45-af91-b5634fcdf13b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T10:46:13.657581Z",
     "iopub.status.busy": "2025-04-15T10:46:13.657581Z",
     "iopub.status.idle": "2025-04-15T10:46:13.688071Z",
     "shell.execute_reply": "2025-04-15T10:46:13.688071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始归一化系数分析...\n",
      "注意: 没有显著的变量 (p < 0.05)，将使用所有非NaN系数变量\n",
      "\n",
      "归一化后的系数 (按绝对值排序):\n",
      "-----------------------------------\n",
      "总计 20 个有效变量, 无显著变量\n",
      "-----------------------------------\n",
      "\n",
      "自变量:\n",
      "季节适应性表达: -0.0766 (归一化: -0.4111, 41.11%)\n",
      "设计美感表达: -0.0312 (归一化: -0.1673, 16.73%)\n",
      "空间效率表达: -0.0212 (归一化: -0.1137, 11.37%)\n",
      "安全性需求表达: -0.0127 (归一化: -0.0680, 6.80%)\n",
      "颜色选择表达: 0.0079 (归一化: 0.0426, 4.26%)\n",
      "组合灵活性表达: 0.0062 (归一化: 0.0335, 3.35%)\n",
      "多功能性表达: -0.0054 (归一化: -0.0290, 2.90%)\n",
      "组装便捷性表达: 0.0039 (归一化: 0.0209, 2.09%)\n",
      "便携性表达: 0.0039 (归一化: 0.0207, 2.07%)\n",
      "环保材质偏好: -0.0037 (归一化: -0.0198, 1.98%)\n",
      "品牌声誉表达: -0.0032 (归一化: -0.0174, 1.74%)\n",
      "创新功能表达: 0.0027 (归一化: 0.0144, 1.44%)\n",
      "承重能力表达: -0.0024 (归一化: -0.0126, 1.26%)\n",
      "耐用性表达: 0.0019 (归一化: 0.0103, 1.03%)\n",
      "价格表达: 0.0015 (归一化: 0.0080, 0.80%)\n",
      "层高可调节性表达: -0.0008 (归一化: -0.0045, 0.45%)\n",
      "儿童友好设计表达: 0.0008 (归一化: 0.0043, 0.43%)\n",
      "防尘功能表达: -0.0003 (归一化: -0.0017, 0.17%)\n",
      "\n",
      "控制变量:\n",
      "author_friends_cnt: 0.0000 (归一化: 0.0000, 0.00%)\n",
      "author_followers_cnt: 0.0000 (归一化: 0.0000, 0.00%)\n",
      "-----------------------------------\n",
      "* 标记表示在0.05水平上显著\n",
      "\n",
      "结果已保存到 生成结果/social_media/Share-归一化的模型结果.txt\n"
     ]
    }
   ],
   "source": [
    "# 归一化显著系数并输出结果\n",
    "def normalize_significant_coefficients(results, iv_list, control_vars=None, model_type=\"ols\", alpha=0.05):\n",
    "    \"\"\"\n",
    "    归一化显著变量的系数，删除NaN值，按绝对值大小排序并输出结果\n",
    "    \n",
    "    参数:\n",
    "    - results: 回归结果对象\n",
    "    - iv_list: 自变量列表\n",
    "    - control_vars: 控制变量列表，默认为None\n",
    "    - model_type: 模型类型，\"ols\"或\"tobit\"\n",
    "    - alpha: 显著性水平，默认0.05\n",
    "    \"\"\"\n",
    "    if control_vars is None:\n",
    "        control_vars = []\n",
    "    \n",
    "    all_vars = iv_list + control_vars\n",
    "    \n",
    "    # 获取系数和p值 - 需要考虑不同模型类型\n",
    "    if model_type.lower() == \"ols\":\n",
    "        # OLS模型 - 跳过截距\n",
    "        coefs = results.params[1:len(all_vars)+1]\n",
    "        p_values = results.pvalues[1:len(all_vars)+1]\n",
    "    else:\n",
    "        # Tobit模型 - 跳过截距和sigma\n",
    "        coefs = results.params[1:len(all_vars)+1]\n",
    "        p_values = results.pvalues[1:len(all_vars)+1]\n",
    "    \n",
    "    # 创建DataFrame\n",
    "    coef_df = pd.DataFrame({\n",
    "        '变量': all_vars,\n",
    "        '系数': coefs,\n",
    "        'p值': p_values,\n",
    "        '变量类型': ['自变量' if var in iv_list else '控制变量' for var in all_vars]\n",
    "    })\n",
    "    \n",
    "    # 过滤掉NaN系数和非显著的变量\n",
    "    valid_coef_df = coef_df.dropna(subset=['系数'])\n",
    "    sig_coef_df = valid_coef_df[valid_coef_df['p值'] < alpha].copy()\n",
    "    \n",
    "    # 如果没有显著变量，则报告所有有效变量\n",
    "    if len(sig_coef_df) == 0:\n",
    "        print(\"注意: 没有显著的变量 (p < 0.05)，将使用所有非NaN系数变量\")\n",
    "        sig_coef_df = valid_coef_df.copy()\n",
    "    \n",
    "    # 如果没有有效系数，退出\n",
    "    if len(sig_coef_df) == 0:\n",
    "        print(\"警告: 没有有效的系数，无法进行归一化\")\n",
    "        return None\n",
    "    \n",
    "    # 计算系数的绝对值\n",
    "    sig_coef_df['系数绝对值'] = sig_coef_df['系数'].abs()\n",
    "    \n",
    "    # 归一化系数\n",
    "    total_abs = sig_coef_df['系数绝对值'].sum()\n",
    "    sig_coef_df['归一化系数'] = sig_coef_df['系数'] / total_abs\n",
    "    sig_coef_df['归一化系数绝对值'] = sig_coef_df['系数绝对值'] / total_abs\n",
    "    sig_coef_df['归一化系数百分比'] = sig_coef_df['归一化系数绝对值'] * 100\n",
    "    \n",
    "    # 按系数绝对值排序\n",
    "    sig_coef_df = sig_coef_df.sort_values('系数绝对值', ascending=False)\n",
    "    \n",
    "    # 显示结果\n",
    "    print(\"\\n归一化后的系数 (按绝对值排序):\")\n",
    "    print(\"-----------------------------------\")\n",
    "    significant_str = \"显著 (p<0.05)\" if len(sig_coef_df[sig_coef_df['p值'] < alpha]) > 0 else \"无显著变量\"\n",
    "    print(f\"总计 {len(sig_coef_df)} 个有效变量, {significant_str}\")\n",
    "    print(\"-----------------------------------\")\n",
    "    \n",
    "    # 先显示自变量，再显示控制变量\n",
    "    for var_type in ['自变量', '控制变量']:\n",
    "        type_df = sig_coef_df[sig_coef_df['变量类型'] == var_type]\n",
    "        if len(type_df) > 0:\n",
    "            print(f\"\\n{var_type}:\")\n",
    "            for _, row in type_df.iterrows():\n",
    "                sig_mark = \"*\" if row['p值'] < alpha else \"\"\n",
    "                print(f\"{row['变量']}: {row['系数']:.4f} (归一化: {row['归一化系数']:.4f}, {row['归一化系数百分比']:.2f}%){sig_mark}\")\n",
    "    \n",
    "    print(\"-----------------------------------\")\n",
    "    print(\"* 标记表示在0.05水平上显著\")\n",
    "    \n",
    "    # 保存到文件\n",
    "    output_file = os.path.join(folder_name, \"Share-归一化的模型结果.txt\")\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"# {model_type.upper()} 模型归一化后的系数 (按绝对值排序)\\n\\n\")\n",
    "        f.write(\"-----------------------------------\\n\")\n",
    "        f.write(f\"总计 {len(sig_coef_df)} 个有效变量, {significant_str}\\n\")\n",
    "        f.write(\"-----------------------------------\\n\\n\")\n",
    "        \n",
    "        # 添加总表\n",
    "        f.write(\"| 变量 | 变量类型 | 系数 | p值 | 归一化系数 | 归一化百分比 | 显著性 |\\n\")\n",
    "        f.write(\"|------|---------|------|------|------------|------------|--------|\\n\")\n",
    "        \n",
    "        for _, row in sig_coef_df.iterrows():\n",
    "            sig = \"是\" if row['p值'] < alpha else \"否\"\n",
    "            f.write(f\"| {row['变量']} | {row['变量类型']} | {row['系数']:.4f} | {row['p值']:.4f} | {row['归一化系数']:.4f} | {row['归一化系数百分比']:.2f}% | {sig} |\\n\")\n",
    "        \n",
    "        f.write(\"\\n\\n## 详细分析\\n\\n\")\n",
    "        \n",
    "        # 先显示自变量，再显示控制变量\n",
    "        for var_type in ['自变量', '控制变量']:\n",
    "            type_df = sig_coef_df[sig_coef_df['变量类型'] == var_type]\n",
    "            if len(type_df) > 0:\n",
    "                f.write(f\"### {var_type}\\n\\n\")\n",
    "                \n",
    "                for _, row in type_df.iterrows():\n",
    "                    sig_symbol = \"*\" if row['p值'] < alpha else \"\"\n",
    "                    direction = \"正向\" if row['系数'] > 0 else \"负向\"\n",
    "                    f.write(f\"#### {row['变量']}{sig_symbol}\\n\\n\")\n",
    "                    f.write(f\"- 系数: {row['系数']:.4f}\\n\")\n",
    "                    f.write(f\"- p值: {row['p值']:.4f}\\n\")\n",
    "                    f.write(f\"- 影响方向: {direction}\\n\")\n",
    "                    f.write(f\"- 归一化系数: {row['归一化系数']:.4f}\\n\")\n",
    "                    f.write(f\"- 归一化百分比: {row['归一化系数百分比']:.2f}%\\n\")\n",
    "                    f.write(f\"- 是否显著: {'是' if row['p值'] < alpha else '否'}\\n\\n\")\n",
    "        \n",
    "        f.write(\"-----------------------------------\\n\")\n",
    "        f.write(\"* 标记表示在0.05水平上显著\\n\")\n",
    "    \n",
    "    print(f\"\\n结果已保存到 {output_file}\")\n",
    "    \n",
    "    return sig_coef_df\n",
    "# 调用归一化函数\n",
    "print(\"\\n开始归一化系数分析...\")\n",
    "normalized_coefs = normalize_significant_coefficients(\n",
    "    results=results,\n",
    "    iv_list=iv_list,\n",
    "    control_vars=control_vars,\n",
    "    model_type=model_type,\n",
    "    alpha=0.05\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb07beb1-0309-4281-849c-f504fdef1279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe49d13-267c-4717-94a9-f481e21661ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lynx",
   "language": "python",
   "name": "lynx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
