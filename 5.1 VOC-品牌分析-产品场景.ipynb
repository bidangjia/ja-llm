{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba94f041-0391-4da7-969c-dadd0c082abc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T08:16:42.971663Z",
     "iopub.status.busy": "2025-04-18T08:16:42.971663Z",
     "iopub.status.idle": "2025-04-18T08:16:44.020337Z",
     "shell.execute_reply": "2025-04-18T08:16:44.020337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前操作系统: Windows\n",
      "当前字体设置: ['SimHei', 'Microsoft YaHei', 'SimSun']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from collections import defaultdict\n",
    "import platform\n",
    "import glob\n",
    "import os\n",
    "import ast\n",
    "\n",
    "# 根据操作系统设置合适的中文字体\n",
    "system = platform.system()\n",
    "if system == 'Darwin':  # macOS\n",
    "    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'Heiti TC', 'PingFang HK', 'Apple Color Emoji']\n",
    "elif system == 'Windows':\n",
    "    plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'SimSun']\n",
    "else:  # Linux或其他\n",
    "    plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'WenQuanYi Micro Hei', 'WenQuanYi Zen Hei']\n",
    "\n",
    "# 正常显示负号\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(f\"当前操作系统: {system}\")\n",
    "print(f\"当前字体设置: {plt.rcParams['font.sans-serif']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55e99b18-b8da-434f-b5a1-258b113b3427",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T08:16:44.022338Z",
     "iopub.status.busy": "2025-04-18T08:16:44.021339Z",
     "iopub.status.idle": "2025-04-18T08:16:44.036012Z",
     "shell.execute_reply": "2025-04-18T08:16:44.036012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "配置完成。\n",
      "象限数据文件模式: 生成结果/last_quadrant/*plot_quadrant_data_场景匹配.xlsx\n",
      "匹配结果文件模式: 生成结果/matches_analysis/refined_*_matches_analysis.xlsx\n",
      "原始数据文件模式: ./Data/*VOC数据.xlsx\n",
      "ASIN数据文件模式: ./Data/*_processed.xlsx\n",
      "输出目录: 生成结果/integrated_analysis_matches/\n",
      "\n",
      "成功找到所有需要的文件:\n",
      "  象限数据文件: 生成结果/last_quadrant\\plot_quadrant_data_场景匹配.xlsx\n",
      "  匹配结果文件: 生成结果/matches_analysis\\refined_致欧-2025-01-10之后VOC数据_rating_3_to_5_length_10_to_200_words_matches_analysis.xlsx\n",
      "  原始数据文件: ./Data\\致欧-2025-01-10之后VOC数据.xlsx\n",
      "  ASIN数据文件: ./Data\\zhiou_processed.xlsx\n"
     ]
    }
   ],
   "source": [
    "# --- 配置区域 ---\n",
    "\n",
    "# 1. 文件路径和模式\n",
    "matches_dir1 = '生成结果/matches_analysis/'\n",
    "matches_dir2 = '生成结果/last_quadrant/'\n",
    "original_data_dir = './Data/'\n",
    "asin_data_dir = './Data/'\n",
    "\n",
    "# 2. 具体文件名或模式 (使用 glob 查找)\n",
    "# 请确保目录下只有一个符合模式的文件，或者修改代码以处理多个文件\n",
    "complete_file_pattern = os.path.join(matches_dir2, '*plot_quadrant_data_场景匹配.xlsx')\n",
    "matches_result_pattern = os.path.join(matches_dir1, 'refined_*_matches_analysis.xlsx')\n",
    "original_data_pattern = os.path.join(original_data_dir, '*VOC数据.xlsx')\n",
    "asin_data_pattern = os.path.join(asin_data_dir, '*_processed.xlsx')\n",
    "\n",
    "# 3. 输出文件路径\n",
    "output_dir = '生成结果/integrated_analysis_matches/'\n",
    "os.makedirs(output_dir, exist_ok=True) # 创建输出目录\n",
    "final_merged_output_file = os.path.join(output_dir, 'final_merged_original_data_matches.xlsx')\n",
    "analysis_output_prefix = os.path.join(output_dir, 'analysis_') # 分析结果文件前缀\n",
    "\n",
    "# 4. 列名定义 (请根据你的 Excel 文件修改)\n",
    "# complete_file ('plot_quadrant_data_场景匹配.xlsx') 列名\n",
    "col_complete_match = '场景匹配' # 用于匹配 'Match' 列\n",
    "col_complete_quadrant = '图表象限'\n",
    "\n",
    "# matches_result_file ('refined_*_matches_analysis.xlsx') 列名\n",
    "col_matches_match = 'Match'\n",
    "col_matches_indices = 'Review_Indices'\n",
    "\n",
    "# original_data_file ('*VOC数据.xlsx') 列名\n",
    "col_original_indices = 'Review_Indices' # 用于匹配 'Review_Indices' 列\n",
    "col_original_rating = 'Rating'\n",
    "col_original_asin = 'ASIN'\n",
    "col_original_site = '站点信息'\n",
    "col_original_likes = '点赞数'\n",
    "# 假设原始数据中有一个 ASIN 排名列，如果名称不同请修改\n",
    "col_original_asin_rank = 'ASIN排名' # 如果没有该列，后续分析会报错或需要调整\n",
    "\n",
    "# asin_data_file ('*_processed.xlsx') 列名\n",
    "col_asin_asin = 'asin' # 用于匹配 'ASIN' 列\n",
    "col_asin_brand = 'brand'\n",
    "col_asin_seller = 'sellerName'\n",
    "\n",
    "# 新增到 original_data_file 的列名\n",
    "col_new_match = 'Match' # 从 matches_result_file 添加\n",
    "col_new_quadrant = '图表象限' # 从 complete_file 添加\n",
    "\n",
    "# --- 配置区域结束 ---\n",
    "\n",
    "# 设置 matplotlib 支持中文显示（选择一种适合你环境的方式）\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 指定默认字体为黑体\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 解决保存图像是负号'-'显示为方块的问题\n",
    "\n",
    "print(\"配置完成。\")\n",
    "print(f\"象限数据文件模式: {complete_file_pattern}\")\n",
    "print(f\"匹配结果文件模式: {matches_result_pattern}\")\n",
    "print(f\"原始数据文件模式: {original_data_pattern}\")\n",
    "print(f\"ASIN数据文件模式: {asin_data_pattern}\")\n",
    "print(f\"输出目录: {output_dir}\")\n",
    "\n",
    "# 辅助函数：查找文件，确保只找到一个\n",
    "def find_single_file(pattern):\n",
    "    files = glob.glob(pattern)\n",
    "    if len(files) == 0:\n",
    "        raise FileNotFoundError(f\"错误：找不到匹配模式的文件: {pattern}\")\n",
    "    if len(files) > 1:\n",
    "        print(f\"警告：找到多个匹配模式的文件: {pattern}。将使用第一个文件: {files[0]}\")\n",
    "        # 或者可以抛出错误： raise ValueError(f\"错误：找到多个匹配模式的文件: {pattern}\")\n",
    "    return files[0]\n",
    "\n",
    "# 查找文件\n",
    "try:\n",
    "    complete_file = find_single_file(complete_file_pattern)\n",
    "    matches_result_file = find_single_file(matches_result_pattern)\n",
    "    original_data_file = find_single_file(original_data_pattern)\n",
    "    asin_data_file = find_single_file(asin_data_pattern)\n",
    "    print(\"\\n成功找到所有需要的文件:\")\n",
    "    print(f\"  象限数据文件: {complete_file}\")\n",
    "    print(f\"  匹配结果文件: {matches_result_file}\")\n",
    "    print(f\"  原始数据文件: {original_data_file}\")\n",
    "    print(f\"  ASIN数据文件: {asin_data_file}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "    # 如果文件找不到，后续代码无法执行，可以考虑退出或采取其他措施\n",
    "    exit()\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "    # 如果找到多个文件且不允许，可以考虑退出\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2dcdee7-9787-481e-95a6-0dcca5cc78aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T08:16:44.038013Z",
     "iopub.status.busy": "2025-04-18T08:16:44.037012Z",
     "iopub.status.idle": "2025-04-18T08:16:44.159805Z",
     "shell.execute_reply": "2025-04-18T08:16:44.159805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 开始第1步：加载数据 ---\n",
      "成功加载并选择了 生成结果/last_quadrant\\plot_quadrant_data_场景匹配.xlsx 的数据。\n",
      "  选择了列: 场景匹配 (重命名为 Match), 图表象限\n",
      "  数据预览 (前5行):\n",
      "Empty DataFrame\n",
      "Columns: [Match, 图表象限]\n",
      "Index: []\n",
      "\n",
      "成功加载并选择了 生成结果/matches_analysis\\refined_致欧-2025-01-10之后VOC数据_rating_3_to_5_length_10_to_200_words_matches_analysis.xlsx 的数据。\n",
      "  选择了列: Match, Review_Indices\n",
      "  数据预览 (前5行):\n",
      "Empty DataFrame\n",
      "Columns: [Match, Review_Indices]\n",
      "Index: []\n",
      "\n",
      "--- 第1步完成 ---\n"
     ]
    }
   ],
   "source": [
    "# --- 第1步：加载数据 ---\n",
    "\n",
    "print(\"\\n--- 开始第1步：加载数据 ---\")\n",
    "\n",
    "# 加载象限数据 (complete_file)\n",
    "try:\n",
    "    df_complete = pd.read_excel(complete_file)\n",
    "    # 选择需要的列，并重命名 '场景匹配' 为 'Match' 以便合并\n",
    "    df_complete_selected = df_complete[[col_complete_match, col_complete_quadrant]].rename(\n",
    "        columns={col_complete_match: col_matches_match} # 使用 matches_result 文件中的列名作为目标\n",
    "    )\n",
    "    print(f\"成功加载并选择了 {complete_file} 的数据。\")\n",
    "    print(f\"  选择了列: {col_complete_match} (重命名为 {col_matches_match}), {col_complete_quadrant}\")\n",
    "    print(f\"  数据预览 (前5行):\\n{df_complete_selected.head()}\")\n",
    "except Exception as e:\n",
    "    print(f\"加载或处理 {complete_file} 时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 加载匹配结果数据 (matches_result_file)\n",
    "try:\n",
    "    df_matches_result = pd.read_excel(matches_result_file)\n",
    "    # 选择需要的列\n",
    "    df_matches_selected = df_matches_result[[col_matches_match, col_matches_indices]]\n",
    "    print(f\"\\n成功加载并选择了 {matches_result_file} 的数据。\")\n",
    "    print(f\"  选择了列: {col_matches_match}, {col_matches_indices}\")\n",
    "    print(f\"  数据预览 (前5行):\\n{df_matches_selected.head()}\")\n",
    "except Exception as e:\n",
    "    print(f\"加载或处理 {matches_result_file} 时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "print(\"\\n--- 第1步完成 ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83be4fb8-c66c-4dbf-9212-185e684ba4dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T08:16:44.161807Z",
     "iopub.status.busy": "2025-04-18T08:16:44.161807Z",
     "iopub.status.idle": "2025-04-18T08:16:44.175076Z",
     "shell.execute_reply": "2025-04-18T08:16:44.175076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 开始第2步：合并象限信息到匹配结果 ---\n",
      "象限数据中的Match数量: 0\n",
      "匹配结果中的Match数量: 0\n",
      "两者共有的Match数量: 0\n",
      "成功将 '图表象限' 合并到匹配结果数据中。\n",
      "  合并后的数据预览 (前5行):\n",
      "Empty DataFrame\n",
      "Columns: [Match, Review_Indices, 图表象限]\n",
      "Index: []\n",
      "\n",
      "--- 第2步完成 ---\n"
     ]
    }
   ],
   "source": [
    "# --- 第2步：合并象限信息到匹配结果 (增强版) ---\n",
    "print(\"\\n--- 开始第2步：合并象限信息到匹配结果 ---\")\n",
    "\n",
    "# 检查并清理 Match 列，确保格式一致\n",
    "def clean_match_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    # 去除额外空格，转换为小写等\n",
    "    return text.strip().lower()\n",
    "\n",
    "# 应用清理函数\n",
    "df_matches_selected[col_matches_match] = df_matches_selected[col_matches_match].apply(clean_match_text)\n",
    "df_complete_selected[col_matches_match] = df_complete_selected[col_matches_match].apply(clean_match_text)\n",
    "\n",
    "# 检查匹配情况\n",
    "matches_in_complete = set(df_complete_selected[col_matches_match].unique())\n",
    "matches_in_results = set(df_matches_selected[col_matches_match].unique())\n",
    "common_matches = matches_in_complete.intersection(matches_in_results)\n",
    "\n",
    "print(f\"象限数据中的Match数量: {len(matches_in_complete)}\")\n",
    "print(f\"匹配结果中的Match数量: {len(matches_in_results)}\")\n",
    "print(f\"两者共有的Match数量: {len(common_matches)}\")\n",
    "\n",
    "if len(common_matches) < min(len(matches_in_complete), len(matches_in_results)):\n",
    "    print(\"警告: 部分Match无法在两个数据源之间匹配！\")\n",
    "    # 输出一些不匹配的例子\n",
    "    mismatched_in_complete = matches_in_complete - common_matches\n",
    "    mismatched_in_results = matches_in_results - common_matches\n",
    "    if mismatched_in_complete:\n",
    "        print(f\"象限数据中但不在匹配结果中的Match示例: {list(mismatched_in_complete)[:3]}\")\n",
    "    if mismatched_in_results:\n",
    "        print(f\"匹配结果中但不在象限数据中的Match示例: {list(mismatched_in_results)[:3]}\")\n",
    "\n",
    "# 使用左合并，保留所有 df_matches_selected 的行\n",
    "df_merged_matches_info = pd.merge(\n",
    "    df_matches_selected,\n",
    "    df_complete_selected,\n",
    "    on=col_matches_match, # 合并键是 'Match' 列\n",
    "    how='left' # 保留左边（df_matches_selected）的所有行\n",
    ")\n",
    "\n",
    "# 检查合并结果\n",
    "nan_quadrant_count = df_merged_matches_info[col_complete_quadrant].isnull().sum()\n",
    "if nan_quadrant_count > 0:\n",
    "    print(f\"警告: 有 {nan_quadrant_count} 行未能匹配到 '{col_complete_quadrant}' 信息\")\n",
    "    # 显示一些未匹配到象限的Match值\n",
    "    unmatched_matches = df_merged_matches_info[df_merged_matches_info[col_complete_quadrant].isnull()][col_matches_match].unique()\n",
    "    print(f\"未匹配到象限的Match示例: {unmatched_matches[:3]}\")\n",
    "\n",
    "print(f\"成功将 '{col_complete_quadrant}' 合并到匹配结果数据中。\")\n",
    "print(f\"  合并后的数据预览 (前5行):\\n{df_merged_matches_info.head()}\")\n",
    "print(\"\\n--- 第2步完成 ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aec3719a-0459-4d1d-a646-953de80baf67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T08:16:44.176076Z",
     "iopub.status.busy": "2025-04-18T08:16:44.176076Z",
     "iopub.status.idle": "2025-04-18T08:16:45.287309Z",
     "shell.execute_reply": "2025-04-18T08:16:45.287309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 开始第3步：合并匹配和象限信息到原始数据 ---\n",
      "从文件名中提取的Rating筛选范围: 3 到 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功加载原始数据文件: ./Data\\致欧-2025-01-10之后VOC数据.xlsx (2342 行)\n",
      "成功加载ASIN数据文件: ./Data\\zhiou_processed.xlsx (100 行)\n",
      "品牌数据统计 (前10个):\n",
      "brand\n",
      "SONGMICS           9\n",
      "Kitsure            5\n",
      "LANTEFUL           5\n",
      "OYREL              4\n",
      "Autonomier         3\n",
      "Simple Trending    3\n",
      "VASAGLE            3\n",
      "HOOBRO             3\n",
      "VILICK             3\n",
      "ROJASOP            2\n",
      "Name: count, dtype: int64\n",
      "展开前的匹配信息数据形状: (0, 3)\n",
      "展开后得到 0 行待合并数据。\n",
      "展开后的匹配信息示例 (前3行):\n",
      "Empty DataFrame\n",
      "Columns: [Match, target_original_index, 图表象限]\n",
      "Index: []\n",
      "合并展开信息到原始数据...\n",
      "合并品牌数据...\n",
      "原始数据中ASIN列的唯一值数量: 77\n",
      "品牌数据中ASIN列的唯一值数量: 100\n",
      "两个数据集共有的ASIN数量: 77\n",
      "合并前行数: 2342, 合并后行数: 2342\n",
      "成功合并品牌数据，2342 行有品牌信息 (100.00%)\n",
      "品牌分布 (前10个):\n",
      "brand\n",
      "LANTEFUL            233\n",
      "VTRIN               172\n",
      "FIDUCIAL HOME       152\n",
      "Sakugi              140\n",
      "ROMGUAR CRAFT       114\n",
      "OYREL               110\n",
      "Simple Houseware    103\n",
      "HOOBRO              102\n",
      "INGIORDAR            93\n",
      "SONGMICS             81\n",
      "Name: count, dtype: int64\n",
      "成功将 'Match' 和 '图表象限' 信息合并到原始数据。\n",
      "  最终数据 2342 行，其中 0 行匹配到信息。\n",
      "\n",
      "验证合并后的数据:\n",
      "各象限数据量:\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最终合并后的数据已保存到: 生成结果/integrated_analysis_matches/final_merged_original_data_matches.xlsx\n",
      "\n",
      "--- 第3步完成 ---\n"
     ]
    }
   ],
   "source": [
    "# --- 第3步：合并匹配和象限信息到原始数据 (增强版) ---\n",
    "import ast  # 确保导入 ast\n",
    "import re   # 导入正则表达式模块，用于从文件名提取信息\n",
    "print(\"\\n--- 开始第3步：合并匹配和象限信息到原始数据 ---\")\n",
    "\n",
    "# 从文件名中提取Rating范围信息\n",
    "def extract_rating_range(filename):\n",
    "    # 使用正则表达式匹配rating_X_to_Y模式\n",
    "    rating_pattern = re.search(r'rating_(\\d+)_to_(\\d+)', filename.lower())\n",
    "    if rating_pattern:\n",
    "        min_rating = int(rating_pattern.group(1))\n",
    "        max_rating = int(rating_pattern.group(2))\n",
    "        return min_rating, max_rating\n",
    "    return None, None  # 如果没有找到匹配项，返回None\n",
    "\n",
    "# 提取当前使用的matches_result_file中的Rating范围\n",
    "min_rating, max_rating = extract_rating_range(matches_result_file)\n",
    "if min_rating is not None and max_rating is not None:\n",
    "    print(f\"从文件名中提取的Rating筛选范围: {min_rating} 到 {max_rating}\")\n",
    "else:\n",
    "    print(\"未能从文件名中提取Rating筛选范围，将使用所有Rating数据\")\n",
    "\n",
    "# 加载原始数据 (original_data_file)\n",
    "try:\n",
    "    df_original = pd.read_excel(original_data_file)\n",
    "    # 为原始数据添加行号索引列，用于后续合并\n",
    "    df_original['original_row_index'] = df_original.index\n",
    "    print(f\"成功加载原始数据文件: {original_data_file} ({len(df_original)} 行)\")\n",
    "except Exception as e:\n",
    "    print(f\"加载或处理 {original_data_file} 时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 加载品牌数据 (asin_data_file)\n",
    "try:\n",
    "    df_asin_data = pd.read_excel(asin_data_file)\n",
    "    print(f\"成功加载ASIN数据文件: {asin_data_file} ({len(df_asin_data)} 行)\")\n",
    "    \n",
    "    # 检查必要的列是否存在\n",
    "    required_cols = [col_asin_asin, col_asin_brand, col_asin_seller]\n",
    "    missing_cols = [col for col in required_cols if col not in df_asin_data.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"警告: ASIN数据文件中缺少以下列: {missing_cols}\")\n",
    "    \n",
    "    # 显示品牌数据的统计信息\n",
    "    if col_asin_brand in df_asin_data.columns:\n",
    "        brand_counts = df_asin_data[col_asin_brand].value_counts().head(10)\n",
    "        print(f\"品牌数据统计 (前10个):\\n{brand_counts}\")\n",
    "except Exception as e:\n",
    "    print(f\"加载或处理 {asin_data_file} 时出错: {e}\")\n",
    "    print(\"将继续处理，但不会包含品牌信息\")\n",
    "    df_asin_data = None\n",
    "\n",
    "# --- 处理包含列表索引的 matches 数据 (df_merged_matches_info 来自第2步) ---\n",
    "# 1. 转换字符串列表为实际列表 (如果需要)\n",
    "if not df_merged_matches_info.empty:\n",
    "    print(f\"处理 '{col_matches_indices}' 列...\")\n",
    "    \n",
    "    # 检查列是否存在\n",
    "    if col_matches_indices not in df_merged_matches_info.columns:\n",
    "        raise ValueError(f\"错误：合并后的匹配信息中缺少列 '{col_matches_indices}'\")\n",
    "    \n",
    "    # 检查第一个非空值的类型\n",
    "    first_valid_idx = df_merged_matches_info[col_matches_indices].first_valid_index()\n",
    "    if first_valid_idx is not None:\n",
    "        first_valid_value = df_merged_matches_info.loc[first_valid_idx, col_matches_indices]\n",
    "        print(f\"'{col_matches_indices}' 列的第一个有效值类型: {type(first_valid_value)}\")\n",
    "        print(f\"值示例: {first_valid_value}\")\n",
    "        \n",
    "        # 如果是字符串，尝试转换为列表\n",
    "        if isinstance(first_valid_value, str):\n",
    "            try:\n",
    "                print(f\"尝试将 '{col_matches_indices}' 列的字符串转换为列表...\")\n",
    "                df_merged_matches_info[col_matches_indices] = df_merged_matches_info[col_matches_indices].apply(\n",
    "                    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    "                )\n",
    "                print(\"转换成功\")\n",
    "            except Exception as e:\n",
    "                print(f\"错误：转换 '{col_matches_indices}' 列失败: {e}\")\n",
    "                # 显示一些导致错误的值\n",
    "                problematic_values = df_merged_matches_info[col_matches_indices].head(3).tolist()\n",
    "                print(f\"问题值示例: {problematic_values}\")\n",
    "                exit()\n",
    "\n",
    "# 2. 展开 (Explode) df_merged_matches_info 数据框\n",
    "try:\n",
    "    print(f\"展开前的匹配信息数据形状: {df_merged_matches_info.shape}\")\n",
    "    \n",
    "    # 处理空列表或非列表项\n",
    "    df_merged_matches_info = df_merged_matches_info.dropna(subset=[col_matches_indices])\n",
    "    \n",
    "    # 确保所有值都是列表\n",
    "    def ensure_list(item):\n",
    "        if isinstance(item, list):\n",
    "            return item\n",
    "        elif isinstance(item, (int, float)):\n",
    "            return [int(item)]  # 单个数字转为列表\n",
    "        else:\n",
    "            return []  # 其他情况返回空列表\n",
    "    \n",
    "    df_merged_matches_info[col_matches_indices] = df_merged_matches_info[col_matches_indices].apply(ensure_list)\n",
    "    \n",
    "    # 执行 explode\n",
    "    df_exploded_matches = df_merged_matches_info.explode(col_matches_indices)\n",
    "    df_exploded_matches = df_exploded_matches.rename(columns={col_matches_indices: 'target_original_index'})\n",
    "    \n",
    "    # 转换索引为整数\n",
    "    df_exploded_matches = df_exploded_matches.dropna(subset=['target_original_index'])\n",
    "    df_exploded_matches['target_original_index'] = df_exploded_matches['target_original_index'].astype(int)\n",
    "    \n",
    "    print(f\"展开后得到 {len(df_exploded_matches)} 行待合并数据。\")\n",
    "    print(f\"展开后的匹配信息示例 (前3行):\\n{df_exploded_matches.head(3)}\")\n",
    "    \n",
    "    # 检查索引范围是否在原始数据范围内\n",
    "    max_original_index = df_original['original_row_index'].max()\n",
    "    max_target_index = df_exploded_matches['target_original_index'].max()\n",
    "    if max_target_index > max_original_index:\n",
    "        print(f\"警告: 展开后的索引最大值 ({max_target_index}) 超出了原始数据索引范围 (0-{max_original_index})!\")\n",
    "        # 过滤掉超出范围的索引\n",
    "        df_exploded_matches = df_exploded_matches[df_exploded_matches['target_original_index'] <= max_original_index]\n",
    "        print(f\"过滤后剩余 {len(df_exploded_matches)} 行数据。\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"展开 '{col_matches_indices}' 列时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 3. 将展开后的信息合并回原始数据 df_original\n",
    "print(\"合并展开信息到原始数据...\")\n",
    "df_final_merged = pd.merge(\n",
    "    df_original,\n",
    "    df_exploded_matches[['target_original_index', col_matches_match, col_complete_quadrant]],\n",
    "    left_on='original_row_index',\n",
    "    right_on='target_original_index',\n",
    "    how='left' # 保留所有原始行\n",
    ")\n",
    "\n",
    "# --- 合并品牌数据 ---\n",
    "# 在第3步合并品牌数据后添加\n",
    "if df_asin_data is not None and col_original_asin in df_final_merged.columns and col_asin_asin in df_asin_data.columns:\n",
    "    print(f\"合并品牌数据...\")\n",
    "    \n",
    "    # 检查ASIN列的唯一值数量\n",
    "    print(f\"原始数据中ASIN列的唯一值数量: {df_final_merged[col_original_asin].nunique()}\")\n",
    "    print(f\"品牌数据中ASIN列的唯一值数量: {df_asin_data[col_asin_asin].nunique()}\")\n",
    "    \n",
    "    # 检查有多少ASIN能够匹配\n",
    "    common_asins = set(df_final_merged[col_original_asin].astype(str).str.lower()) & set(df_asin_data[col_asin_asin].astype(str).str.lower())\n",
    "    print(f\"两个数据集共有的ASIN数量: {len(common_asins)}\")\n",
    "    \n",
    "    # 确保ASIN列的格式一致 (转换为小写字符串)\n",
    "    df_final_merged[col_original_asin] = df_final_merged[col_original_asin].astype(str).str.lower()\n",
    "    df_asin_data[col_asin_asin] = df_asin_data[col_asin_asin].astype(str).str.lower()\n",
    "    \n",
    "    # 合并品牌数据\n",
    "    df_final_merged_before = df_final_merged.copy()\n",
    "    df_final_merged = pd.merge(\n",
    "        df_final_merged,\n",
    "        df_asin_data[[col_asin_asin, col_asin_brand, col_asin_seller]],\n",
    "        left_on=col_original_asin,\n",
    "        right_on=col_asin_asin,\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 检查合并前后的行数变化\n",
    "    print(f\"合并前行数: {len(df_final_merged_before)}, 合并后行数: {len(df_final_merged)}\")\n",
    "    \n",
    "    # 检查合并结果\n",
    "    brand_matched_count = df_final_merged[col_asin_brand].notna().sum()\n",
    "    print(f\"成功合并品牌数据，{brand_matched_count} 行有品牌信息 ({brand_matched_count/len(df_final_merged)*100:.2f}%)\")\n",
    "    \n",
    "    # 如果匹配率很低，输出一些未匹配的ASIN示例\n",
    "    if brand_matched_count/len(df_final_merged) < 0.5:  # 如果匹配率低于50%\n",
    "        unmatched_asins = df_final_merged[df_final_merged[col_asin_brand].isna()][col_original_asin].sample(min(5, len(df_final_merged))).tolist()\n",
    "        print(f\"未匹配ASIN示例: {unmatched_asins}\")\n",
    "        print(f\"检查这些ASIN是否在品牌数据中: {[asin in df_asin_data[col_asin_asin].values for asin in unmatched_asins]}\")\n",
    "\n",
    "    \n",
    "    # 如果有品牌数据，显示品牌分布\n",
    "    if brand_matched_count > 0:\n",
    "        brand_distribution = df_final_merged[col_asin_brand].value_counts().head(10)\n",
    "        print(f\"品牌分布 (前10个):\\n{brand_distribution}\")\n",
    "else:\n",
    "    print(\"跳过品牌数据合并，因为缺少必要的列或数据\")\n",
    "\n",
    "# 清理辅助列\n",
    "df_final_merged = df_final_merged.drop(columns=['original_row_index', 'target_original_index'], errors='ignore')\n",
    "if col_asin_asin in df_final_merged.columns and col_asin_asin != col_original_asin:\n",
    "    df_final_merged = df_final_merged.drop(columns=[col_asin_asin], errors='ignore')\n",
    "\n",
    "# 重命名列 (确保最终列名正确)\n",
    "rename_dict_final = {}\n",
    "if col_matches_match in df_final_merged.columns and col_matches_match != col_new_match:\n",
    "    rename_dict_final[col_matches_match] = col_new_match\n",
    "if col_complete_quadrant in df_final_merged.columns and col_complete_quadrant != col_new_quadrant:\n",
    "     rename_dict_final[col_complete_quadrant] = col_new_quadrant\n",
    "if rename_dict_final:\n",
    "    df_final_merged = df_final_merged.rename(columns=rename_dict_final)\n",
    "\n",
    "print(f\"成功将 '{col_new_match}' 和 '{col_new_quadrant}' 信息合并到原始数据。\")\n",
    "matched_rows_count = df_final_merged[col_new_match].notna().sum()\n",
    "print(f\"  最终数据 {len(df_final_merged)} 行，其中 {matched_rows_count} 行匹配到信息。\")\n",
    "\n",
    "# 验证合并后的数据\n",
    "print(\"\\n验证合并后的数据:\")\n",
    "if col_new_quadrant in df_final_merged.columns:\n",
    "    quadrant_counts = df_final_merged[col_new_quadrant].value_counts()\n",
    "    print(f\"各象限数据量:\\n{quadrant_counts}\")\n",
    "    \n",
    "    # 检查每个象限对应的Match\n",
    "    for quadrant in df_final_merged[col_new_quadrant].dropna().unique():\n",
    "        matches = df_final_merged[df_final_merged[col_new_quadrant] == quadrant][col_new_match].unique()\n",
    "        print(f\"象限 '{quadrant}' 包含的Match: {matches}\")\n",
    "else:\n",
    "    print(f\"警告: 合并后的数据中没有 '{col_new_quadrant}' 列!\")\n",
    "\n",
    "# 保存最终合并后的数据\n",
    "try:\n",
    "    df_final_merged.to_excel(final_merged_output_file, index=False)\n",
    "    print(f\"最终合并后的数据已保存到: {final_merged_output_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"保存最终合并文件时出错: {e}\")\n",
    "\n",
    "print(\"\\n--- 第3步完成 ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fb7cc45-ab16-4716-ae81-5db0de89cdb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T08:16:45.289309Z",
     "iopub.status.busy": "2025-04-18T08:16:45.289309Z",
     "iopub.status.idle": "2025-04-18T08:16:45.319134Z",
     "shell.execute_reply": "2025-04-18T08:16:45.318783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 开始第4步：按 'Match' 统计分析 ---\n",
      "没有找到有效的 'Match' 数据进行分析。\n",
      "\n",
      "--- 第4步完成 ---\n"
     ]
    }
   ],
   "source": [
    "# --- 第4步：按 'Match' 统计分析 ---\n",
    "\n",
    "print(\"\\n--- 开始第4步：按 'Match' 统计分析 ---\")\n",
    "\n",
    "# 筛选出包含有效 'Match' 信息的行进行分析\n",
    "df_analysis_match = df_final_merged.dropna(subset=[col_new_match])\n",
    "\n",
    "if df_analysis_match.empty:\n",
    "    print(\"没有找到有效的 'Match' 数据进行分析。\")\n",
    "else:\n",
    "    # 获取所有唯一的 Match 值\n",
    "    unique_matches = df_analysis_match[col_new_match].unique()\n",
    "    print(f\"将对以下 {len(unique_matches)} 个 'Defect' 进行分析: {unique_matches}\")\n",
    "\n",
    "    # 创建一个 Excel writer 用于保存所有 Match 的分析结果\n",
    "    match_analysis_file = f\"{analysis_output_prefix}by_matches.xlsx\"\n",
    "    with pd.ExcelWriter(match_analysis_file) as writer:\n",
    "        print(f\"\\n分析结果将保存在: {match_analysis_file}\")\n",
    "\n",
    "        for match_value in unique_matches:\n",
    "            print(f\"\\n--- 分析 Match: {match_value} ---\")\n",
    "            df_subset = df_analysis_match[df_analysis_match[col_new_match] == match_value]\n",
    "            sheet_name = str(match_value)[:31] # Excel sheet 名长度限制\n",
    "\n",
    "            analysis_results = {} # 存储当前 Match 的分析结果\n",
    "\n",
    "            # 1. Rating 分布\n",
    "            if col_original_rating in df_subset.columns:\n",
    "                rating_distribution = df_subset[col_original_rating].value_counts().sort_index()\n",
    "                analysis_results[f'{col_original_rating}_分布'] = rating_distribution\n",
    "                print(f\"  {col_original_rating} 分布:\\n{rating_distribution}\")\n",
    "                # 可视化 Rating 分布 (柱状图)\n",
    "                plt.figure(figsize=(8, 5))\n",
    "                sns.countplot(x=col_original_rating, data=df_subset, order=sorted(df_subset[col_original_rating].unique()))\n",
    "                plt.title(f'Match: {match_value} - {col_original_rating} 分布')\n",
    "                plt.xlabel(col_original_rating)\n",
    "                plt.ylabel('数量')\n",
    "                plot_filename = os.path.join(output_dir, f'match_{match_value}_rating_dist.png')\n",
    "                plt.savefig(plot_filename)\n",
    "                plt.close()\n",
    "                print(f\"  Rating 分布图已保存至: {plot_filename}\")\n",
    "            else:\n",
    "                print(f\"  警告: 找不到列 '{col_original_rating}'\")\n",
    "\n",
    "            # 2. ASIN 排名分布 (假设是数值型，用描述性统计)\n",
    "            if col_original_asin_rank in df_subset.columns:\n",
    "                 # 检查列是否为数值类型\n",
    "                if pd.api.types.is_numeric_dtype(df_subset[col_original_asin_rank]):\n",
    "                    asin_rank_stats = df_subset[col_original_asin_rank].describe()\n",
    "                    analysis_results[f'{col_original_asin_rank}_统计'] = asin_rank_stats\n",
    "                    print(f\"\\n  {col_original_asin_rank} 统计:\\n{asin_rank_stats}\")\n",
    "                    # 可视化 ASIN 排名分布 (直方图或箱线图)\n",
    "                    plt.figure(figsize=(8, 5))\n",
    "                    sns.histplot(df_subset[col_original_asin_rank].dropna(), kde=True)\n",
    "                    plt.title(f'Match: {match_value} - {col_original_asin_rank} 分布')\n",
    "                    plt.xlabel(col_original_asin_rank)\n",
    "                    plt.ylabel('频率')\n",
    "                    plot_filename = os.path.join(output_dir, f'match_{match_value}_asin_rank_dist.png')\n",
    "                    plt.savefig(plot_filename)\n",
    "                    plt.close()\n",
    "                    print(f\"  ASIN排名 分布图已保存至: {plot_filename}\")\n",
    "                else:\n",
    "                    print(f\"  警告: 列 '{col_original_asin_rank}' 不是数值类型，无法计算统计信息。将显示值计数。\")\n",
    "                    asin_rank_counts = df_subset[col_original_asin_rank].value_counts()\n",
    "                    analysis_results[f'{col_original_asin_rank}_分布'] = asin_rank_counts\n",
    "                    print(f\"\\n  {col_original_asin_rank} 值计数:\\n{asin_rank_counts.head()}\") # 显示前几个\n",
    "            else:\n",
    "                print(f\"  警告: 找不到列 '{col_original_asin_rank}'\")\n",
    "\n",
    "\n",
    "            # 3. 站点信息分布\n",
    "            if col_original_site in df_subset.columns:\n",
    "                site_distribution = df_subset[col_original_site].value_counts()\n",
    "                analysis_results[f'{col_original_site}_分布'] = site_distribution\n",
    "                print(f\"\\n  {col_original_site} 分布:\\n{site_distribution}\")\n",
    "                # 可视化站点分布 (柱状图)\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                sns.countplot(y=col_original_site, data=df_subset, order=site_distribution.index)\n",
    "                plt.title(f'Match: {match_value} - {col_original_site} 分布')\n",
    "                plt.xlabel('数量')\n",
    "                plt.ylabel(col_original_site)\n",
    "                plot_filename = os.path.join(output_dir, f'match_{match_value}_site_dist.png')\n",
    "                plt.savefig(plot_filename)\n",
    "                plt.close()\n",
    "                print(f\"  站点信息 分布图已保存至: {plot_filename}\")\n",
    "            else:\n",
    "                print(f\"  警告: 找不到列 '{col_original_site}'\")\n",
    "\n",
    "            # 4. 点赞数分布 (假设是数值型)\n",
    "            if col_original_likes in df_subset.columns:\n",
    "                 # 检查列是否为数值类型\n",
    "                if pd.api.types.is_numeric_dtype(df_subset[col_original_likes]):\n",
    "                    likes_stats = df_subset[col_original_likes].describe()\n",
    "                    analysis_results[f'{col_original_likes}_统计'] = likes_stats\n",
    "                    print(f\"\\n  {col_original_likes} 统计:\\n{likes_stats}\")\n",
    "                    # 可视化点赞数分布 (直方图或箱线图)\n",
    "                    plt.figure(figsize=(8, 5))\n",
    "                    # 使用对数刻度可能更好，如果分布很偏斜\n",
    "                    sns.histplot(df_subset[col_original_likes].dropna(), kde=False, bins=30) # 可以调整 bins 数量\n",
    "                    plt.title(f'Match: {match_value} - {col_original_likes} 分布')\n",
    "                    plt.xlabel(col_original_likes)\n",
    "                    plt.ylabel('频率')\n",
    "                    # plt.xscale('log') # 如果需要对数刻度\n",
    "                    plot_filename = os.path.join(output_dir, f'match_{match_value}_likes_dist.png')\n",
    "                    plt.savefig(plot_filename)\n",
    "                    plt.close()\n",
    "                    print(f\"  点赞数 分布图已保存至: {plot_filename}\")\n",
    "                else:\n",
    "                    print(f\"  警告: 列 '{col_original_likes}' 不是数值类型，无法计算统计信息。将显示值计数。\")\n",
    "                    likes_counts = df_subset[col_original_likes].value_counts()\n",
    "                    analysis_results[f'{col_original_likes}_分布'] = likes_counts\n",
    "                    print(f\"\\n  {col_original_likes} 值计数:\\n{likes_counts.head()}\")\n",
    "            else:\n",
    "                print(f\"  警告: 找不到列 '{col_original_likes}'\")\n",
    "\n",
    "            # 将当前 Match 的分析结果写入 Excel 的不同 sheet\n",
    "            # 为了写入 Excel，需要将 Series 转换为 DataFrame\n",
    "            start_row = 0\n",
    "            for name, data in analysis_results.items():\n",
    "                df_to_write = data.reset_index()\n",
    "                # 尝试设置列名\n",
    "                try:\n",
    "                    if \"分布\" in name:\n",
    "                        df_to_write.columns = [data.index.name if data.index.name else 'Value', 'Count']\n",
    "                    elif \"统计\" in name:\n",
    "                         df_to_write.columns = ['Statistic', 'Value']\n",
    "                except: # 如果转换失败，使用默认列名\n",
    "                     pass\n",
    "                df_to_write.to_excel(writer, sheet_name=sheet_name, startrow=start_row, index=False)\n",
    "                # 写入标题\n",
    "                pd.DataFrame([name]).to_excel(writer, sheet_name=sheet_name, startrow=start_row, header=False, index=False)\n",
    "                start_row += len(df_to_write) + 2 # 增加行数，留出空间\n",
    "\n",
    "print(\"\\n--- 第4步完成 ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08c4987f-279d-4293-8a20-0159fb43cd4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T08:16:45.320639Z",
     "iopub.status.busy": "2025-04-18T08:16:45.320639Z",
     "iopub.status.idle": "2025-04-18T08:16:45.412576Z",
     "shell.execute_reply": "2025-04-18T08:16:45.412576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 开始第5步：按 '图表象限' 统计分析 ---\n",
      "df_final_merged 形状: (2342, 24)\n",
      "df_final_merged 中有象限信息的行数: 0\n",
      "df_final_merged 中有品牌信息的行数: 2342\n",
      "df_final_merged 中同时有象限和品牌信息的行数: 0\n",
      "象限分布:\n",
      "Series([], Name: count, dtype: int64)\n",
      "前5个品牌分布:\n",
      "brand\n",
      "LANTEFUL         233\n",
      "VTRIN            172\n",
      "FIDUCIAL HOME    152\n",
      "Sakugi           140\n",
      "ROMGUAR CRAFT    114\n",
      "Name: count, dtype: int64\n",
      "筛选出包含有效象限信息的行数: 0\n",
      "应用Rating 3-5 筛选后，剩余 0 行数据\n",
      "将对以下 0 个 '图表象限' 进行分析: []\n",
      "\n",
      "分析结果将保存在: 生成结果/integrated_analysis_matches/analysis_by_quadrant.xlsx\n",
      "象限数据量概览:\n",
      "Empty DataFrame\n",
      "Columns: [象限, 数据量]\n",
      "Index: []\n",
      "品牌总体分布 (前5个):\n",
      "Empty DataFrame\n",
      "Columns: [品牌, 数量, 占比]\n",
      "Index: []\n",
      "已添加品牌与象限的交叉表\n",
      "\n",
      "--- 第5步完成 ---\n"
     ]
    }
   ],
   "source": [
    "# --- 第5步：按 '图表象限' 统计分析 (增强版) ---\n",
    "print(\"\\n--- 开始第5步：按 '图表象限' 统计分析 ---\")\n",
    "# 检查数据情况\n",
    "print(f\"df_final_merged 形状: {df_final_merged.shape}\")\n",
    "print(f\"df_final_merged 中有象限信息的行数: {df_final_merged[col_new_quadrant].notna().sum()}\")\n",
    "print(f\"df_final_merged 中有品牌信息的行数: {df_final_merged[col_asin_brand].notna().sum() if col_asin_brand in df_final_merged.columns else 0}\")\n",
    "print(f\"df_final_merged 中同时有象限和品牌信息的行数: {df_final_merged.dropna(subset=[col_new_quadrant, col_asin_brand]).shape[0] if col_asin_brand in df_final_merged.columns else 0}\")\n",
    "\n",
    "# 检查象限分布\n",
    "if col_new_quadrant in df_final_merged.columns:\n",
    "    quadrant_counts = df_final_merged[col_new_quadrant].value_counts()\n",
    "    print(f\"象限分布:\\n{quadrant_counts}\")\n",
    "\n",
    "# 检查品牌分布\n",
    "if col_asin_brand in df_final_merged.columns:\n",
    "    brand_counts = df_final_merged[col_asin_brand].value_counts().head(5)\n",
    "    print(f\"前5个品牌分布:\\n{brand_counts}\")\n",
    "\n",
    "# 确保只分析有效的象限数据\n",
    "if col_new_quadrant not in df_final_merged.columns:\n",
    "    print(f\"错误: 合并后的数据中没有 '{col_new_quadrant}' 列，无法进行象限分析\")\n",
    "    print(\"请检查前面的数据处理步骤是否正确\")\n",
    "    exit()\n",
    "\n",
    "df_analysis_quadrant = df_final_merged.dropna(subset=[col_new_quadrant])\n",
    "print(f\"筛选出包含有效象限信息的行数: {len(df_analysis_quadrant)}\")\n",
    "\n",
    "# 如果从文件名中提取到了Rating范围，应用这个筛选条件\n",
    "if min_rating is not None and max_rating is not None and col_original_rating in df_analysis_quadrant.columns:\n",
    "    # 应用Rating筛选\n",
    "    df_analysis_quadrant = df_analysis_quadrant[(df_analysis_quadrant[col_original_rating] >= min_rating) & \n",
    "                                               (df_analysis_quadrant[col_original_rating] <= max_rating)]\n",
    "    print(f\"应用Rating {min_rating}-{max_rating} 筛选后，剩余 {len(df_analysis_quadrant)} 行数据\")\n",
    "\n",
    "# 获取所有唯一的图表象限值\n",
    "unique_quadrants = df_analysis_quadrant[col_new_quadrant].unique()\n",
    "print(f\"将对以下 {len(unique_quadrants)} 个 '图表象限' 进行分析: {unique_quadrants}\")\n",
    "\n",
    "# 创建一个 Excel writer 用于保存所有象限的分析结果\n",
    "quadrant_analysis_file = f\"{analysis_output_prefix}by_quadrant.xlsx\"\n",
    "with pd.ExcelWriter(quadrant_analysis_file) as writer:\n",
    "    print(f\"\\n分析结果将保存在: {quadrant_analysis_file}\")\n",
    "    \n",
    "    # 添加一个总览表，显示每个象限的数据量\n",
    "    quadrant_counts = df_analysis_quadrant[col_new_quadrant].value_counts().reset_index()\n",
    "    quadrant_counts.columns = ['象限', '数据量']\n",
    "    quadrant_counts.to_excel(writer, sheet_name='象限数据量概览', index=False)\n",
    "    print(f\"象限数据量概览:\\n{quadrant_counts}\")\n",
    "    \n",
    "    # 添加一个品牌总体分布表\n",
    "    if col_asin_brand in df_analysis_quadrant.columns:\n",
    "        brand_overall = df_analysis_quadrant[col_asin_brand].value_counts().reset_index()\n",
    "        brand_overall.columns = ['品牌', '数量']\n",
    "        brand_overall['占比'] = brand_overall['数量'] / brand_overall['数量'].sum() * 100\n",
    "        brand_overall['占比'] = brand_overall['占比'].round(2).astype(str) + '%'\n",
    "        brand_overall.to_excel(writer, sheet_name='品牌总体分布', index=False)\n",
    "        print(f\"品牌总体分布 (前5个):\\n{brand_overall.head()}\")\n",
    "        \n",
    "        # 创建品牌与象限的交叉表\n",
    "        brand_quadrant_cross = pd.crosstab(\n",
    "            df_analysis_quadrant[col_asin_brand], \n",
    "            df_analysis_quadrant[col_new_quadrant],\n",
    "            margins=True,\n",
    "            margins_name='总计'\n",
    "        )\n",
    "        brand_quadrant_cross.to_excel(writer, sheet_name='品牌象限交叉表')\n",
    "        print(\"已添加品牌与象限的交叉表\")\n",
    "    \n",
    "    for quadrant_value in unique_quadrants:\n",
    "        print(f\"\\n--- 分析 图表象限: {quadrant_value} ---\")\n",
    "        \n",
    "        # 正确筛选当前象限的数据\n",
    "        df_subset = df_analysis_quadrant[df_analysis_quadrant[col_new_quadrant] == quadrant_value]\n",
    "        print(f\"  该象限包含 {len(df_subset)} 行数据\")\n",
    "        \n",
    "        # 清理象限值作为 sheet 名称 (移除特殊字符等)\n",
    "        sheet_name = str(quadrant_value).replace('/', '-').replace('\\\\', '-').replace('?', '').replace('*', '')[:31]\n",
    "        analysis_results = {} # 存储当前象限的分析结果\n",
    "        \n",
    "        # 1. Rating 分布\n",
    "        if col_original_rating in df_subset.columns:\n",
    "            rating_distribution = df_subset[col_original_rating].value_counts().sort_index()\n",
    "            analysis_results[f'{col_original_rating}_分布'] = rating_distribution\n",
    "            print(f\"  {col_original_rating} 分布:\\n{rating_distribution}\")\n",
    "            \n",
    "            # 可视化\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            sns.countplot(x=col_original_rating, data=df_subset, order=sorted(df_subset[col_original_rating].unique()))\n",
    "            plt.title(f'象限: {quadrant_value} - {col_original_rating} 分布')\n",
    "            plt.xlabel(col_original_rating)\n",
    "            plt.ylabel('数量')\n",
    "            plot_filename = os.path.join(output_dir, f'quadrant_{sheet_name}_rating_dist.png')\n",
    "            plt.savefig(plot_filename)\n",
    "            plt.close()\n",
    "            print(f\"  Rating 分布图已保存至: {plot_filename}\")\n",
    "        \n",
    "        # 2. 品牌分布 (新增)\n",
    "        if col_asin_brand in df_subset.columns:\n",
    "            # 计算品牌分布\n",
    "            brand_distribution = df_subset[col_asin_brand].value_counts()\n",
    "            analysis_results[f'{col_asin_brand}_分布'] = brand_distribution\n",
    "            print(f\"  {col_asin_brand} 分布 (前5个):\\n{brand_distribution.head()}\")\n",
    "            \n",
    "            # 可视化品牌分布 (只显示前10个品牌，其他归为\"其他\")\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            top_brands = brand_distribution.nlargest(10)\n",
    "            if len(brand_distribution) > 10:\n",
    "                other_count = brand_distribution[~brand_distribution.index.isin(top_brands.index)].sum()\n",
    "                top_brands = pd.concat([top_brands, pd.Series({'其他': other_count})])\n",
    "            \n",
    "            # 创建横向条形图\n",
    "            ax = sns.barplot(x=top_brands.values, y=top_brands.index, orient='h')\n",
    "            plt.title(f'象限: {quadrant_value} - 品牌分布 (前10)')\n",
    "            plt.xlabel('数量')\n",
    "            plt.ylabel('品牌')\n",
    "            \n",
    "            # 添加数值标签\n",
    "            for i, v in enumerate(top_brands.values):\n",
    "                ax.text(v + 0.1, i, str(v), va='center')\n",
    "            \n",
    "            plot_filename = os.path.join(output_dir, f'quadrant_{sheet_name}_brand_dist.png')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(plot_filename)\n",
    "            plt.close()\n",
    "            print(f\"  品牌分布图已保存至: {plot_filename}\")\n",
    "            \n",
    "            # 计算品牌占比\n",
    "            brand_percentage = (brand_distribution / brand_distribution.sum() * 100).round(2)\n",
    "            analysis_results[f'{col_asin_brand}_占比'] = brand_percentage\n",
    "            print(f\"  {col_asin_brand} 占比 (前5个):\\n{brand_percentage.head()}\")\n",
    "            \n",
    "            # 可视化品牌占比 (饼图，只显示前7个品牌，其他归为\"其他\")\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            top_brands_pct = brand_percentage.nlargest(7)\n",
    "            if len(brand_percentage) > 7:\n",
    "                other_pct = brand_percentage[~brand_percentage.index.isin(top_brands_pct.index)].sum()\n",
    "                top_brands_pct = pd.concat([top_brands_pct, pd.Series({'其他': other_pct})])\n",
    "            \n",
    "            plt.pie(top_brands_pct.values, labels=top_brands_pct.index, autopct='%1.1f%%', startangle=90)\n",
    "            plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "            plt.title(f'象限: {quadrant_value} - 品牌占比')\n",
    "            \n",
    "            plot_filename = os.path.join(output_dir, f'quadrant_{sheet_name}_brand_pie.png')\n",
    "            plt.savefig(plot_filename)\n",
    "            plt.close()\n",
    "            print(f\"  品牌占比饼图已保存至: {plot_filename}\")\n",
    "        else:\n",
    "            print(f\"  警告: 找不到列 '{col_asin_brand}'，无法分析品牌分布\")\n",
    "        \n",
    "        # 3. ASIN 排名分布\n",
    "        if col_original_asin_rank in df_subset.columns:\n",
    "            # 检查列是否为数值类型\n",
    "            if pd.api.types.is_numeric_dtype(df_subset[col_original_asin_rank]):\n",
    "                asin_rank_stats = df_subset[col_original_asin_rank].describe()\n",
    "                analysis_results[f'{col_original_asin_rank}_统计'] = asin_rank_stats\n",
    "                print(f\"\\n  {col_original_asin_rank} 统计:\\n{asin_rank_stats}\")\n",
    "                \n",
    "                # 可视化 ASIN 排名分布 (直方图或箱线图)\n",
    "                plt.figure(figsize=(8, 5))\n",
    "                sns.histplot(df_subset[col_original_asin_rank].dropna(), kde=True)\n",
    "                plt.title(f'象限: {quadrant_value} - {col_original_asin_rank} 分布')\n",
    "                plt.xlabel(col_original_asin_rank)\n",
    "                plt.ylabel('频率')\n",
    "                plot_filename = os.path.join(output_dir, f'quadrant_{sheet_name}_asin_rank_dist.png')\n",
    "                plt.savefig(plot_filename)\n",
    "                plt.close()\n",
    "                print(f\"  ASIN排名 分布图已保存至: {plot_filename}\")\n",
    "                \n",
    "                # 添加箱线图\n",
    "                plt.figure(figsize=(8, 5))\n",
    "                sns.boxplot(y=df_subset[col_original_asin_rank].dropna())\n",
    "                plt.title(f'象限: {quadrant_value} - {col_original_asin_rank} 箱线图')\n",
    "                plt.ylabel(col_original_asin_rank)\n",
    "                plot_filename = os.path.join(output_dir, f'quadrant_{sheet_name}_asin_rank_box.png')\n",
    "                plt.savefig(plot_filename)\n",
    "                plt.close()\n",
    "                print(f\"  ASIN排名 箱线图已保存至: {plot_filename}\")\n",
    "            else:\n",
    "                print(f\"  警告: 列 '{col_original_asin_rank}' 不是数值类型，无法计算统计量\")\n",
    "                asin_rank_counts = df_subset[col_original_asin_rank].value_counts()\n",
    "                analysis_results[f'{col_original_asin_rank}_分布'] = asin_rank_counts\n",
    "                print(f\"\\n  {col_original_asin_rank} 值计数:\\n{asin_rank_counts.head()}\")\n",
    "        else:\n",
    "            print(f\"  警告: 找不到列 '{col_original_asin_rank}'\")\n",
    "        \n",
    "        # 4. 站点信息分布\n",
    "        if col_original_site in df_subset.columns:\n",
    "            site_distribution = df_subset[col_original_site].value_counts()\n",
    "            analysis_results[f'{col_original_site}_分布'] = site_distribution\n",
    "            print(f\"\\n  {col_original_site} 分布:\\n{site_distribution}\")\n",
    "            \n",
    "            # 可视化站点分布 (柱状图)\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.countplot(y=col_original_site, data=df_subset, order=site_distribution.index)\n",
    "            plt.title(f'象限: {quadrant_value} - {col_original_site} 分布')\n",
    "            plt.xlabel('数量')\n",
    "            plt.ylabel(col_original_site)\n",
    "            plot_filename = os.path.join(output_dir, f'quadrant_{sheet_name}_site_dist.png')\n",
    "            plt.savefig(plot_filename)\n",
    "            plt.close()\n",
    "            print(f\"  站点信息 分布图已保存至: {plot_filename}\")\n",
    "            \n",
    "            # 添加饼图\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            site_percentage = (site_distribution / site_distribution.sum() * 100).round(2)\n",
    "            plt.pie(site_distribution.values, labels=site_distribution.index, autopct='%1.1f%%', startangle=90)\n",
    "            plt.axis('equal')\n",
    "            plt.title(f'象限: {quadrant_value} - {col_original_site} 占比')\n",
    "            plot_filename = os.path.join(output_dir, f'quadrant_{sheet_name}_site_pie.png')\n",
    "            plt.savefig(plot_filename)\n",
    "            plt.close()\n",
    "            print(f\"  站点信息 占比饼图已保存至: {plot_filename}\")\n",
    "        else:\n",
    "            print(f\"  警告: 找不到列 '{col_original_site}'\")\n",
    "        \n",
    "        # 5. 点赞数分布\n",
    "        if col_original_likes in df_subset.columns:\n",
    "            # 检查列是否为数值类型\n",
    "            if pd.api.types.is_numeric_dtype(df_subset[col_original_likes]):\n",
    "                likes_stats = df_subset[col_original_likes].describe()\n",
    "                analysis_results[f'{col_original_likes}_统计'] = likes_stats\n",
    "                print(f\"\\n  {col_original_likes} 统计:\\n{likes_stats}\")\n",
    "                \n",
    "                # 可视化点赞数分布 (直方图)\n",
    "                plt.figure(figsize=(8, 5))\n",
    "                sns.histplot(df_subset[col_original_likes].dropna(), kde=False, bins=20)\n",
    "                plt.title(f'象限: {quadrant_value} - {col_original_likes} 分布')\n",
    "                plt.xlabel(col_original_likes)\n",
    "                plt.ylabel('频率')\n",
    "                plot_filename = os.path.join(output_dir, f'quadrant_{sheet_name}_likes_dist.png')\n",
    "                plt.savefig(plot_filename)\n",
    "                plt.close()\n",
    "                print(f\"  点赞数 分布图已保存至: {plot_filename}\")\n",
    "                \n",
    "                # 对于点赞数，可能存在很多0值，可以添加一个非零点赞数的分布\n",
    "                non_zero_likes = df_subset[df_subset[col_original_likes] > 0][col_original_likes]\n",
    "                if len(non_zero_likes) > 0:\n",
    "                    plt.figure(figsize=(8, 5))\n",
    "                    sns.histplot(non_zero_likes, kde=True, bins=20)\n",
    "                    plt.title(f'象限: {quadrant_value} - 非零{col_original_likes}分布')\n",
    "                    plt.xlabel(f'非零{col_original_likes}')\n",
    "                    plt.ylabel('频率')\n",
    "                    plot_filename = os.path.join(output_dir, f'quadrant_{sheet_name}_non_zero_likes_dist.png')\n",
    "                    plt.savefig(plot_filename)\n",
    "                    plt.close()\n",
    "                    print(f\"  非零点赞数 分布图已保存至: {plot_filename}\")\n",
    "                    \n",
    "                    # 添加非零点赞数统计\n",
    "                    non_zero_likes_stats = non_zero_likes.describe()\n",
    "                    analysis_results[f'非零{col_original_likes}_统计'] = non_zero_likes_stats\n",
    "                    print(f\"\\n  非零{col_original_likes} 统计:\\n{non_zero_likes_stats}\")\n",
    "            else:\n",
    "                print(f\"  警告: 列 '{col_original_likes}' 不是数值类型，无法计算统计量\")\n",
    "                likes_counts = df_subset[col_original_likes].value_counts()\n",
    "                analysis_results[f'{col_original_likes}_分布'] = likes_counts\n",
    "                print(f\"\\n  {col_original_likes} 值计数:\\n{likes_counts.head()}\")\n",
    "        else:\n",
    "            print(f\"  警告: 找不到列 '{col_original_likes}'\")\n",
    "        \n",
    "        # 6. 交叉分析: Rating与品牌\n",
    "        if col_original_rating in df_subset.columns and col_asin_brand in df_subset.columns:\n",
    "            # 创建Rating与品牌的交叉表\n",
    "            rating_brand_cross = pd.crosstab(\n",
    "                df_subset[col_original_rating], \n",
    "                df_subset[col_asin_brand],\n",
    "                margins=True,\n",
    "                margins_name='总计'\n",
    "            )\n",
    "            \n",
    "            # 如果品牌太多，只保留前10个\n",
    "            if rating_brand_cross.shape[1] > 11:  # 10个品牌+1个总计\n",
    "                top_brands = df_subset[col_asin_brand].value_counts().nlargest(10).index\n",
    "                selected_columns = list(top_brands) + ['总计']\n",
    "                rating_brand_cross = rating_brand_cross[selected_columns]\n",
    "            \n",
    "            analysis_results[f'{col_original_rating}与{col_asin_brand}_交叉表'] = rating_brand_cross\n",
    "            print(f\"\\n  {col_original_rating}与{col_asin_brand}交叉表 (部分):\\n{rating_brand_cross.head()}\")\n",
    "        \n",
    "        # 7. 交叉分析: 站点与品牌 (如果数据足够)\n",
    "        if col_original_site in df_subset.columns and col_asin_brand in df_subset.columns and len(df_subset) >= 10:\n",
    "            # 创建站点与品牌的交叉表\n",
    "            site_brand_cross = pd.crosstab(\n",
    "                df_subset[col_original_site], \n",
    "                df_subset[col_asin_brand],\n",
    "                margins=True,\n",
    "                margins_name='总计'\n",
    "            )\n",
    "            \n",
    "            # 如果品牌太多，只保留前10个\n",
    "            if site_brand_cross.shape[1] > 11:  # 10个品牌+1个总计\n",
    "                top_brands = df_subset[col_asin_brand].value_counts().nlargest(10).index\n",
    "                selected_columns = list(top_brands) + ['总计']\n",
    "                site_brand_cross = site_brand_cross[selected_columns]\n",
    "            \n",
    "            analysis_results[f'{col_original_site}与{col_asin_brand}_交叉表'] = site_brand_cross\n",
    "            print(f\"\\n  {col_original_site}与{col_asin_brand}交叉表 (部分):\\n{site_brand_cross.head()}\")\n",
    "        \n",
    "        # 将当前象限的分析结果写入 Excel\n",
    "        start_row = 0\n",
    "        for name, data in analysis_results.items():\n",
    "            df_to_write = data.reset_index() if hasattr(data, 'reset_index') else pd.DataFrame(data)\n",
    "            try:\n",
    "                if \"分布\" in name:\n",
    "                    df_to_write.columns = [data.index.name if data.index.name else '值', '数量']\n",
    "                elif \"占比\" in name:\n",
    "                    df_to_write.columns = [data.index.name if data.index.name else '值', '占比(%)']\n",
    "                elif \"统计\" in name:\n",
    "                    df_to_write.columns = ['统计量', '值']\n",
    "                elif \"交叉表\" in name:\n",
    "                    # 交叉表已经有列名，不需要修改\n",
    "                    pass\n",
    "            except Exception as e:\n",
    "                print(f\"  警告: 设置列名时出错: {e}\")\n",
    "            \n",
    "            try:\n",
    "                df_to_write.to_excel(writer, sheet_name=sheet_name, startrow=start_row+1, index=False if \"交叉表\" not in name else True)\n",
    "                pd.DataFrame([name]).to_excel(writer, sheet_name=sheet_name, startrow=start_row, index=False, header=False)\n",
    "                start_row += len(df_to_write) + 3  # 增加一行空行\n",
    "            except Exception as e:\n",
    "                print(f\"  警告: 写入Excel时出错: {e}\")\n",
    "                # 如果是因为数据太大，尝试写入一个单独的文件\n",
    "                try:\n",
    "                    detail_file = os.path.join(output_dir, f'quadrant_{sheet_name}_{name.replace(\" \", \"_\")}.xlsx')\n",
    "                    df_to_write.to_excel(detail_file, index=False if \"交叉表\" not in name else True)\n",
    "                    print(f\"  数据太大，已保存到单独文件: {detail_file}\")\n",
    "                except:\n",
    "                    print(f\"  无法保存数据 {name}\")\n",
    "\n",
    "print(\"\\n--- 第5步完成 ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fdc4305-805b-431f-8090-623b363a683a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T08:16:45.414992Z",
     "iopub.status.busy": "2025-04-18T08:16:45.414992Z",
     "iopub.status.idle": "2025-04-18T08:16:47.661600Z",
     "shell.execute_reply": "2025-04-18T08:16:47.661600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 开始第6步：品牌专项分析 ---\n",
      "df_final_merged 形状: (2342, 24)\n",
      "df_final_merged 中有品牌信息的行数: 2342\n",
      "筛选出包含有效品牌信息的行数: 2342\n",
      "品牌数量: 52\n",
      "前5个品牌及其数量:\n",
      "brand\n",
      "LANTEFUL         233\n",
      "VTRIN            172\n",
      "FIDUCIAL HOME    152\n",
      "Sakugi           140\n",
      "ROMGUAR CRAFT    114\n",
      "Name: count, dtype: int64\n",
      "同时包含品牌和象限信息的行数: 0\n",
      "\n",
      "分析结果将保存在: 生成结果/integrated_analysis_matches/analysis_brand_analysis.xlsx\n",
      "品牌总体分布 (前5个):\n",
      "              品牌   数量     占比\n",
      "0       LANTEFUL  233  9.95%\n",
      "1          VTRIN  172  7.34%\n",
      "2  FIDUCIAL HOME  152  6.49%\n",
      "3         Sakugi  140  5.98%\n",
      "4  ROMGUAR CRAFT  114  4.87%\n",
      "已添加品牌与象限的交叉表\n",
      "已添加品牌与Rating的交叉表\n",
      "将对前10个品牌进行详细分析: ['LANTEFUL', 'VTRIN', 'FIDUCIAL HOME', 'Sakugi', 'ROMGUAR CRAFT', 'OYREL', 'Simple Houseware', 'HOOBRO', 'INGIORDAR', 'SONGMICS']\n",
      "\n",
      "--- 分析品牌: LANTEFUL ---\n",
      "  象限分布:\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  象限分布图已保存至: 生成结果/integrated_analysis_matches/brand_LANTEFUL_quadrant_dist.png\n",
      "  Rating分布:\n",
      "Rating\n",
      "1     56\n",
      "2     12\n",
      "3     22\n",
      "4     23\n",
      "5    120\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\Lynx\\lib\\site-packages\\seaborn\\_base.py:1601: UserWarning: Horizontal orientation ignored with only `y` specified.\n",
      "  warnings.warn(single_var_warning.format(\"Horizontal\", \"y\"))\n",
      "C:\\Users\\admin\\anaconda3\\envs\\Lynx\\lib\\site-packages\\seaborn\\_base.py:1601: UserWarning: Horizontal orientation ignored with only `y` specified.\n",
      "  warnings.warn(single_var_warning.format(\"Horizontal\", \"y\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rating分布图已保存至: 生成结果/integrated_analysis_matches/brand_LANTEFUL_rating_dist.png\n",
      "\n",
      "--- 分析品牌: VTRIN ---\n",
      "  象限分布:\n",
      "Series([], Name: count, dtype: int64)\n",
      "  象限分布图已保存至: 生成结果/integrated_analysis_matches/brand_VTRIN_quadrant_dist.png\n",
      "  Rating分布:\n",
      "Rating\n",
      "1    38\n",
      "2    21\n",
      "3    12\n",
      "4    16\n",
      "5    85\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rating分布图已保存至: 生成结果/integrated_analysis_matches/brand_VTRIN_rating_dist.png\n",
      "\n",
      "--- 分析品牌: FIDUCIAL HOME ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  象限分布:\n",
      "Series([], Name: count, dtype: int64)\n",
      "  象限分布图已保存至: 生成结果/integrated_analysis_matches/brand_FIDUCIAL HOME_quadrant_dist.png\n",
      "  Rating分布:\n",
      "Rating\n",
      "1    62\n",
      "2    16\n",
      "3    15\n",
      "4    16\n",
      "5    43\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\Lynx\\lib\\site-packages\\seaborn\\_base.py:1601: UserWarning: Horizontal orientation ignored with only `y` specified.\n",
      "  warnings.warn(single_var_warning.format(\"Horizontal\", \"y\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rating分布图已保存至: 生成结果/integrated_analysis_matches/brand_FIDUCIAL HOME_rating_dist.png\n",
      "\n",
      "--- 分析品牌: Sakugi ---\n",
      "  象限分布:\n",
      "Series([], Name: count, dtype: int64)\n",
      "  象限分布图已保存至: 生成结果/integrated_analysis_matches/brand_Sakugi_quadrant_dist.png\n",
      "  Rating分布:\n",
      "Rating\n",
      "1    39\n",
      "2    21\n",
      "3    17\n",
      "4    12\n",
      "5    51\n",
      "Name: count, dtype: int64\n",
      "  Rating分布图已保存至: 生成结果/integrated_analysis_matches/brand_Sakugi_rating_dist.png\n",
      "\n",
      "--- 分析品牌: ROMGUAR CRAFT ---\n",
      "  象限分布:\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\Lynx\\lib\\site-packages\\seaborn\\_base.py:1601: UserWarning: Horizontal orientation ignored with only `y` specified.\n",
      "  warnings.warn(single_var_warning.format(\"Horizontal\", \"y\"))\n",
      "C:\\Users\\admin\\anaconda3\\envs\\Lynx\\lib\\site-packages\\seaborn\\_base.py:1601: UserWarning: Horizontal orientation ignored with only `y` specified.\n",
      "  warnings.warn(single_var_warning.format(\"Horizontal\", \"y\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  象限分布图已保存至: 生成结果/integrated_analysis_matches/brand_ROMGUAR CRAFT_quadrant_dist.png\n",
      "  Rating分布:\n",
      "Rating\n",
      "1    14\n",
      "2    10\n",
      "3    14\n",
      "4    19\n",
      "5    57\n",
      "Name: count, dtype: int64\n",
      "  Rating分布图已保存至: 生成结果/integrated_analysis_matches/brand_ROMGUAR CRAFT_rating_dist.png\n",
      "\n",
      "--- 分析品牌: OYREL ---\n",
      "  象限分布:\n",
      "Series([], Name: count, dtype: int64)\n",
      "  象限分布图已保存至: 生成结果/integrated_analysis_matches/brand_OYREL_quadrant_dist.png\n",
      "  Rating分布:\n",
      "Rating\n",
      "1    13\n",
      "2     4\n",
      "3     8\n",
      "4    15\n",
      "5    70\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\Lynx\\lib\\site-packages\\seaborn\\_base.py:1601: UserWarning: Horizontal orientation ignored with only `y` specified.\n",
      "  warnings.warn(single_var_warning.format(\"Horizontal\", \"y\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rating分布图已保存至: 生成结果/integrated_analysis_matches/brand_OYREL_rating_dist.png\n",
      "\n",
      "--- 分析品牌: Simple Houseware ---\n",
      "  象限分布:\n",
      "Series([], Name: count, dtype: int64)\n",
      "  象限分布图已保存至: 生成结果/integrated_analysis_matches/brand_Simple Houseware_quadrant_dist.png\n",
      "  Rating分布:\n",
      "Rating\n",
      "1     9\n",
      "2     4\n",
      "3     4\n",
      "4    10\n",
      "5    76\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\Lynx\\lib\\site-packages\\seaborn\\_base.py:1601: UserWarning: Horizontal orientation ignored with only `y` specified.\n",
      "  warnings.warn(single_var_warning.format(\"Horizontal\", \"y\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rating分布图已保存至: 生成结果/integrated_analysis_matches/brand_Simple Houseware_rating_dist.png\n",
      "\n",
      "--- 分析品牌: HOOBRO ---\n",
      "  象限分布:\n",
      "Series([], Name: count, dtype: int64)\n",
      "  象限分布图已保存至: 生成结果/integrated_analysis_matches/brand_HOOBRO_quadrant_dist.png\n",
      "  Rating分布:\n",
      "Rating\n",
      "1     4\n",
      "2     6\n",
      "3     6\n",
      "4    13\n",
      "5    73\n",
      "Name: count, dtype: int64\n",
      "  Rating分布图已保存至: 生成结果/integrated_analysis_matches/brand_HOOBRO_rating_dist.png\n",
      "\n",
      "--- 分析品牌: INGIORDAR ---\n",
      "  象限分布:\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\Lynx\\lib\\site-packages\\seaborn\\_base.py:1601: UserWarning: Horizontal orientation ignored with only `y` specified.\n",
      "  warnings.warn(single_var_warning.format(\"Horizontal\", \"y\"))\n",
      "C:\\Users\\admin\\anaconda3\\envs\\Lynx\\lib\\site-packages\\seaborn\\_base.py:1601: UserWarning: Horizontal orientation ignored with only `y` specified.\n",
      "  warnings.warn(single_var_warning.format(\"Horizontal\", \"y\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  象限分布图已保存至: 生成结果/integrated_analysis_matches/brand_INGIORDAR_quadrant_dist.png\n",
      "  Rating分布:\n",
      "Rating\n",
      "1     7\n",
      "2     5\n",
      "3     2\n",
      "4    11\n",
      "5    68\n",
      "Name: count, dtype: int64\n",
      "  Rating分布图已保存至: 生成结果/integrated_analysis_matches/brand_INGIORDAR_rating_dist.png\n",
      "\n",
      "--- 分析品牌: SONGMICS ---\n",
      "  象限分布:\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\Lynx\\lib\\site-packages\\seaborn\\_base.py:1601: UserWarning: Horizontal orientation ignored with only `y` specified.\n",
      "  warnings.warn(single_var_warning.format(\"Horizontal\", \"y\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  象限分布图已保存至: 生成结果/integrated_analysis_matches/brand_SONGMICS_quadrant_dist.png\n",
      "  Rating分布:\n",
      "Rating\n",
      "1     6\n",
      "2     1\n",
      "3     4\n",
      "4     8\n",
      "5    62\n",
      "Name: count, dtype: int64\n",
      "  Rating分布图已保存至: 生成结果/integrated_analysis_matches/brand_SONGMICS_rating_dist.png\n",
      "\n",
      "--- 第6步完成 ---\n"
     ]
    }
   ],
   "source": [
    "# --- 第6步：品牌专项分析 ---\n",
    "print(\"\\n--- 开始第6步：品牌专项分析 ---\")\n",
    "\n",
    "# 检查数据情况\n",
    "print(f\"df_final_merged 形状: {df_final_merged.shape}\")\n",
    "print(f\"df_final_merged 中有品牌信息的行数: {df_final_merged[col_asin_brand].notna().sum() if col_asin_brand in df_final_merged.columns else 0}\")\n",
    "\n",
    "# 确保有品牌数据\n",
    "if col_asin_brand not in df_final_merged.columns:\n",
    "    print(f\"错误: 合并后的数据中没有 '{col_asin_brand}' 列，无法进行品牌分析\")\n",
    "    print(\"请检查前面的数据处理步骤是否正确\")\n",
    "    exit()\n",
    "\n",
    "# 筛选有效数据\n",
    "df_brand_analysis = df_final_merged.dropna(subset=[col_asin_brand])\n",
    "print(f\"筛选出包含有效品牌信息的行数: {len(df_brand_analysis)}\")\n",
    "print(f\"品牌数量: {df_brand_analysis[col_asin_brand].nunique()}\")\n",
    "print(f\"前5个品牌及其数量:\\n{df_brand_analysis[col_asin_brand].value_counts().head()}\")\n",
    "\n",
    "# 如果有象限信息，进行品牌-象限交叉分析\n",
    "if col_new_quadrant in df_brand_analysis.columns:\n",
    "    df_brand_with_quadrant = df_brand_analysis.dropna(subset=[col_new_quadrant])\n",
    "    print(f\"同时包含品牌和象限信息的行数: {len(df_brand_with_quadrant)}\")\n",
    "    \n",
    "    # 创建一个 Excel writer 用于保存品牌分析结果\n",
    "    brand_analysis_file = f\"{analysis_output_prefix}brand_analysis.xlsx\"\n",
    "    with pd.ExcelWriter(brand_analysis_file) as writer:\n",
    "        print(f\"\\n分析结果将保存在: {brand_analysis_file}\")\n",
    "        \n",
    "        # 1. 品牌总体分布\n",
    "        brand_overall = df_brand_analysis[col_asin_brand].value_counts().reset_index()\n",
    "        brand_overall.columns = ['品牌', '数量']\n",
    "        brand_overall['占比'] = brand_overall['数量'] / brand_overall['数量'].sum() * 100\n",
    "        brand_overall['占比'] = brand_overall['占比'].round(2).astype(str) + '%'\n",
    "        brand_overall.to_excel(writer, sheet_name='品牌总体分布', index=False)\n",
    "        print(f\"品牌总体分布 (前5个):\\n{brand_overall.head()}\")\n",
    "        \n",
    "        # 2. 品牌-象限交叉表\n",
    "        brand_quadrant_cross = pd.crosstab(\n",
    "            df_brand_with_quadrant[col_asin_brand], \n",
    "            df_brand_with_quadrant[col_new_quadrant],\n",
    "            margins=True,\n",
    "            margins_name='总计'\n",
    "        )\n",
    "        brand_quadrant_cross.to_excel(writer, sheet_name='品牌象限交叉表')\n",
    "        print(\"已添加品牌与象限的交叉表\")\n",
    "        \n",
    "        # 3. 品牌-Rating交叉表\n",
    "        if col_original_rating in df_brand_analysis.columns:\n",
    "            brand_rating_cross = pd.crosstab(\n",
    "                df_brand_analysis[col_asin_brand], \n",
    "                df_brand_analysis[col_original_rating],\n",
    "                margins=True,\n",
    "                margins_name='总计'\n",
    "            )\n",
    "            brand_rating_cross.to_excel(writer, sheet_name='品牌Rating交叉表')\n",
    "            print(\"已添加品牌与Rating的交叉表\")\n",
    "        \n",
    "        # 4. 每个品牌的详细分析\n",
    "        top_brands = df_brand_analysis[col_asin_brand].value_counts().nlargest(10).index\n",
    "        print(f\"将对前10个品牌进行详细分析: {top_brands.tolist()}\")\n",
    "        \n",
    "        for brand in top_brands:\n",
    "            print(f\"\\n--- 分析品牌: {brand} ---\")\n",
    "            df_brand_subset = df_brand_analysis[df_brand_analysis[col_asin_brand] == brand]\n",
    "            \n",
    "            # 清理品牌名作为sheet名\n",
    "            sheet_name = str(brand).replace('/', '-').replace('\\\\', '-').replace('?', '').replace('*', '')[:31]\n",
    "            \n",
    "            # 4.1 象限分布\n",
    "            if col_new_quadrant in df_brand_subset.columns:\n",
    "                quadrant_dist = df_brand_subset[col_new_quadrant].value_counts()\n",
    "                quadrant_dist_df = quadrant_dist.reset_index()\n",
    "                quadrant_dist_df.columns = ['象限', '数量']\n",
    "                quadrant_dist_df['占比'] = (quadrant_dist_df['数量'] / quadrant_dist_df['数量'].sum() * 100).round(2)\n",
    "                quadrant_dist_df.to_excel(writer, sheet_name=sheet_name, startrow=0, index=False)\n",
    "                print(f\"  象限分布:\\n{quadrant_dist}\")\n",
    "                \n",
    "                # 可视化象限分布\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                ax = sns.barplot(x=quadrant_dist.values, y=quadrant_dist.index, orient='h')\n",
    "                plt.title(f'品牌: {brand} - 象限分布')\n",
    "                plt.xlabel('数量')\n",
    "                plt.ylabel('象限')\n",
    "                \n",
    "                # 添加数值标签\n",
    "                for i, v in enumerate(quadrant_dist.values):\n",
    "                    ax.text(v + 0.1, i, str(v), va='center')\n",
    "                \n",
    "                plot_filename = os.path.join(output_dir, f'brand_{sheet_name}_quadrant_dist.png')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(plot_filename)\n",
    "                plt.close()\n",
    "                print(f\"  象限分布图已保存至: {plot_filename}\")\n",
    "            \n",
    "            # 4.2 Rating分布\n",
    "            if col_original_rating in df_brand_subset.columns:\n",
    "                rating_dist = df_brand_subset[col_original_rating].value_counts().sort_index()\n",
    "                rating_dist_df = rating_dist.reset_index()\n",
    "                rating_dist_df.columns = ['Rating', '数量']\n",
    "                rating_dist_df['占比'] = (rating_dist_df['数量'] / rating_dist_df['数量'].sum() * 100).round(2)\n",
    "                rating_dist_df.to_excel(writer, sheet_name=sheet_name, startrow=len(quadrant_dist)+3 if col_new_quadrant in df_brand_subset.columns else 0, index=False)\n",
    "                print(f\"  Rating分布:\\n{rating_dist}\")\n",
    "                \n",
    "                # 可视化Rating分布\n",
    "                plt.figure(figsize=(8, 5))\n",
    "                sns.countplot(x=col_original_rating, data=df_brand_subset, order=sorted(df_brand_subset[col_original_rating].unique()))\n",
    "                plt.title(f'品牌: {brand} - Rating分布')\n",
    "                plt.xlabel('Rating')\n",
    "                plt.ylabel('数量')\n",
    "                plot_filename = os.path.join(output_dir, f'brand_{sheet_name}_rating_dist.png')\n",
    "                plt.savefig(plot_filename)\n",
    "                plt.close()\n",
    "                print(f\"  Rating分布图已保存至: {plot_filename}\")\n",
    "            \n",
    "            # 4.3 Match分布\n",
    "            if col_new_match in df_brand_subset.columns:\n",
    "                match_dist = df_brand_subset[col_new_match].value_counts()\n",
    "                if not match_dist.empty:\n",
    "                    match_dist_df = match_dist.reset_index()\n",
    "                    match_dist_df.columns = ['Match', '数量']\n",
    "                    match_dist_df['占比'] = (match_dist_df['数量'] / match_dist_df['数量'].sum() * 100).round(2)\n",
    "                    \n",
    "                    # 计算起始行\n",
    "                    start_row = 0\n",
    "                    if col_new_quadrant in df_brand_subset.columns:\n",
    "                        start_row += len(quadrant_dist) + 3\n",
    "                    if col_original_rating in df_brand_subset.columns:\n",
    "                        start_row += len(rating_dist) + 3\n",
    "                    \n",
    "                    match_dist_df.to_excel(writer, sheet_name=sheet_name, startrow=start_row, index=False)\n",
    "                    print(f\"  Match分布 (前3个):\\n{match_dist.head(3)}\")\n",
    "\n",
    "print(\"\\n--- 第6步完成 ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c32606-045d-4fe2-a7f0-49c96bca846e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0434ba3b-33ed-46eb-8796-82d6d74b08db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lynx",
   "language": "python",
   "name": "lynx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
