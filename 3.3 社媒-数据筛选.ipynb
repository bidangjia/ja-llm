{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T10:45:11.386822Z",
     "iopub.status.busy": "2025-04-15T10:45:11.384811Z",
     "iopub.status.idle": "2025-04-15T10:45:12.026127Z",
     "shell.execute_reply": "2025-04-15T10:45:12.026127Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨è¯»å–æ–‡ä»¶: twitter_keywords_zo tech.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æˆåŠŸè¯»å–æ•°æ®ï¼Œå…± 898 è¡Œå’Œ 37 åˆ—\n",
      "ä½¿ç”¨çš„æ–‡ä»¶å¤¹å: ç”Ÿæˆç»“æœ/social_media/\n",
      "ä½¿ç”¨çš„å…³é”®è¯æ–‡ä»¶: ç”Ÿæˆç»“æœ/social_media/keywords.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# # ä»Excelæ–‡ä»¶åä¸­æå–åŸºç¡€æ–‡ä»¶å¤¹åç§°\n",
    "folder_name = 'ç”Ÿæˆç»“æœ/social_media/'\n",
    "\n",
    "# ä½¿ç”¨å‰é¢ä»£ç ä¸­ç”Ÿæˆçš„æ–‡ä»¶å¤¹åå’Œæ–‡ä»¶è·¯å¾„\n",
    "#filename_keywords = f'{folder_name}/keywords.txt'  # æŒ‡å‘æ–°ç”Ÿæˆçš„å…³é”®è¯æ–‡ä»¶\n",
    "filename_keywords = os.path.join(folder_name, 'keywords.txt')\n",
    "# è®¾ç½®æ•°æ®æ–‡ä»¶å¤¹è·¯å¾„\n",
    "origin_folder = './Data'\n",
    "\n",
    "# æŸ¥æ‰¾æ‰€æœ‰ä»¥\"twitter_keywords\"å¼€å¤´çš„xlsxæ–‡ä»¶\n",
    "xlsx_pattern = os.path.join(origin_folder, 'twitter_keywords*.xlsx')\n",
    "xlsx_files = glob.glob(xlsx_pattern)\n",
    "\n",
    "if not xlsx_files:\n",
    "    print(f\"åœ¨ {origin_folder} ç›®å½•ä¸­æœªæ‰¾åˆ°ä»¥'twitter_keywords'å¼€å¤´çš„Excelæ–‡ä»¶\")\n",
    "else:\n",
    "    # ä½¿ç”¨æ‰¾åˆ°çš„ç¬¬ä¸€ä¸ªæ–‡ä»¶ï¼ˆå¦‚æœæœ‰å¤šä¸ªæ–‡ä»¶ï¼Œå¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´ï¼‰\n",
    "    filename = xlsx_files[0]\n",
    "    print(f\"æ­£åœ¨è¯»å–æ–‡ä»¶: {os.path.basename(filename)}\")\n",
    "    \n",
    "    # è¯»å–Excelæ–‡ä»¶\n",
    "    data = pd.read_excel(filename)\n",
    "    \n",
    "    # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯\n",
    "    print(f\"æˆåŠŸè¯»å–æ•°æ®ï¼Œå…± {len(data)} è¡Œå’Œ {len(data.columns)} åˆ—\")\n",
    "\n",
    "print(f\"ä½¿ç”¨çš„æ–‡ä»¶å¤¹å: {folder_name}\")\n",
    "print(f\"ä½¿ç”¨çš„å…³é”®è¯æ–‡ä»¶: {filename_keywords}\")\n",
    "\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T10:45:12.026127Z",
     "iopub.status.busy": "2025-04-15T10:45:12.026127Z",
     "iopub.status.idle": "2025-04-15T10:45:12.041421Z",
     "shell.execute_reply": "2025-04-15T10:45:12.041421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ–‡ä»¶ ç”Ÿæˆç»“æœ/social_media/hypo.md ä¸å­˜åœ¨ï¼Œè¯·æä¾›æ­£ç¡®çš„æ–‡ä»¶è·¯å¾„\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "def extract_markdown_table(markdown_file):\n",
    "    \"\"\"\n",
    "    ä»Markdownæ–‡ä»¶ä¸­æå–è¡¨æ ¼å†…å®¹å¹¶è½¬æ¢ä¸ºDataFrame\n",
    "    \n",
    "    å‚æ•°:\n",
    "    markdown_file - Markdownæ–‡ä»¶è·¯å¾„\n",
    "    \n",
    "    è¿”å›:\n",
    "    pandas DataFrame - åŒ…å«è¡¨æ ¼å†…å®¹çš„æ•°æ®æ¡†\n",
    "    \"\"\"\n",
    "    # è¯»å–Markdownæ–‡ä»¶å†…å®¹\n",
    "    with open(markdown_file, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    # æŒ‰è¡Œåˆ†å‰²å†…å®¹\n",
    "    lines = content.strip().split('\\n')\n",
    "    \n",
    "    # æ‰¾åˆ°è¡¨æ ¼è¡Œï¼ˆä»¥|å¼€å§‹å’Œç»“æŸçš„è¡Œï¼‰\n",
    "    table_lines = []\n",
    "    in_table = False\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith('|') and line.endswith('|'):\n",
    "            if not in_table:\n",
    "                in_table = True\n",
    "                table_lines = []\n",
    "            table_lines.append(line)\n",
    "        elif in_table and not line:\n",
    "            # è¡¨æ ¼ç»“æŸï¼Œæ‰¾åˆ°äº†ä¸€ä¸ªå®Œæ•´è¡¨æ ¼\n",
    "            break\n",
    "    \n",
    "    if not table_lines:\n",
    "        raise ValueError(\"æœªåœ¨Markdownæ–‡ä»¶ä¸­æ‰¾åˆ°è¡¨æ ¼å†…å®¹\")\n",
    "    \n",
    "    # è§£æè¡¨æ ¼å†…å®¹\n",
    "    rows = []\n",
    "    for line in table_lines:\n",
    "        # åˆ†å‰²è¡Œå¹¶ç§»é™¤å‰åçš„|\n",
    "        cells = line.strip().split('|')[1:-1]\n",
    "        # æ¸…ç†æ¯ä¸ªå•å…ƒæ ¼å†…å®¹\n",
    "        cells = [cell.strip() for cell in cells]\n",
    "        rows.append(cells)\n",
    "    \n",
    "    # ç¬¬ä¸€è¡Œæ˜¯è¡¨å¤´\n",
    "    headers = rows[0]\n",
    "    \n",
    "    # è·³è¿‡è¡¨å¤´å’Œåˆ†éš”è¡Œ(é€šå¸¸æ˜¯ç¬¬äºŒè¡Œï¼ŒåŒ…å« ---|--- ç±»ä¼¼å†…å®¹)\n",
    "    data_rows = rows[2:] if len(rows) > 2 else []\n",
    "    \n",
    "    # åˆ›å»ºDataFrame\n",
    "    df = pd.DataFrame(data_rows, columns=headers)\n",
    "    \n",
    "    print(f\"å·²æˆåŠŸä»Markdownæå–è¡¨æ ¼ï¼ŒåŒ…å«{len(df)}è¡Œå’Œ{len(df.columns)}åˆ—\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ä½¿ç”¨ç¤ºä¾‹\n",
    "# å‡è®¾Markdownæ–‡ä»¶è·¯å¾„\n",
    "markdown_file = os.path.join(folder_name, 'hypo.md')\n",
    "\n",
    "# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n",
    "if os.path.exists(markdown_file):\n",
    "    # ä»Markdownæ–‡ä»¶æå–è¡¨æ ¼\n",
    "    variables_df = extract_markdown_table(markdown_file)\n",
    "    \n",
    "    # æ˜¾ç¤ºæå–çš„DataFrame\n",
    "    print(\"\\næå–çš„DataFrameå¤´éƒ¨:\")\n",
    "    display(variables_df.head())\n",
    "else:\n",
    "    print(f\"æ–‡ä»¶ {markdown_file} ä¸å­˜åœ¨ï¼Œè¯·æä¾›æ­£ç¡®çš„æ–‡ä»¶è·¯å¾„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T10:45:12.043756Z",
     "iopub.status.busy": "2025-04-15T10:45:12.041421Z",
     "iopub.status.idle": "2025-04-15T10:45:12.268350Z",
     "shell.execute_reply": "2025-04-15T10:45:12.268350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "å¤„ç†åçš„æ•°æ®æ ·æœ¬:\n",
      "                    id  title  \\\n",
      "0  1911502146408952289    NaN   \n",
      "1  1910928938831847857    NaN   \n",
      "2  1910777809611694348    NaN   \n",
      "3  1909802064718578054    NaN   \n",
      "4  1909480340126581095    NaN   \n",
      "\n",
      "                                             content  url lang  \\\n",
      "0  When choosing a shoe cabinet, consider space, ...  NaN   en   \n",
      "1  Jager-Smith Basic Duffle Polyester Bag/Gym Bag...  NaN   en   \n",
      "2  NEEWER DSLR Camera Clamp Adjustable Monitor Mo...  NaN   en   \n",
      "3  @Lukebraus @mrginden @nikicaga No itâ€™s not, it...  NaN   en   \n",
      "4  Metal Shoe Rack\\nUpto 24% off\\nLink for you: h...  NaN   en   \n",
      "\n",
      "                     publish_time publish_time_date publish_time_time  \\\n",
      "0  Sun Apr 13 19:30:00 +0000 2025        2025-04-13          19:30:00   \n",
      "1  Sat Apr 12 05:32:17 +0000 2025        2025-04-12          05:32:17   \n",
      "2  Fri Apr 11 19:31:45 +0000 2025        2025-04-11          19:31:45   \n",
      "3  Wed Apr 09 02:54:29 +0000 2025        2025-04-09          02:54:29   \n",
      "4  Tue Apr 08 05:36:04 +0000 2025        2025-04-08          05:36:04   \n",
      "\n",
      "   is_truncated  interaction_like_cnt  ...  author_video_cnt  \\\n",
      "0         False                     0  ...               NaN   \n",
      "1         False                     0  ...               NaN   \n",
      "2          True                     0  ...               NaN   \n",
      "3         False                     4  ...               NaN   \n",
      "4         False                     0  ...               NaN   \n",
      "\n",
      "   author_media_cnt  author_followers_cnt  author_org_attribute  \\\n",
      "0               666                   172                   NaN   \n",
      "1                34                     2                   NaN   \n",
      "2                16                    26                   NaN   \n",
      "3               203                   134                   NaN   \n",
      "4              1993                     6                   NaN   \n",
      "\n",
      "   author_verified_type  author_collection_cnt  \\\n",
      "0                 False                      0   \n",
      "1                 False                      0   \n",
      "2                 False                      0   \n",
      "3                 False                      0   \n",
      "4                 False                      0   \n",
      "\n",
      "                              author_profile_picture  \\\n",
      "0  https://pbs.twimg.com/profile_images/171799062...   \n",
      "1  https://pbs.twimg.com/profile_images/138328528...   \n",
      "2  https://pbs.twimg.com/profile_images/186457102...   \n",
      "3  https://pbs.twimg.com/profile_images/76942362/...   \n",
      "4  https://pbs.twimg.com/profile_images/186528787...   \n",
      "\n",
      "        author_registed_timestamp  author_registed_timestamp_date  \\\n",
      "0  Fri Oct 27 19:21:03 +0000 2023                      2023-10-27   \n",
      "1  Thu Sep 27 13:04:00 +0000 2018                      2018-09-27   \n",
      "2  Sat Jan 09 04:45:08 +0000 2021                      2021-01-09   \n",
      "3  Tue Aug 26 03:51:50 +0000 2008                      2008-08-26   \n",
      "4  Sun Jun 18 16:13:39 +0000 2023                      2023-06-18   \n",
      "\n",
      "   author_registed_timestamp_time  \n",
      "0                        19:21:03  \n",
      "1                        13:04:00  \n",
      "2                        04:45:08  \n",
      "3                        03:51:50  \n",
      "4                        16:13:39  \n",
      "\n",
      "[5 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "# æ‰§è¡Œå¤„ç†\n",
    "result = pd.read_excel(filename)\n",
    "\n",
    "# # æ£€æŸ¥ç»“æœ\n",
    "# print(\"å¤„ç†åçš„æ•°æ®æ¡†åˆ—:\")\n",
    "# print(result.columns.tolist())\n",
    "\n",
    "# # å®šä¹‰æ„Ÿå…´è¶£çš„äº¤äº’å­—æ®µ\n",
    "# interaction_fields = ['rating', 'sumCnt', 'likeCnt', 'viewCnt', 'shareCnt', \n",
    "#                       'repostCnt', 'commentCnt', 'dislikeCnt', 'collectionCnt']\n",
    "\n",
    "# # æ£€æŸ¥è¿™äº›å­—æ®µçš„ç©ºå€¼æƒ…å†µ\n",
    "# print(\"\\nå¤„ç†åå„äº¤äº’å­—æ®µçš„ NaN å€¼æ•°é‡:\")\n",
    "# for field in interaction_fields:\n",
    "#     print(f\"{field} çš„ null å€¼æ•°é‡: {result[field].isna().sum()}\")\n",
    "\n",
    "# éªŒè¯å‰å‡ è¡Œ\n",
    "print(\"\\nå¤„ç†åçš„æ•°æ®æ ·æœ¬:\")\n",
    "print(result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T10:45:12.268350Z",
     "iopub.status.busy": "2025-04-15T10:45:12.268350Z",
     "iopub.status.idle": "2025-04-15T10:45:12.283594Z",
     "shell.execute_reply": "2025-04-15T10:45:12.283594Z"
    }
   },
   "outputs": [],
   "source": [
    "# # å®šä¹‰å¯èƒ½æ¥è‡ª interaction çš„æ‰€æœ‰å­—æ®µ\n",
    "# interaction_fields = ['rating', 'sumCnt', 'likeCnt', 'reactor', 'viewCnt', \n",
    "#                      'shareCnt', 'repostCnt', 'commentCnt', 'dislikeCnt', 'collectionCnt']\n",
    "\n",
    "# # æ›¿æ¢æ‰€æœ‰è¿™äº›å­—æ®µä¸­çš„ NaN å€¼ä¸º 0\n",
    "# for field in interaction_fields:\n",
    "#     if field in result.columns:\n",
    "#         result[field] = result[field].fillna(0)\n",
    "\n",
    "# # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ NaN å€¼\n",
    "# print(\"å¤„ç†åå„äº¤äº’å­—æ®µçš„ NaN å€¼æ•°é‡:\")\n",
    "# for field in interaction_fields:\n",
    "#     if field in result.columns:\n",
    "#         print(f\"{field}: {result[field].isna().sum()}\")\n",
    "\n",
    "# # éªŒè¯å‰å‡ è¡Œ\n",
    "# print(\"\\nå¤„ç†åçš„æ•°æ®æ ·æœ¬:\")\n",
    "# print(result[interaction_fields].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å…ˆä½¿ç”¨å…³é”®è¯ç­›é€‰topicåˆ—ï¼Œå†ç­›é€‰contentåˆ—ï¼Œé˜²æ­¢é”™æ¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T10:45:12.283594Z",
     "iopub.status.busy": "2025-04-15T10:45:12.283594Z",
     "iopub.status.idle": "2025-04-15T10:45:12.298625Z",
     "shell.execute_reply": "2025-04-15T10:45:12.298625Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm  # ç”¨äºæ˜¾ç¤ºè¿›åº¦æ¡\n",
    "\n",
    "\n",
    "def load_keywords(file_path):\n",
    "    \"\"\"\n",
    "    åŠ è½½å…³é”®è¯æ–‡ä»¶ï¼Œæ¯è¡Œä¸€ä¸ªå…³é”®è¯\n",
    "    è¿”å›ä¸€ä¸ªåŒ…å«æ‰€æœ‰å…³é”®è¯çš„é›†åˆï¼ˆå…¨éƒ¨è½¬ä¸ºå°å†™ä»¥ç¡®ä¿å¤§å°å†™ä¸æ•æ„ŸåŒ¹é…ï¼‰\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        # å»é™¤æ¯è¡Œæœ«å°¾çš„æ¢è¡Œç¬¦ï¼Œå¹¶è¿‡æ»¤æ‰ç©ºè¡Œï¼Œå…¨éƒ¨è½¬ä¸ºå°å†™\n",
    "        keywords = {line.strip().lower() for line in f if line.strip()}\n",
    "    \n",
    "    print(f\"å·²åŠ è½½ {len(keywords)} ä¸ªå…³é”®è¯\")\n",
    "    return keywords\n",
    "\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    å¯¹æ–‡æœ¬è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ï¼ŒåŒ…æ‹¬ï¼š\n",
    "    1. ç§»é™¤è¡¨æƒ…ç¬¦å·å’Œç‰¹æ®Šå­—ç¬¦\n",
    "    2. è½¬ä¸ºå°å†™\n",
    "    3. å¤„ç†æ ‡ç‚¹ç¬¦å·\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # è§„èŒƒåŒ–ä¸º NFKD å½¢å¼ï¼Œè¿™ä¼šå°†å¤åˆå­—ç¬¦åˆ†è§£\n",
    "    text = unicodedata.normalize('NFKD', text)\n",
    "    \n",
    "    # ç§»é™¤éASCIIå­—ç¬¦ï¼ˆåŒ…æ‹¬è¡¨æƒ…ç¬¦å·ï¼‰\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "    \n",
    "    # è½¬ä¸ºå°å†™\n",
    "    text = text.lower()\n",
    "    \n",
    "    # ç”¨ç©ºæ ¼æ›¿æ¢æ ‡ç‚¹ç¬¦å·å’Œç‰¹æ®Šå­—ç¬¦\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    \n",
    "    # å°†å¤šä¸ªç©ºæ ¼æ›¿æ¢ä¸ºå•ä¸ªç©ºæ ¼\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def contains_keywords(text, keywords):\n",
    "    \"\"\"\n",
    "    æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«å…³é”®è¯åˆ—è¡¨ä¸­çš„ä»»ä½•ä¸€ä¸ªå…³é”®è¯\n",
    "    å¤§å°å†™ä¸æ•æ„ŸåŒ¹é…\n",
    "    \n",
    "    å‚æ•°:\n",
    "    text - è¦æ£€æŸ¥çš„æ–‡æœ¬ï¼ˆåº”è¯¥å·²ç»æ ‡å‡†åŒ–ä¸ºå°å†™ï¼‰\n",
    "    keywords - å…³é”®è¯é›†åˆï¼ˆå…¨éƒ¨å°å†™ï¼‰\n",
    "    \n",
    "    è¿”å›:\n",
    "    True å¦‚æœæ–‡æœ¬åŒ…å«ä»»ä½•å…³é”®è¯ï¼Œå¦åˆ™ False\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return False\n",
    "    \n",
    "    # å°†æ–‡æœ¬åˆ†å‰²æˆå•è¯ï¼Œä¾¿äºå®Œæ•´å•è¯åŒ¹é…\n",
    "    words = set(text.split())\n",
    "    \n",
    "    # æ£€æŸ¥æ˜¯å¦æœ‰å…³é”®è¯å‡ºç°åœ¨æ–‡æœ¬ä¸­ï¼ˆä½œä¸ºå®Œæ•´å•è¯ï¼‰\n",
    "    if any(keyword in words for keyword in keywords):\n",
    "        return True\n",
    "    \n",
    "    # æ£€æŸ¥æ˜¯å¦æœ‰å¤šè¯å…³é”®è¯æ˜¯æ–‡æœ¬çš„å­å­—ç¬¦ä¸²\n",
    "    for keyword in keywords:\n",
    "        if ' ' in keyword and keyword in text:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "def filter_dataframe_by_keywords(df, keywords_file, verbose=True):\n",
    "    \"\"\"\n",
    "    é€šè¿‡å…³é”®è¯å¯¹DataFrameè¿›è¡Œå†…å®¹ç­›é€‰\n",
    "    \n",
    "    å‚æ•°:\n",
    "    df - è¦ç­›é€‰çš„DataFrame\n",
    "    keywords_file - å…³é”®è¯æ–‡ä»¶è·¯å¾„\n",
    "    verbose - æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†è¿›åº¦\n",
    "    \n",
    "    è¿”å›:\n",
    "    ç­›é€‰åçš„DataFrame\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # åŠ è½½å…³é”®è¯ï¼ˆå…¨éƒ¨è½¬ä¸ºå°å†™ä»¥ç¡®ä¿å¤§å°å†™ä¸æ•æ„ŸåŒ¹é…ï¼‰\n",
    "    keywords = load_keywords(keywords_file)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"åŸå§‹æ•°æ®: {len(df)} è¡Œ\")\n",
    "    \n",
    "    # é€šè¿‡contentç­›é€‰\n",
    "    if verbose:\n",
    "        print(\"æ­£åœ¨é€šè¿‡contentç­›é€‰...\")\n",
    "    \n",
    "    # åˆ›å»ºä¸€ä¸ªæ©ç æ•°ç»„æ¥æ ‡è®°è¦ä¿ç•™çš„è¡Œ\n",
    "    content_mask = pd.Series(False, index=df.index)\n",
    "    \n",
    "    if 'content' in df.columns:\n",
    "        # å¯¹äºæ¯ä¸€è¡Œï¼Œæ£€æŸ¥å…¶contentæ˜¯å¦åŒ…å«ä»»ä½•å…³é”®è¯\n",
    "        for idx, content in tqdm(enumerate(df['content']), total=len(df), disable=not verbose):\n",
    "            if isinstance(content, str) and content.strip():\n",
    "                # æ ‡å‡†åŒ–contentï¼ˆè½¬ä¸ºå°å†™ç­‰ï¼‰\n",
    "                normalized_content = normalize_text(content)\n",
    "                if contains_keywords(normalized_content, keywords):\n",
    "                    content_mask.iloc[idx] = True\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"è­¦å‘Š: DataFrameä¸­æ²¡æœ‰'content'åˆ—ï¼Œæ— æ³•è¿›è¡Œç­›é€‰\")\n",
    "            return df\n",
    "    \n",
    "    # ç­›é€‰ç»“æœ\n",
    "    filtered_df = df[content_mask].copy()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    if verbose:\n",
    "        print(f\"ç­›é€‰ç»“æœ: {len(filtered_df)} è¡Œ ({len(filtered_df)/len(df)*100:.2f}%)\")\n",
    "        print(f\"æ€»è€—æ—¶: {end_time - start_time:.2f} ç§’\")\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "\n",
    "# ä½¿ç”¨ç¤ºä¾‹\n",
    "# filtered_data = filter_dataframe_by_keywords(df, 'keywords.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T10:45:12.298625Z",
     "iopub.status.busy": "2025-04-15T10:45:12.298625Z",
     "iopub.status.idle": "2025-04-15T10:45:12.359234Z",
     "shell.execute_reply": "2025-04-15T10:45:12.359234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·²åŠ è½½ 61 ä¸ªå…³é”®è¯\n",
      "åŸå§‹æ•°æ®: 898 è¡Œ\n",
      "æ­£åœ¨é€šè¿‡contentç­›é€‰...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/898 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 898/898 [00:00<00:00, 24239.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç­›é€‰ç»“æœ: 605 è¡Œ (67.37%)\n",
      "æ€»è€—æ—¶: 0.04 ç§’\n",
      "(605, 37)\n",
      "                    id  title  \\\n",
      "4  1909480340126581095    NaN   \n",
      "6  1909020699747885481    NaN   \n",
      "7  1908203431765881038    NaN   \n",
      "8  1908194727209386420    NaN   \n",
      "9  1908053656731086945    NaN   \n",
      "\n",
      "                                             content  url lang  \\\n",
      "4  Metal Shoe Rack\\nUpto 24% off\\nLink for you: h...  NaN   en   \n",
      "6  @emob_ @DamnNearWhite @Tr3sMilagros @MyFirstKi...  NaN   en   \n",
      "7  J.T. Foote Adjustable Shoe Trees - Plastic \\nğŸ› ...  NaN   en   \n",
      "8  EXVITO Metal Shoe Rack for Home â€“ Adjustable &...  NaN   en   \n",
      "9  Closet Shoe Organizer for 24 Pairs with Adjust...  NaN   en   \n",
      "\n",
      "                     publish_time publish_time_date publish_time_time  \\\n",
      "4  Tue Apr 08 05:36:04 +0000 2025        2025-04-08          05:36:04   \n",
      "6  Sun Apr 06 23:09:37 +0000 2025        2025-04-06          23:09:37   \n",
      "7  Fri Apr 04 17:02:05 +0000 2025        2025-04-04          17:02:05   \n",
      "8  Fri Apr 04 16:27:30 +0000 2025        2025-04-04          16:27:30   \n",
      "9  Fri Apr 04 07:06:56 +0000 2025        2025-04-04          07:06:56   \n",
      "\n",
      "   is_truncated  interaction_like_cnt  ...  author_video_cnt  \\\n",
      "4         False                     0  ...               NaN   \n",
      "6         False                     1  ...               NaN   \n",
      "7         False                     0  ...               NaN   \n",
      "8         False                     0  ...               NaN   \n",
      "9         False                     0  ...               NaN   \n",
      "\n",
      "   author_media_cnt  author_followers_cnt  author_org_attribute  \\\n",
      "4              1993                     6                   NaN   \n",
      "6              5586                  4709                   NaN   \n",
      "7              1072                    24                   NaN   \n",
      "8              2179                  3974                   NaN   \n",
      "9                86                  3118                   NaN   \n",
      "\n",
      "   author_verified_type  author_collection_cnt  \\\n",
      "4                 False                      0   \n",
      "6                 False                      0   \n",
      "7                 False                      0   \n",
      "8                 False                      0   \n",
      "9                 False                      0   \n",
      "\n",
      "                              author_profile_picture  \\\n",
      "4  https://pbs.twimg.com/profile_images/186528787...   \n",
      "6  https://pbs.twimg.com/profile_images/191001923...   \n",
      "7  https://pbs.twimg.com/profile_images/941323346...   \n",
      "8  https://pbs.twimg.com/profile_images/182118449...   \n",
      "9  https://pbs.twimg.com/profile_images/189695809...   \n",
      "\n",
      "        author_registed_timestamp  author_registed_timestamp_date  \\\n",
      "4  Sun Jun 18 16:13:39 +0000 2023                      2023-06-18   \n",
      "6  Thu Feb 11 17:37:08 +0000 2016                      2016-02-11   \n",
      "7  Thu Dec 14 14:58:31 +0000 2017                      2017-12-14   \n",
      "8  Mon Jan 05 11:51:21 +0000 2015                      2015-01-05   \n",
      "9  Wed Oct 23 12:18:05 +0000 2024                      2024-10-23   \n",
      "\n",
      "   author_registed_timestamp_time  \n",
      "4                        16:13:39  \n",
      "6                        17:37:08  \n",
      "7                        14:58:31  \n",
      "8                        11:51:21  \n",
      "9                        12:18:05  \n",
      "\n",
      "[5 rows x 37 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ç­›é€‰æ•°æ®\n",
    "filtered_data = filter_dataframe_by_keywords(result, filename_keywords)\n",
    "\n",
    "# æŸ¥çœ‹ç­›é€‰ç»“æœ\n",
    "print(filtered_data.shape)\n",
    "print(filtered_data.head())\n",
    "\n",
    "# ä¿å­˜ç»“æœ\n",
    "# filtered_data.to_csv('filtered_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T10:45:12.361101Z",
     "iopub.status.busy": "2025-04-15T10:45:12.359234Z",
     "iopub.status.idle": "2025-04-15T10:45:12.618189Z",
     "shell.execute_reply": "2025-04-15T10:45:12.618189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ•°æ®å·²ä¿å­˜åˆ°: ç”Ÿæˆç»“æœ/social_media/å…³é”®è¯ç­›é€‰åçš„æ•°æ®.xlsx\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºæ–‡ä»¶å¤¹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "    print(f\"å·²åˆ›å»ºæ–‡ä»¶å¤¹: {folder_name}\")\n",
    "\n",
    "# ä¿®æ”¹ä¿å­˜è·¯å¾„ï¼Œå°†è¾“å‡ºæ–‡ä»¶ä¿å­˜åˆ°æ–°æ–‡ä»¶å¤¹\n",
    "output_path = os.path.join(folder_name, 'å…³é”®è¯ç­›é€‰åçš„æ•°æ®.xlsx')\n",
    "filtered_data.to_excel(output_path, index=False)\n",
    "print(f\"æ•°æ®å·²ä¿å­˜åˆ°: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lynx",
   "language": "python",
   "name": "lynx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
